{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run default-imports.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run run-experiment.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not unpickle object. [Errno 2] No such file or directory: 'experiments.json'\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 264.385ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 54, 12, 814115)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2974683544303797, 'recall': 0.6714285714285714, 'f1-score': 0.41228070175438597, 'support': 140.0, 'confusion_matrix': [[995, 222], [46, 94]], 'auc': 0.8044811597605352, 'n': 1357, 'tn': 995, 'fp': 222, 'fn': 46, 'tp': 94, 'dor': 9.158832745789267}, 'calibration': {'slope': 1.3688330426681565, 'intercept': 0.24974813654972466}, 'clinical_usefulness': {'treated': -0.3124539425202652, 'treated_all': -1.9894374846475065, 'untreated': 0.7187072323402462, 'overall': 0.40625328981998104, 'prevalence': 0.10316875460574797, 'adapt': 0.4093588798820928, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.307507999999871, 'explain': 2.100000028804061e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 228.548ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 54, 18, 534875)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18893129770992367, 'recall': 0.7734375, 'f1-score': 0.303680981595092, 'support': 128.0, 'confusion_matrix': [[804, 425], [29, 99]], 'auc': 0.7946374084621644, 'n': 1357, 'tn': 804, 'fp': 425, 'fn': 29, 'tp': 99, 'dor': 6.458093306288032}, 'calibration': {'slope': 0.5356009518061176, 'intercept': 0.448120914328559}, 'clinical_usefulness': {'treated': -0.6578236305576025, 'treated_all': -2.01891427167772, 'untreated': 0.5833245604800505, 'overall': -0.07449907007755197, 'prevalence': 0.09432571849668386, 'adapt': 0.2109801031687546, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.270786000000044, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 542.053ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 54, 23, 562378)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17657657657657658, 'recall': 0.7716535433070866, 'f1-score': 0.2873900293255132, 'support': 127.0, 'confusion_matrix': [[773, 457], [29, 98]], 'auc': 0.7692913385826772, 'n': 1357, 'tn': 773, 'fp': 457, 'fn': 29, 'tp': 98, 'dor': 5.71598883271712}, 'calibration': {'slope': 1.1209406708609195, 'intercept': 0.2662974080729905}, 'clinical_usefulness': {'treated': -0.71358388602309, 'treated_all': -2.021370670596905, 'untreated': 0.5604800505316349, 'overall': -0.15310383549145512, 'prevalence': 0.09358879882092852, 'adapt': 0.17826086956521736, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.545440999999755, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 64.082ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 54, 30, 549658)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18773234200743494, 'recall': 0.7829457364341085, 'f1-score': 0.3028485757121439, 'support': 129.0, 'confusion_matrix': [[791, 437], [28, 101]], 'auc': 0.7832739943943641, 'n': 1357, 'tn': 791, 'fp': 437, 'fn': 28, 'tp': 101, 'dor': 6.529176201372998}, 'calibration': {'slope': 0.6978385527630797, 'intercept': 0.3469226587603563}, 'clinical_usefulness': {'treated': -0.6769835421272413, 'treated_all': -2.016457872758535, 'untreated': 0.5740604274134119, 'overall': -0.10292311471382942, 'prevalence': 0.0950626381724392, 'adapt': 0.19874723655121587, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.102167000000009, 'explain': 3.300000025774352e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 753.079ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 54, 37, 4350)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19395017793594305, 'recall': 0.7124183006535948, 'f1-score': 0.3048951048951049, 'support': 153.0, 'confusion_matrix': [[751, 453], [44, 109]], 'auc': 0.714201572101709, 'n': 1357, 'tn': 751, 'fp': 453, 'fn': 44, 'tp': 109, 'dor': 4.1069135059201285}, 'calibration': {'slope': 0.19904225782967905, 'intercept': 0.4336210486730553}, 'clinical_usefulness': {'treated': -0.6985998526160647, 'treated_all': -1.957504298698108, 'untreated': 0.5395304768923044, 'overall': -0.15906937572376034, 'prevalence': 0.11274871039056743, 'adapt': 0.1680913780397936, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.796542000000045, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 434.831ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 54, 41, 958299)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.28654970760233917, 'recall': 0.7424242424242424, 'f1-score': 0.41350210970464135, 'support': 132.0, 'confusion_matrix': [[981, 244], [34, 98]], 'auc': 0.8506802721088436, 'n': 1357, 'tn': 981, 'fp': 244, 'fn': 34, 'tp': 98, 'dor': 11.58847637415622}, 'calibration': {'slope': 1.3067021943090984, 'intercept': 0.27829636768334054}, 'clinical_usefulness': {'treated': -0.3473348071726848, 'treated_all': -2.009088676000982, 'untreated': 0.7121802294978419, 'overall': 0.3648454223251571, 'prevalence': 0.09727339719970524, 'adapt': 0.3943257184966838, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.468973000000005, 'explain': 2.700000004551839e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 886.216ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 54, 47, 323578)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.16129032258064516, 'recall': 0.7377049180327869, 'f1-score': 0.2647058823529412, 'support': 122.0, 'confusion_matrix': [[767, 468], [32, 90]], 'auc': 0.7566469768367957, 'n': 1357, 'tn': 767, 'fp': 468, 'fn': 32, 'tp': 90, 'dor': 4.609375}, 'calibration': {'slope': 0.6885123243725658, 'intercept': 0.3624963775694096}, 'clinical_usefulness': {'treated': -0.7383935151068531, 'treated_all': -2.0336526651928266, 'untreated': 0.5551110643225602, 'overall': -0.18328245078429295, 'prevalence': 0.0899042004421518, 'adapt': 0.16705969049373615, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.926855999999589, 'explain': 2.89999998130952e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 790.846ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 54, 52, 797295)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20404411764705882, 'recall': 0.7655172413793103, 'f1-score': 0.32220609579100146, 'support': 145.0, 'confusion_matrix': [[779, 433], [34, 111]], 'auc': 0.7654574940252645, 'n': 1357, 'tn': 779, 'fp': 433, 'fn': 34, 'tp': 111, 'dor': 5.873454693655753}, 'calibration': {'slope': 0.802094933459077, 'intercept': 0.2942836451447296}, 'clinical_usefulness': {'treated': -0.6627364283959714, 'treated_all': -1.9771554900515838, 'untreated': 0.5633224549952626, 'overall': -0.09941397340070879, 'prevalence': 0.10685335298452468, 'adapt': 0.19550478997789236, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.826935000000049, 'explain': 0.0}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 776.734ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 54, 58, 85207)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1349911190053286, 'recall': 0.7102803738317757, 'f1-score': 0.22686567164179106, 'support': 107.0, 'confusion_matrix': [[763, 487], [31, 76]], 'auc': 0.7056, 'n': 1357, 'tn': 763, 'fp': 487, 'fn': 31, 'tp': 76, 'dor': 3.8410280188116848}, 'calibration': {'slope': 1.248249509962707, 'intercept': 0.2663520536667374}, 'clinical_usefulness': {'treated': -0.7813804961925815, 'treated_all': -2.070498648980594, 'untreated': 0.5524792083377197, 'overall': -0.22890128785486186, 'prevalence': 0.07885040530582167, 'adapt': 0.15232129697862923, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.825684999999794, 'explain': 3.200000037395512e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 161.421ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 55, 2, 775812)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2, 'recall': 0.7777777777777778, 'f1-score': 0.3181818181818182, 'support': 144.0, 'confusion_matrix': [[765, 448], [32, 112]], 'auc': 0.7649795044426124, 'n': 1357, 'tn': 765, 'fp': 448, 'fn': 32, 'tp': 112, 'dor': 5.9765625}, 'calibration': {'slope': 1.1112356520143876, 'intercept': 0.25208189586905116}, 'clinical_usefulness': {'treated': -0.6877916973716529, 'treated_all': -1.9796118889707683, 'untreated': 0.5536372249710495, 'overall': -0.1341544724006034, 'prevalence': 0.10611643330876934, 'adapt': 0.18120854826823873, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.199150999999802, 'explain': 3.299999980299617e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 69.764ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 55, 8, 546751)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.26666666666666666, 'recall': 0.6495726495726496, 'f1-score': 0.3781094527363184, 'support': 117.0, 'confusion_matrix': [[1031, 209], [41, 76]], 'auc': 0.816880341880342, 'n': 1357, 'tn': 1031, 'fp': 209, 'fn': 41, 'tp': 76, 'dor': 9.144124168514413}, 'calibration': {'slope': 1.4598202178440194, 'intercept': 0.23912667229305423}, 'clinical_usefulness': {'treated': -0.30336526651928275, 'treated_all': -2.0459346597887493, 'untreated': 0.746815454258343, 'overall': 0.4434501877390602, 'prevalence': 0.08621960206337509, 'adapt': 0.43176123802505517, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.10558600000013, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 442.563ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 55, 13, 701693)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1956521739130435, 'recall': 0.7941176470588235, 'f1-score': 0.3139534883720931, 'support': 136.0, 'confusion_matrix': [[777, 444], [28, 108]], 'auc': 0.7699902442549501, 'n': 1357, 'tn': 777, 'fp': 444, 'fn': 28, 'tp': 108, 'dor': 6.75}, 'calibration': {'slope': 0.7698908615646194, 'intercept': 0.30088795061476226}, 'clinical_usefulness': {'treated': -0.6838614591009577, 'treated_all': -1.9992630803242442, 'untreated': 0.5637435519528371, 'overall': -0.12011790714812065, 'prevalence': 0.10022107590272661, 'adapt': 0.18946204863669858, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.479906000000028, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 581.87ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 55, 19, 790968)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17921146953405018, 'recall': 0.7575757575757576, 'f1-score': 0.28985507246376807, 'support': 132.0, 'confusion_matrix': [[767, 458], [32, 100]], 'auc': 0.7623964131106988, 'n': 1357, 'tn': 767, 'fp': 458, 'fn': 32, 'tp': 100, 'dor': 5.23335152838428}, 'calibration': {'slope': 1.2439865917678286, 'intercept': 0.2878271246873017}, 'clinical_usefulness': {'treated': -0.7138295259150084, 'treated_all': -2.009088676000982, 'untreated': 0.5551110643225602, 'overall': -0.15871846159244818, 'prevalence': 0.09727339719970524, 'adapt': 0.17442888725128958, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.620194000000083, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 158.56ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 55, 25, 980524)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19964028776978418, 'recall': 0.8604651162790697, 'f1-score': 0.32408759124087594, 'support': 129.0, 'confusion_matrix': [[783, 445], [18, 111]], 'auc': 0.8203103300255031, 'n': 1357, 'tn': 783, 'fp': 445, 'fn': 18, 'tp': 111, 'dor': 10.850561797752809}, 'calibration': {'slope': 0.4801384531308473, 'intercept': 0.3962726588301452}, 'clinical_usefulness': {'treated': -0.683370179317121, 'treated_all': -2.016457872758535, 'untreated': 0.5713232971891777, 'overall': -0.11204688212794323, 'prevalence': 0.0950626381724392, 'adapt': 0.1949152542372881, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.189573999999993, 'explain': 1.700000029813964e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 556.8ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 55, 31, 14720)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1931407942238267, 'recall': 0.8045112781954887, 'f1-score': 0.31149927219796214, 'support': 133.0, 'confusion_matrix': [[777, 447], [26, 107]], 'auc': 0.787796697626419, 'n': 1357, 'tn': 777, 'fp': 447, 'fn': 26, 'tp': 107, 'dor': 7.15358802271554}, 'calibration': {'slope': 0.6641968562562915, 'intercept': 0.35136640548456033}, 'clinical_usefulness': {'treated': -0.6897568165070006, 'treated_all': -2.0066322770817977, 'untreated': 0.5643751973891988, 'overall': -0.12538161911780177, 'prevalence': 0.09801031687546058, 'adapt': 0.18813559322033893, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.599356000000171, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 309.515ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 55, 35, 808471)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2872340425531915, 'recall': 0.6532258064516129, 'f1-score': 0.3990147783251232, 'support': 124.0, 'confusion_matrix': [[1032, 201], [43, 81]], 'auc': 0.8089272165973367, 'n': 1357, 'tn': 1032, 'fp': 201, 'fn': 43, 'tp': 81, 'dor': 9.671641791044777}, 'calibration': {'slope': 1.4355120079955852, 'intercept': 0.25632950518460773}, 'clinical_usefulness': {'treated': -0.28592483419307296, 'treated_all': -2.028739867354458, 'untreated': 0.7469207284977366, 'overall': 0.46099589430466364, 'prevalence': 0.09137803979366249, 'adapt': 0.4370670596904937, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.313169000000016, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 426.696ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 55, 40, 933298)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19012797074954296, 'recall': 0.8125, 'f1-score': 0.30814814814814817, 'support': 128.0, 'confusion_matrix': [[786, 443], [24, 104]], 'auc': 0.7766731082180635, 'n': 1357, 'tn': 786, 'fp': 443, 'fn': 24, 'tp': 104, 'dor': 7.6884875846501135}, 'calibration': {'slope': 0.3875091158056872, 'intercept': 0.40540440011153056}, 'clinical_usefulness': {'treated': -0.68508965856055, 'treated_all': -2.01891427167772, 'untreated': 0.5716391199073587, 'overall': -0.11345053865319132, 'prevalence': 0.09432571849668386, 'adapt': 0.19462048636698606, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.4630520000000615, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 941.271ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 55, 46, 851442)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19962686567164178, 'recall': 0.8359375, 'f1-score': 0.32228915662650603, 'support': 128.0, 'confusion_matrix': [[800, 429], [21, 107]], 'auc': 0.795412937347437, 'n': 1357, 'tn': 800, 'fp': 429, 'fn': 21, 'tp': 107, 'dor': 9.5016095016095}, 'calibration': {'slope': 1.0802760767687976, 'intercept': 0.2614060838963711}, 'clinical_usefulness': {'treated': -0.6588061901252763, 'treated_all': -2.01891427167772, 'untreated': 0.5829034635224761, 'overall': -0.07590272660280017, 'prevalence': 0.09432571849668386, 'adapt': 0.21039056742815038, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.945322999999917, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 330.807ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 55, 51, 669195)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19521178637200737, 'recall': 0.8217054263565892, 'f1-score': 0.31547619047619047, 'support': 129.0, 'confusion_matrix': [[791, 437], [23, 106]], 'auc': 0.8075650834532737, 'n': 1357, 'tn': 791, 'fp': 437, 'fn': 23, 'tp': 106, 'dor': 8.342055516863994}, 'calibration': {'slope': 0.4874887209471397, 'intercept': 0.4382984531274893}, 'clinical_usefulness': {'treated': -0.6732989437484646, 'treated_all': -2.016457872758535, 'untreated': 0.5756395410043162, 'overall': -0.0976594027441483, 'prevalence': 0.0950626381724392, 'adapt': 0.20095799557848196, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.375944000000345, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 569.68ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 55, 56, 717817)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17657992565055763, 'recall': 0.753968253968254, 'f1-score': 0.2861445783132531, 'support': 126.0, 'confusion_matrix': [[788, 443], [31, 95]], 'auc': 0.7656634817479661, 'n': 1357, 'tn': 788, 'fp': 443, 'fn': 31, 'tp': 95, 'dor': 5.4511031821160705}, 'calibration': {'slope': 0.9873274967761037, 'intercept': 0.34072637697905894}, 'clinical_usefulness': {'treated': -0.6917219356423482, 'treated_all': -2.023827069516089, 'untreated': 0.5709022002316033, 'overall': -0.12081973541074487, 'prevalence': 0.09285187914517318, 'adapt': 0.19211495946941784, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.573357999999644, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 4.946ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 56, 2, 412389)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.3345070422535211, 'recall': 0.6737588652482269, 'f1-score': 0.4470588235294117, 'support': 141.0, 'confusion_matrix': [[1027, 189], [46, 95]], 'auc': 0.8159236188876446, 'n': 1357, 'tn': 1027, 'fp': 189, 'fn': 46, 'tp': 95, 'dor': 11.22210720036807}, 'calibration': {'slope': 1.1780406858008083, 'intercept': 0.26556093665987457}, 'clinical_usefulness': {'treated': -0.25497420781134855, 'treated_all': -1.9869810857283219, 'untreated': 0.7422886619644172, 'overall': 0.4873144541530687, 'prevalence': 0.10390567428150331, 'adapt': 0.4431098010316875, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.042693000000327, 'explain': 3.299999980299617e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 787.697ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 56, 8, 676678)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.14431239388794567, 'recall': 0.6854838709677419, 'f1-score': 0.23842917251051893, 'support': 124.0, 'confusion_matrix': [[729, 504], [39, 85]], 'auc': 0.6816576406875442, 'n': 1357, 'tn': 729, 'fp': 504, 'fn': 39, 'tp': 85, 'dor': 3.152472527472528}, 'calibration': {'slope': 0.646964042353046, 'intercept': 0.3431510833145712}, 'clinical_usefulness': {'treated': -0.8039793662490787, 'treated_all': -2.028739867354458, 'untreated': 0.5248973576165913, 'overall': -0.27908200863248744, 'prevalence': 0.09137803979366249, 'adapt': 0.1262343404568902, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.823213000000123, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 443.298ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 56, 14, 632513)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21414913957934992, 'recall': 0.8, 'f1-score': 0.33785822021116135, 'support': 140.0, 'confusion_matrix': [[806, 411], [28, 112]], 'auc': 0.7981306491372226, 'n': 1357, 'tn': 806, 'fp': 411, 'fn': 28, 'tp': 112, 'dor': 7.844282238442822}, 'calibration': {'slope': 0.657722124147555, 'intercept': 0.3350753904556799}, 'clinical_usefulness': {'treated': -0.6241709653647751, 'treated_all': -1.9894374846475065, 'untreated': 0.5851142225497421, 'overall': -0.03905674281503302, 'prevalence': 0.10316875460574797, 'adapt': 0.22232866617538685, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.534594000000197, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 746.175ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 56, 19, 921884)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19672131147540983, 'recall': 0.7714285714285715, 'f1-score': 0.3134978229317852, 'support': 140.0, 'confusion_matrix': [[776, 441], [32, 108]], 'auc': 0.778321986148609, 'n': 1357, 'tn': 776, 'fp': 441, 'fn': 32, 'tp': 108, 'dor': 5.938775510204081}, 'calibration': {'slope': 0.6618738105282722, 'intercept': 0.3142554859550804}, 'clinical_usefulness': {'treated': -0.6787030213706704, 'treated_all': -1.9894374846475065, 'untreated': 0.5617433414043583, 'overall': -0.11695967996631207, 'prevalence': 0.10316875460574797, 'adapt': 0.18960943257184967, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.784716000000117, 'explain': 2.100000028804061e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 898.57ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 56, 25, 318123)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2011070110701107, 'recall': 0.7676056338028169, 'f1-score': 0.31871345029239767, 'support': 142.0, 'confusion_matrix': [[782, 433], [33, 109]], 'auc': 0.7527473482872544, 'n': 1357, 'tn': 782, 'fp': 433, 'fn': 33, 'tp': 109, 'dor': 5.9652879837637345}, 'calibration': {'slope': 1.1211343117794272, 'intercept': 0.23437312178669478}, 'clinical_usefulness': {'treated': -0.664210267747482, 'treated_all': -1.9845246868091375, 'untreated': 0.5658490367407095, 'overall': -0.09836123100677252, 'prevalence': 0.10464259395725865, 'adapt': 0.19683124539425198, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.902815999999802, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=537\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 796, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 814, in _sample\n",
      "    X_class, nns, n_samples, 1.0)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 781.947ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 56, 30, 650593)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.3277591973244147, 'recall': 0.7538461538461538, 'f1-score': 0.4568764568764569, 'support': 130.0, 'confusion_matrix': [[1026, 201], [32, 98]], 'auc': 0.853281925898063, 'n': 1357, 'tn': 1026, 'fp': 201, 'fn': 32, 'tp': 98, 'dor': 15.632462686567164}, 'calibration': {'slope': 1.1020721936069966, 'intercept': 0.26431500043833733}, 'clinical_usefulness': {'treated': -0.27339719970523213, 'treated_all': -2.014001473839351, 'untreated': 0.745973260343194, 'overall': 0.47257606063796187, 'prevalence': 0.09579955784819455, 'adapt': 0.4401621223286661, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.785769999999957, 'explain': 1.8999999610969098e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4898\n",
      "Class:1.0/N=527\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 796, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 814, in _sample\n",
      "    X_class, nns, n_samples, 1.0)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 36.93ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 56, 36, 219552)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21033210332103322, 'recall': 0.8142857142857143, 'f1-score': 0.3343108504398827, 'support': 140.0, 'confusion_matrix': [[789, 428], [26, 114]], 'auc': 0.7906033572015495, 'n': 1357, 'tn': 789, 'fp': 428, 'fn': 26, 'tp': 114, 'dor': 8.082854061826023}, 'calibration': {'slope': 0.5071821439329859, 'intercept': 0.3933631007180761}, 'clinical_usefulness': {'treated': -0.6519282731515599, 'treated_all': -1.9894374846475065, 'untreated': 0.573218233498263, 'overall': -0.07871003965329693, 'prevalence': 0.10316875460574797, 'adapt': 0.20567428150331604, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.0762620000000425, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4898\n",
      "Class:1.0/N=527\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 796, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 814, in _sample\n",
      "    X_class, nns, n_samples, 1.0)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 563.478ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 56, 42, 341224)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18545454545454546, 'recall': 0.7285714285714285, 'f1-score': 0.2956521739130435, 'support': 140.0, 'confusion_matrix': [[769, 448], [38, 102]], 'auc': 0.7211761943890129, 'n': 1357, 'tn': 769, 'fp': 448, 'fn': 38, 'tp': 102, 'dor': 4.6074953007518795}, 'calibration': {'slope': 0.816638658171275, 'intercept': 0.2946845736193524}, 'clinical_usefulness': {'treated': -0.6951608941292063, 'treated_all': -1.9894374846475065, 'untreated': 0.5546899673649858, 'overall': -0.14047092676422057, 'prevalence': 0.10316875460574797, 'adapt': 0.1797347089167281, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.56685299999981, 'explain': 3.100000003541936e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4893\n",
      "Class:1.0/N=532\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 796, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 814, in _sample\n",
      "    X_class, nns, n_samples, 1.0)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 243.517ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 56, 48, 174095)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19611650485436893, 'recall': 0.7481481481481481, 'f1-score': 0.31076923076923074, 'support': 135.0, 'confusion_matrix': [[808, 414], [34, 101]], 'auc': 0.7622082802933867, 'n': 1357, 'tn': 808, 'fp': 414, 'fn': 34, 'tp': 101, 'dor': 5.797669792554703}, 'calibration': {'slope': 0.669763857198577, 'intercept': 0.34052220630917857}, 'clinical_usefulness': {'treated': -0.6374355195283714, 'treated_all': -2.001719479243429, 'untreated': 0.5846931255921676, 'overall': -0.052742393936203835, 'prevalence': 0.09948415622697127, 'adapt': 0.21805453205600583, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.279121000000032, 'explain': 0.00012199999991935329}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4891\n",
      "Class:1.0/N=534\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 796, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 814, in _sample\n",
      "    X_class, nns, n_samples, 1.0)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 890.307ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 56, 53, 589479)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1786339754816112, 'recall': 0.7669172932330827, 'f1-score': 0.2897727272727273, 'support': 133.0, 'confusion_matrix': [[755, 469], [31, 102]], 'auc': 0.7667913656690746, 'n': 1357, 'tn': 755, 'fp': 469, 'fn': 31, 'tp': 102, 'dor': 5.296787949652659}, 'calibration': {'slope': 0.5883636984302271, 'intercept': 0.37829179051722783}, 'clinical_usefulness': {'treated': -0.7312699582412182, 'treated_all': -2.0066322770817977, 'untreated': 0.5465838509316769, 'overall': -0.18468610730954127, 'prevalence': 0.09801031687546058, 'adapt': 0.1632277081798083, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.88542600000028, 'explain': 3.200000037395512e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4884\n",
      "Class:1.0/N=541\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4884\n",
      "Class:1.0/N=1221\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 67.883ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 57, 0, 300862)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2826086956521739, 'recall': 0.7222222222222222, 'f1-score': 0.40625, 'support': 126.0, 'confusion_matrix': [[1000, 231], [35, 91]], 'auc': 0.8269731667375859, 'n': 1357, 'tn': 1000, 'fp': 231, 'fn': 35, 'tp': 91, 'dor': 11.255411255411254}, 'calibration': {'slope': 1.3739682475657686, 'intercept': 0.2827757378484611}, 'clinical_usefulness': {'treated': -0.33014001473839344, 'treated_all': -2.023827069516089, 'untreated': 0.7258658806190126, 'overall': 0.39572586588061914, 'prevalence': 0.09285187914517318, 'adapt': 0.40906411201179077, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.114943999999923, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4881\n",
      "Class:1.0/N=544\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4881\n",
      "Class:1.0/N=1220\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 341.501ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 57, 6, 249412)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1774193548387097, 'recall': 0.8048780487804879, 'f1-score': 0.2907488986784141, 'support': 123.0, 'confusion_matrix': [[775, 459], [24, 99]], 'auc': 0.7735864595274803, 'n': 1357, 'tn': 775, 'fp': 459, 'fn': 24, 'tp': 99, 'dor': 6.964869281045752}, 'calibration': {'slope': 0.4577203917307507, 'intercept': 0.44813156896032136}, 'clinical_usefulness': {'treated': -0.716285924834193, 'treated_all': -2.0311962662736427, 'untreated': 0.5635330034740499, 'overall': -0.15275292136014307, 'prevalence': 0.09064112011790715, 'adapt': 0.179587324981577, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.384385000000293, 'explain': 0.0}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=529\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=1224\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 658.255ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 57, 12, 469214)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19782214156079855, 'recall': 0.7898550724637681, 'f1-score': 0.316400580551524, 'support': 138.0, 'confusion_matrix': [[777, 442], [29, 109]], 'auc': 0.7668794806862361, 'n': 1357, 'tn': 777, 'fp': 442, 'fn': 29, 'tp': 109, 'dor': 6.607349040411921}, 'calibration': {'slope': 0.6708706146301959, 'intercept': 0.35154875136710106}, 'clinical_usefulness': {'treated': -0.6796855809383442, 'treated_all': -1.9943502824858752, 'untreated': 0.5634277292346562, 'overall': -0.11625785170368796, 'prevalence': 0.1016949152542373, 'adapt': 0.19049373618275608, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.702389000000039, 'explain': 1.8000000181928044e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=532\n",
      "Class:0.0/N=4893\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=1223\n",
      "Class:0.0/N=4893\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 555.855ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 57, 18, 786986)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19047619047619047, 'recall': 0.7703703703703704, 'f1-score': 0.3054331864904552, 'support': 135.0, 'confusion_matrix': [[780, 442], [31, 104]], 'auc': 0.7743468509425956, 'n': 1357, 'tn': 780, 'fp': 442, 'fn': 31, 'tp': 104, 'dor': 5.9203036053130935}, 'calibration': {'slope': 0.7654667537182468, 'intercept': 0.28422996686486923}, 'clinical_usefulness': {'treated': -0.6833701793171209, 'treated_all': -2.001719479243429, 'untreated': 0.5650068428255606, 'overall': -0.11836333649156028, 'prevalence': 0.09948415622697127, 'adapt': 0.1904937361827561, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.597004000000197, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4907\n",
      "Class:1.0/N=518\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4907\n",
      "Class:1.0/N=1226\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 458.432ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 57, 24, 833612)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2111111111111111, 'recall': 0.7651006711409396, 'f1-score': 0.33091436865021767, 'support': 149.0, 'confusion_matrix': [[782, 426], [35, 114]], 'auc': 0.78780168007467, 'n': 1357, 'tn': 782, 'fp': 426, 'fn': 35, 'tp': 114, 'dor': 5.97907444668008}, 'calibration': {'slope': 0.618622892528162, 'intercept': 0.3321748428560774}, 'clinical_usefulness': {'treated': -0.6484893146647015, 'treated_all': -1.967329894374846, 'untreated': 0.5652173913043479, 'overall': -0.0832719233603536, 'prevalence': 0.10980103168754606, 'adapt': 0.20110537951363305, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.503596000000016, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4894\n",
      "Class:1.0/N=531\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4894\n",
      "Class:1.0/N=2447\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 1.061ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 57, 32, 523510)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.26571428571428574, 'recall': 0.6838235294117647, 'f1-score': 0.3827160493827161, 'support': 136.0, 'confusion_matrix': [[964, 257], [43, 93]], 'auc': 0.8133280339162694, 'n': 1357, 'tn': 964, 'fp': 257, 'fn': 43, 'tp': 93, 'dor': 8.112568998280699}, 'calibration': {'slope': 1.1926403280424476, 'intercept': 0.30803603160961757}, 'clinical_usefulness': {'treated': -0.37337263571604024, 'treated_all': -1.9992630803242442, 'untreated': 0.6968101905463733, 'overall': 0.32343755483033304, 'prevalence': 0.10022107590272661, 'adapt': 0.37575534266764915, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.049521000000368, 'explain': 1.8999999610969098e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4891\n",
      "Class:1.0/N=534\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4891\n",
      "Class:1.0/N=2445\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 871.154ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 57, 39, 967264)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17477477477477477, 'recall': 0.7293233082706767, 'f1-score': 0.28197674418604646, 'support': 133.0, 'confusion_matrix': [[766, 458], [36, 97]], 'auc': 0.7280333185905941, 'n': 1357, 'tn': 766, 'fp': 458, 'fn': 36, 'tp': 97, 'dor': 4.50642891800097}, 'calibration': {'slope': 1.1275174733710682, 'intercept': 0.2621452758349487}, 'clinical_usefulness': {'treated': -0.7160402849422745, 'treated_all': -2.0066322770817977, 'untreated': 0.5531108537740815, 'overall': -0.16292943116819292, 'prevalence': 0.09801031687546058, 'adapt': 0.17236551215917467, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.913829000000078, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=540\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=2442\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 451.833ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 57, 45, 983712)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.16, 'recall': 0.7244094488188977, 'f1-score': 0.2621082621082621, 'support': 127.0, 'confusion_matrix': [[747, 483], [35, 92]], 'auc': 0.7307726778055182, 'n': 1357, 'tn': 747, 'fp': 483, 'fn': 35, 'tp': 92, 'dor': 4.0653061224489795}, 'calibration': {'slope': 0.7783025449003794, 'intercept': 0.3149559976685975}, 'clinical_usefulness': {'treated': -0.7627118644067795, 'treated_all': -2.021370670596905, 'untreated': 0.5394252026529108, 'overall': -0.2232866617538687, 'prevalence': 0.09358879882092852, 'adapt': 0.14878408253500364, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.492443999999978, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4873\n",
      "Class:1.0/N=552\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4873\n",
      "Class:1.0/N=2436\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 969.701ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 57, 53, 519103)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18664047151277013, 'recall': 0.8260869565217391, 'f1-score': 0.30448717948717946, 'support': 115.0, 'confusion_matrix': [[828, 414], [20, 95]], 'auc': 0.8288454806413218, 'n': 1357, 'tn': 828, 'fp': 414, 'fn': 20, 'tp': 95, 'dor': 9.5}, 'calibration': {'slope': 0.8012647307072506, 'intercept': 0.3325264898743715}, 'clinical_usefulness': {'treated': -0.6418570375829035, 'treated_all': -2.0508474576271185, 'untreated': 0.6038530371618065, 'overall': -0.03800400042109697, 'prevalence': 0.0847457627118644, 'adapt': 0.23014001473839346, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.018009000000347, 'explain': 2.100000028804061e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=529\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=2448\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 504.538ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 58, 0, 633411)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21235521235521235, 'recall': 0.7971014492753623, 'f1-score': 0.33536585365853655, 'support': 138.0, 'confusion_matrix': [[811, 408], [28, 110]], 'auc': 0.8042467691502895, 'n': 1357, 'tn': 811, 'fp': 408, 'fn': 28, 'tp': 110, 'dor': 7.808998599439776}, 'calibration': {'slope': 0.7478520358164584, 'intercept': 0.32409879100832517}, 'clinical_usefulness': {'treated': -0.6204863669859986, 'treated_all': -1.9943502824858752, 'untreated': 0.5887988209285188, 'overall': -0.03168754605747981, 'prevalence': 0.1016949152542373, 'adapt': 0.2260132645541635, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.548345000000154, 'explain': 2.100000028804061e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4875\n",
      "Class:1.0/N=550\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4875\n",
      "Class:1.0/N=3656\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 619.447ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 58, 6, 861387)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.26625386996904027, 'recall': 0.7350427350427351, 'f1-score': 0.390909090909091, 'support': 117.0, 'confusion_matrix': [[1003, 237], [31, 86]], 'auc': 0.8194306589467879, 'n': 1357, 'tn': 1003, 'fp': 237, 'fn': 31, 'tp': 86, 'dor': 11.740574384102356}, 'calibration': {'slope': 1.727106715725057, 'intercept': 0.2347859743571168}, 'clinical_usefulness': {'treated': -0.34414148857774496, 'treated_all': -2.0459346597887493, 'untreated': 0.7293399305190019, 'overall': 0.38519844194125696, 'prevalence': 0.08621960206337509, 'adapt': 0.4072955047899778, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.665105999999923, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4872\n",
      "Class:1.0/N=553\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4872\n",
      "Class:1.0/N=3654\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 517.751ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 58, 13, 944077)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1554054054054054, 'recall': 0.8070175438596491, 'f1-score': 0.26062322946175637, 'support': 114.0, 'confusion_matrix': [[743, 500], [22, 92]], 'auc': 0.7714358301223695, 'n': 1357, 'tn': 743, 'fp': 500, 'fn': 22, 'tp': 92, 'dor': 6.214181818181818}, 'calibration': {'slope': 1.0332161160471116, 'intercept': 0.29395357021278534}, 'clinical_usefulness': {'treated': -0.7919430115450747, 'treated_all': -2.0533038565463024, 'untreated': 0.5405832192862406, 'overall': -0.2513597922588341, 'prevalence': 0.08400884303610906, 'adapt': 0.140825350036846, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.56306799999993, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=533\n",
      "Class:0.0/N=4892\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=3669\n",
      "Class:0.0/N=4892\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 620.152ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 58, 22, 126994)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1890909090909091, 'recall': 0.7761194029850746, 'f1-score': 0.30409356725146197, 'support': 134.0, 'confusion_matrix': [[777, 446], [30, 104]], 'auc': 0.7688489278871383, 'n': 1357, 'tn': 777, 'fp': 446, 'fn': 30, 'tp': 104, 'dor': 6.039461883408072}, 'calibration': {'slope': 1.0361469555475171, 'intercept': 0.28772326977743834}, 'clinical_usefulness': {'treated': -0.6902480962908374, 'treated_all': -2.0041758781626133, 'untreated': 0.5631119065164754, 'overall': -0.12713618977436203, 'prevalence': 0.09874723655121592, 'adapt': 0.18710390567428148, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.665343000000121, 'explain': 3.100000003541936e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=536\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=3666\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 701.228ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 58, 29, 372127)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1808695652173913, 'recall': 0.7938931297709924, 'f1-score': 0.2946175637393768, 'support': 131.0, 'confusion_matrix': [[755, 471], [27, 104]], 'auc': 0.7453519793781054, 'n': 1357, 'tn': 755, 'fp': 471, 'fn': 27, 'tp': 104, 'dor': 6.174412204136195}, 'calibration': {'slope': 1.5452851494055901, 'intercept': 0.2542502154981937}, 'clinical_usefulness': {'treated': -0.7332350773765658, 'treated_all': -2.011545074920167, 'untreated': 0.5478471418044004, 'overall': -0.18538793557216537, 'prevalence': 0.09653647752394989, 'adapt': 0.1635224760501105, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.549436000000242, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4887\n",
      "Class:1.0/N=538\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4887\n",
      "Class:1.0/N=3665\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 226.123ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 58, 36, 597739)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19891500904159132, 'recall': 0.8527131782945736, 'f1-score': 0.32258064516129037, 'support': 129.0, 'confusion_matrix': [[785, 443], [19, 110]], 'auc': 0.8230216145241522, 'n': 1357, 'tn': 785, 'fp': 443, 'fn': 19, 'tp': 110, 'dor': 10.258999643578472}, 'calibration': {'slope': 0.5554028166674975, 'intercept': 0.33963575743983243}, 'clinical_usefulness': {'treated': -0.680668140506018, 'treated_all': -2.016457872758535, 'untreated': 0.5724813138225076, 'overall': -0.10818682668351043, 'prevalence': 0.0950626381724392, 'adapt': 0.19653647752394984, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.19809000000032, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=536\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=4889\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 760.449ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 58, 45, 267074)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.3079470198675497, 'recall': 0.7099236641221374, 'f1-score': 0.42956120092378763, 'support': 131.0, 'confusion_matrix': [[1017, 209], [38, 93]], 'auc': 0.8313823892009016, 'n': 1357, 'tn': 1017, 'fp': 209, 'fn': 38, 'tp': 93, 'dor': 11.908964996222613}, 'calibration': {'slope': 1.4628295502491635, 'intercept': 0.2513079482929927}, 'clinical_usefulness': {'treated': -0.2908376320314419, 'treated_all': -2.011545074920167, 'untreated': 0.7374460469523108, 'overall': 0.44660841492086883, 'prevalence': 0.09653647752394989, 'adapt': 0.428960943257185, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.740903999999773, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=540\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=4885\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 429.734ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 58, 54, 267954)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19065420560747665, 'recall': 0.8031496062992126, 'f1-score': 0.30815709969788524, 'support': 127.0, 'confusion_matrix': [[797, 433], [25, 102]], 'auc': 0.817658920683695, 'n': 1357, 'tn': 797, 'fp': 433, 'fn': 25, 'tp': 102, 'dor': 7.5098383371824475}, 'calibration': {'slope': 0.6980517902076375, 'intercept': 0.33637517088733027}, 'clinical_usefulness': {'treated': -0.6693687054777694, 'treated_all': -2.021370670596905, 'untreated': 0.5794294136224866, 'overall': -0.08993929185528282, 'prevalence': 0.09358879882092852, 'adapt': 0.20478997789240974, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 8.474001999999928, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4882\n",
      "Class:1.0/N=543\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4882\n",
      "Class:1.0/N=4882\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 304.52ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 59, 2, 145207)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1766848816029144, 'recall': 0.782258064516129, 'f1-score': 0.28826151560178304, 'support': 124.0, 'confusion_matrix': [[781, 452], [27, 97]], 'auc': 0.7790662690003402, 'n': 1357, 'tn': 781, 'fp': 452, 'fn': 27, 'tp': 97, 'dor': 6.207554900032776}, 'calibration': {'slope': 1.3854992722248036, 'intercept': 0.26100926150873605}, 'clinical_usefulness': {'treated': -0.7057234094816996, 'treated_all': -2.028739867354458, 'untreated': 0.5670070533740393, 'overall': -0.1387163561076603, 'prevalence': 0.09137803979366249, 'adapt': 0.1851879145173176, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.266047999999955, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4880\n",
      "Class:1.0/N=545\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4880\n",
      "Class:1.0/N=4880\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 703.125ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 59, 10, 887472)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1711229946524064, 'recall': 0.7868852459016393, 'f1-score': 0.28111273792093705, 'support': 122.0, 'confusion_matrix': [[770, 465], [26, 96]], 'auc': 0.7701898188093184, 'n': 1357, 'tn': 770, 'fp': 465, 'fn': 26, 'tp': 96, 'dor': 6.114143920595534}, 'calibration': {'slope': 1.5207852949560445, 'intercept': 0.23228595598215673}, 'clinical_usefulness': {'treated': -0.7288135593220337, 'treated_all': -2.0336526651928266, 'untreated': 0.5592167596589115, 'overall': -0.16959679966312224, 'prevalence': 0.0899042004421518, 'adapt': 0.17280766396462788, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.669499000000087, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4893\n",
      "Class:1.0/N=532\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4893\n",
      "Class:1.0/N=4893\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 727.185ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 59, 18, 213041)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1771019677996422, 'recall': 0.7333333333333333, 'f1-score': 0.2853025936599423, 'support': 135.0, 'confusion_matrix': [[762, 460], [36, 99]], 'auc': 0.755282778687034, 'n': 1357, 'tn': 762, 'fp': 460, 'fn': 36, 'tp': 99, 'dor': 4.555434782608696}, 'calibration': {'slope': 0.9333692617682198, 'intercept': 0.2918774236337637}, 'clinical_usefulness': {'treated': -0.718005404077622, 'treated_all': -2.001719479243429, 'untreated': 0.5501631750710602, 'overall': -0.16784222900656187, 'prevalence': 0.09948415622697127, 'adapt': 0.16971260132645544, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.7755660000002536, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4891\n",
      "Class:1.0/N=534\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 335, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 364, in _sample\n",
      "    class_sample, X_class, nns, n_samples)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 813.079ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 59, 23, 857992)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.28391167192429023, 'recall': 0.6766917293233082, 'f1-score': 0.4, 'support': 133.0, 'confusion_matrix': [[997, 227], [43, 90]], 'auc': 0.796375128998968, 'n': 1357, 'tn': 997, 'fp': 227, 'fn': 43, 'tp': 90, 'dor': 9.192705665403135}, 'calibration': {'slope': 1.4252951698754968, 'intercept': 0.2568469703200177}, 'clinical_usefulness': {'treated': -0.32399901744043225, 'treated_all': -2.0066322770817977, 'untreated': 0.7211285398462995, 'overall': 0.3971295224058673, 'prevalence': 0.09801031687546058, 'adapt': 0.40759027266028, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.8492379999997866, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=529\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 335, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 364, in _sample\n",
      "    class_sample, X_class, nns, n_samples)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 476.166ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 59, 29, 640608)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17452006980802792, 'recall': 0.7246376811594203, 'f1-score': 0.2812939521800281, 'support': 138.0, 'confusion_matrix': [[746, 473], [38, 100]], 'auc': 0.7202446766772478, 'n': 1357, 'tn': 746, 'fp': 473, 'fn': 38, 'tp': 100, 'dor': 4.150439523756537}, 'calibration': {'slope': 1.0232189622881125, 'intercept': 0.2776702247640047}, 'clinical_usefulness': {'treated': -0.7396217145664454, 'treated_all': -1.9943502824858752, 'untreated': 0.5377408148226129, 'overall': -0.2018808997438325, 'prevalence': 0.1016949152542373, 'adapt': 0.15453205600589537, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.515668000000005, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4900\n",
      "Class:1.0/N=525\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 335, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 364, in _sample\n",
      "    class_sample, X_class, nns, n_samples)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 143.894ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 59, 35, 981465)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19413919413919414, 'recall': 0.7464788732394366, 'f1-score': 0.308139534883721, 'support': 142.0, 'confusion_matrix': [[775, 440], [36, 106]], 'auc': 0.736329913638208, 'n': 1357, 'tn': 775, 'fp': 440, 'fn': 36, 'tp': 106, 'dor': 5.186237373737374}, 'calibration': {'slope': 0.9048253298094985, 'intercept': 0.29422719894973254}, 'clinical_usefulness': {'treated': -0.6784573814787519, 'treated_all': -1.9845246868091375, 'untreated': 0.5597431308558796, 'overall': -0.11871425062287233, 'prevalence': 0.10464259395725865, 'adapt': 0.18828297715549008, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.181824999999662, 'explain': 4.399999988891068e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=537\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 335, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 364, in _sample\n",
      "    class_sample, X_class, nns, n_samples)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 763.775ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 59, 42, 172284)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1889908256880734, 'recall': 0.7923076923076923, 'f1-score': 0.3051851851851852, 'support': 130.0, 'confusion_matrix': [[785, 442], [27, 103]], 'auc': 0.796924957682904, 'n': 1357, 'tn': 785, 'fp': 442, 'fn': 27, 'tp': 103, 'dor': 6.775180157533099}, 'calibration': {'slope': 0.6091522781356784, 'intercept': 0.3813213417807051}, 'clinical_usefulness': {'treated': -0.6841070989928763, 'treated_all': -2.014001473839351, 'untreated': 0.5699547320770607, 'overall': -0.11415236691581554, 'prevalence': 0.09579955784819455, 'adapt': 0.1937361827560796, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.809022999999797, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4898\n",
      "Class:1.0/N=527\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 335, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 364, in _sample\n",
      "    class_sample, X_class, nns, n_samples)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 576.659ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 59, 47, 598729)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19272727272727272, 'recall': 0.7571428571428571, 'f1-score': 0.30724637681159417, 'support': 140.0, 'confusion_matrix': [[773, 444], [34, 106]], 'auc': 0.7616680361544783, 'n': 1357, 'tn': 773, 'fp': 444, 'fn': 34, 'tp': 106, 'dor': 5.427795442501324}, 'calibration': {'slope': 0.5914626493050361, 'intercept': 0.37526231391839937}, 'clinical_usefulness': {'treated': -0.6853352984524684, 'treated_all': -1.9894374846475065, 'untreated': 0.5589009369407305, 'overall': -0.12643436151173792, 'prevalence': 0.10316875460574797, 'adapt': 0.1856300663227708, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.622229999999945, 'explain': 1.8999999610969098e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=535\n",
      "Class:0.0/N=4890\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=1222\n",
      "Class:0.0/N=4890\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 823.707ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 59, 53, 292974)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.3, 'recall': 0.7045454545454546, 'f1-score': 0.420814479638009, 'support': 132.0, 'confusion_matrix': [[1008, 217], [39, 93]], 'auc': 0.8323871366728509, 'n': 1357, 'tn': 1008, 'fp': 217, 'fn': 39, 'tp': 93, 'dor': 11.076923076923077}, 'calibration': {'slope': 1.487115481142897, 'intercept': 0.24660650745654522}, 'clinical_usefulness': {'treated': -0.3045934659788749, 'treated_all': -2.009088676000982, 'untreated': 0.7304979471523319, 'overall': 0.425904481173457, 'prevalence': 0.09727339719970524, 'adapt': 0.41997052321296974, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.869125000000167, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4909\n",
      "Class:1.0/N=516\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4909\n",
      "Class:1.0/N=1227\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 449.288ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 15, 59, 59, 517349)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.22972972972972974, 'recall': 0.7880794701986755, 'f1-score': 0.35575485799701045, 'support': 151.0, 'confusion_matrix': [[807, 399], [32, 119]], 'auc': 0.8008247943505431, 'n': 1357, 'tn': 807, 'fp': 399, 'fn': 32, 'tp': 119, 'dor': 7.521381578947368}, 'calibration': {'slope': 0.6549518069952336, 'intercept': 0.33399346885761216}, 'clinical_usefulness': {'treated': -0.5983787767133382, 'treated_all': -1.9624170965364773, 'untreated': 0.5845878513527739, 'overall': -0.013790925360564255, 'prevalence': 0.11127487103905674, 'adapt': 0.22969786293294026, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.457051999999749, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4887\n",
      "Class:1.0/N=538\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4887\n",
      "Class:1.0/N=1221\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 385.954ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 0, 5, 765582)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18165784832451498, 'recall': 0.7984496124031008, 'f1-score': 0.2959770114942529, 'support': 129.0, 'confusion_matrix': [[764, 464], [26, 103]], 'auc': 0.7893625482917962, 'n': 1357, 'tn': 764, 'fp': 464, 'fn': 26, 'tp': 103, 'dor': 6.5228779840848805}, 'calibration': {'slope': 0.8169422863975141, 'intercept': 0.3266754761270886}, 'clinical_usefulness': {'treated': -0.7219356423483172, 'treated_all': -2.016457872758535, 'untreated': 0.5547952416043794, 'overall': -0.16714040074393777, 'prevalence': 0.0950626381724392, 'adapt': 0.1717759764185704, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.42618500000026, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=537\n",
      "Class:0.0/N=4888\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=1222\n",
      "Class:0.0/N=4888\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 184.407ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 0, 12, 739301)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.16923076923076924, 'recall': 0.676923076923077, 'f1-score': 0.27076923076923076, 'support': 130.0, 'confusion_matrix': [[795, 432], [42, 88]], 'auc': 0.7058711052598584, 'n': 1357, 'tn': 795, 'fp': 432, 'fn': 42, 'tp': 88, 'dor': 3.8558201058201056}, 'calibration': {'slope': 0.7879590376317025, 'intercept': 0.29273292580225074}, 'clinical_usefulness': {'treated': -0.677966101694915, 'treated_all': -2.014001473839351, 'untreated': 0.5725865880619012, 'overall': -0.10537951363301379, 'prevalence': 0.09579955784819455, 'adapt': 0.19742078113485628, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.191240999999991, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=536\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=1222\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 405.02ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 0, 19, 984076)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17491166077738515, 'recall': 0.7557251908396947, 'f1-score': 0.28407460545193686, 'support': 131.0, 'confusion_matrix': [[759, 467], [32, 99]], 'auc': 0.7541187751391604, 'n': 1357, 'tn': 759, 'fp': 467, 'fn': 32, 'tp': 99, 'dor': 5.028171841541756}, 'calibration': {'slope': 0.9041086608850751, 'intercept': 0.24387213576197592}, 'clinical_usefulness': {'treated': -0.730041758781626, 'treated_all': -2.011545074920167, 'untreated': 0.5492157069165174, 'overall': -0.18082605186510858, 'prevalence': 0.09653647752394989, 'adapt': 0.16543846720707436, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.4493490000004385, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4904\n",
      "Class:1.0/N=521\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4904\n",
      "Class:1.0/N=2452\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 229.079ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 0, 26, 972062)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2903225806451613, 'recall': 0.6164383561643836, 'f1-score': 0.3947368421052632, 'support': 146.0, 'confusion_matrix': [[991, 220], [56, 90]], 'auc': 0.7949928169858489, 'n': 1357, 'tn': 991, 'fp': 220, 'fn': 56, 'tp': 90, 'dor': 7.239448051948052}, 'calibration': {'slope': 1.7962827708124371, 'intercept': 0.19237412226183032}, 'clinical_usefulness': {'treated': -0.3119626627364283, 'treated_all': -1.9746990911323994, 'untreated': 0.7126013264554163, 'overall': 0.400638663718988, 'prevalence': 0.10759027266028003, 'adapt': 0.4052321296978629, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.236315000000104, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=536\n",
      "Class:0.0/N=4889\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=2444\n",
      "Class:0.0/N=4889\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 889.067ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 0, 34, 66857)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17580340264650285, 'recall': 0.7099236641221374, 'f1-score': 0.2818181818181818, 'support': 131.0, 'confusion_matrix': [[790, 436], [38, 93]], 'auc': 0.7260220664234212, 'n': 1357, 'tn': 790, 'fp': 436, 'fn': 38, 'tp': 93, 'dor': 4.434451955577016}, 'calibration': {'slope': 0.6626929671790669, 'intercept': 0.34431785489715894}, 'clinical_usefulness': {'treated': -0.6811594202898549, 'treated_all': -2.011545074920167, 'untreated': 0.570165280555848, 'overall': -0.11099413973400685, 'prevalence': 0.09653647752394989, 'adapt': 0.19476787030213713, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.930276000000049, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=530\n",
      "Class:0.0/N=4895\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=2447\n",
      "Class:0.0/N=4895\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 312.583ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 0, 41, 169512)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17142857142857143, 'recall': 0.7007299270072993, 'f1-score': 0.27546628407460544, 'support': 137.0, 'confusion_matrix': [[756, 464], [41, 96]], 'auc': 0.7182362091659686, 'n': 1357, 'tn': 756, 'fp': 464, 'fn': 41, 'tp': 96, 'dor': 3.8149705634987385}, 'calibration': {'slope': 1.3740448703582333, 'intercept': 0.2551591198982859}, 'clinical_usefulness': {'treated': -0.7270940800786045, 'treated_all': -1.9968066814050593, 'untreated': 0.5441625434256238, 'overall': -0.1829315366529808, 'prevalence': 0.10095799557848195, 'adapt': 0.1627855563743552, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.360861999999997, 'explain': 2.2000000171829015e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4904\n",
      "Class:1.0/N=521\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4904\n",
      "Class:1.0/N=2452\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 584.699ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 0, 47, 577447)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18057921635434412, 'recall': 0.726027397260274, 'f1-score': 0.2892223738062756, 'support': 146.0, 'confusion_matrix': [[730, 481], [40, 106]], 'auc': 0.731117722249245, 'n': 1357, 'tn': 730, 'fp': 481, 'fn': 40, 'tp': 106, 'dor': 4.021829521829522}, 'calibration': {'slope': 1.0061829791133765, 'intercept': 0.2505137286549275}, 'clinical_usefulness': {'treated': -0.7489560304593464, 'treated_all': -1.9746990911323994, 'untreated': 0.5253184545741657, 'overall': -0.22363757588518074, 'prevalence': 0.10759027266028003, 'adapt': 0.14303610906411202, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.629861999999775, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4921\n",
      "Class:1.0/N=504\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4921\n",
      "Class:1.0/N=2460\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 992.941ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 0, 54, 409905)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.24165029469548133, 'recall': 0.754601226993865, 'f1-score': 0.36607142857142855, 'support': 163.0, 'confusion_matrix': [[808, 386], [40, 123]], 'auc': 0.8085237023563625, 'n': 1357, 'tn': 808, 'fp': 386, 'fn': 40, 'tp': 123, 'dor': 6.436787564766839}, 'calibration': {'slope': 0.9309055407560419, 'intercept': 0.2748918357797279}, 'clinical_usefulness': {'treated': -0.5730778678457381, 'treated_all': -1.9329403095062634, 'untreated': 0.5827981892830825, 'overall': 0.00972032143734436, 'prevalence': 0.12011790714812086, 'adapt': 0.23603537214443626, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.000676000000112, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=529\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=3672\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 846.63ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 1, 2, 337893)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.29354838709677417, 'recall': 0.6594202898550725, 'f1-score': 0.40625, 'support': 138.0, 'confusion_matrix': [[1000, 219], [47, 91]], 'auc': 0.8050076684381353, 'n': 1357, 'tn': 1000, 'fp': 219, 'fn': 47, 'tp': 91, 'dor': 8.840959875643641}, 'calibration': {'slope': 1.5680953100683872, 'intercept': 0.22725288918009967}, 'clinical_usefulness': {'treated': -0.30950626381724383, 'treated_all': -1.9943502824858752, 'untreated': 0.7220760080008422, 'overall': 0.4125697441835983, 'prevalence': 0.1016949152542373, 'adapt': 0.4126013264554163, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.887867000000369, 'explain': 3.399999968678458e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4899\n",
      "Class:1.0/N=526\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4899\n",
      "Class:1.0/N=3674\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 29.574ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 1, 10, 192346)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21264367816091953, 'recall': 0.7872340425531915, 'f1-score': 0.334841628959276, 'support': 141.0, 'confusion_matrix': [[805, 411], [30, 111]], 'auc': 0.7910484322508399, 'n': 1357, 'tn': 805, 'fp': 411, 'fn': 30, 'tp': 111, 'dor': 7.246958637469587}, 'calibration': {'slope': 0.8019672738215252, 'intercept': 0.30396241442912153}, 'clinical_usefulness': {'treated': -0.6249078850405305, 'treated_all': -1.9869810857283219, 'untreated': 0.583745657437625, 'overall': -0.041162227602905554, 'prevalence': 0.10390567428150331, 'adapt': 0.22114959469417828, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.074059000000034, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4900\n",
      "Class:1.0/N=525\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4900\n",
      "Class:1.0/N=3675\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 324.769ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 1, 17, 338449)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1961904761904762, 'recall': 0.7253521126760564, 'f1-score': 0.30884557721139433, 'support': 142.0, 'confusion_matrix': [[793, 422], [39, 103]], 'auc': 0.7397583029038428, 'n': 1357, 'tn': 793, 'fp': 422, 'fn': 39, 'tp': 103, 'dor': 4.9628751974723535}, 'calibration': {'slope': 0.8583661628556122, 'intercept': 0.2941592152785605}, 'clinical_usefulness': {'treated': -0.6497175141242938, 'treated_all': -1.9845246868091375, 'untreated': 0.5720602168649331, 'overall': -0.07765729725936066, 'prevalence': 0.10464259395725865, 'adapt': 0.205526897568165, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.3722240000001875, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=536\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=3666\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 654.26ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 1, 24, 812963)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1651705565529623, 'recall': 0.7022900763358778, 'f1-score': 0.2674418604651163, 'support': 131.0, 'confusion_matrix': [[761, 465], [39, 92]], 'auc': 0.7157360248060471, 'n': 1357, 'tn': 761, 'fp': 465, 'fn': 39, 'tp': 92, 'dor': 3.8606010476978216}, 'calibration': {'slope': 1.3417244959415155, 'intercept': 0.2645944422120538}, 'clinical_usefulness': {'treated': -0.7317612380250551, 'treated_all': -2.011545074920167, 'untreated': 0.5484787872407622, 'overall': -0.18328245078429295, 'prevalence': 0.09653647752394989, 'adapt': 0.1644067796610169, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.662932000000183, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4878\n",
      "Class:1.0/N=547\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4878\n",
      "Class:1.0/N=3658\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 36.098ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 1, 31, 685397)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.14981949458483754, 'recall': 0.6916666666666667, 'f1-score': 0.2462908011869436, 'support': 120.0, 'confusion_matrix': [[766, 471], [37, 83]], 'auc': 0.6731743465373214, 'n': 1357, 'tn': 766, 'fp': 471, 'fn': 37, 'tp': 83, 'dor': 3.6482469730877374}, 'calibration': {'slope': 1.1359216845110245, 'intercept': 0.2501298009025692}, 'clinical_usefulness': {'treated': -0.748710390567428, 'treated_all': -2.038565463031196, 'untreated': 0.5527950310559007, 'overall': -0.1959153595115274, 'prevalence': 0.08843036109064112, 'adapt': 0.16234340456890198, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.080930999999964, 'explain': 3.299999980299617e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=530\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=4895\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 552.259ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 1, 39, 62468)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.3120567375886525, 'recall': 0.6423357664233577, 'f1-score': 0.4200477326968974, 'support': 137.0, 'confusion_matrix': [[1026, 194], [49, 88]], 'auc': 0.8105959076223526, 'n': 1357, 'tn': 1026, 'fp': 194, 'fn': 49, 'tp': 88, 'dor': 9.498001262360615}, 'calibration': {'slope': 1.438550398955851, 'intercept': 0.24246143325905956}, 'clinical_usefulness': {'treated': -0.2687300417587816, 'treated_all': -1.9968066814050593, 'untreated': 0.7406042741341194, 'overall': 0.4718742323753378, 'prevalence': 0.10095799557848195, 'adapt': 0.43780397936624915, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.594197000000349, 'explain': 1.7999999727180693e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4894\n",
      "Class:1.0/N=531\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4894\n",
      "Class:1.0/N=4894\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 335.907ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 1, 47, 217546)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17300380228136883, 'recall': 0.6691176470588235, 'f1-score': 0.27492447129909364, 'support': 136.0, 'confusion_matrix': [[786, 435], [45, 91]], 'auc': 0.6931938623115094, 'n': 1357, 'tn': 786, 'fp': 435, 'fn': 45, 'tp': 91, 'dor': 3.653946360153257}, 'calibration': {'slope': 0.8421585706007085, 'intercept': 0.333163705702061}, 'clinical_usefulness': {'treated': -0.6809137803979365, 'treated_all': -1.9992630803242442, 'untreated': 0.5650068428255606, 'overall': -0.11590693757237591, 'prevalence': 0.10022107590272661, 'adapt': 0.19123065585851143, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.389513999999963, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4909\n",
      "Class:1.0/N=516\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4909\n",
      "Class:1.0/N=4909\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 223.83ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 1, 55, 290888)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20075046904315197, 'recall': 0.7086092715231788, 'f1-score': 0.3128654970760234, 'support': 151.0, 'confusion_matrix': [[780, 426], [44, 107]], 'auc': 0.7255554457294104, 'n': 1357, 'tn': 780, 'fp': 426, 'fn': 44, 'tp': 107, 'dor': 4.4526248399487836}, 'calibration': {'slope': 0.5013612690215301, 'intercept': 0.3692400859736724}, 'clinical_usefulness': {'treated': -0.653647752394989, 'treated_all': -1.9624170965364773, 'untreated': 0.5609011474892094, 'overall': -0.09274660490577957, 'prevalence': 0.11127487103905674, 'adapt': 0.19653647752394982, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.273642999999993, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4883\n",
      "Class:1.0/N=542\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4883\n",
      "Class:1.0/N=4883\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 709.321ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 2, 2, 846597)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17477477477477477, 'recall': 0.776, 'f1-score': 0.2852941176470588, 'support': 125.0, 'confusion_matrix': [[774, 458], [28, 97]], 'auc': 0.775698051948052, 'n': 1357, 'tn': 774, 'fp': 458, 'fn': 28, 'tp': 97, 'dor': 5.854491578290705}, 'calibration': {'slope': 0.6490043417929601, 'intercept': 0.4293334787603189}, 'clinical_usefulness': {'treated': -0.7160402849422745, 'treated_all': -2.0262834684352735, 'untreated': 0.5615327929255711, 'overall': -0.15450749201670333, 'prevalence': 0.09211495946941783, 'adapt': 0.17826086956521736, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.751459999999952, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4898\n",
      "Class:1.0/N=527\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4898\n",
      "Class:1.0/N=4898\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 595.822ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 2, 11, 747583)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1977818853974122, 'recall': 0.7642857142857142, 'f1-score': 0.3142437591776798, 'support': 140.0, 'confusion_matrix': [[783, 434], [33, 107]], 'auc': 0.776420354501702, 'n': 1357, 'tn': 783, 'fp': 434, 'fn': 33, 'tp': 107, 'dor': 5.849811478843736}, 'calibration': {'slope': 0.264869258139149, 'intercept': 0.40858363459521796}, 'clinical_usefulness': {'treated': -0.6674035863424218, 'treated_all': -1.9894374846475065, 'untreated': 0.5665859564164648, 'overall': -0.100817629925957, 'prevalence': 0.10316875460574797, 'adapt': 0.19638909358879877, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.637216999999964, 'explain': 2.900000026784255e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4899\n",
      "Class:1.0/N=526\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_adasyn.py\", line 133, in _fit_resample\n",
      "    raise ValueError(\"No samples will be generated with the\"\n",
      "ValueError: No samples will be generated with the provided ratio settings.\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 897.116ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 2, 17, 395125)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.30116959064327486, 'recall': 0.7304964539007093, 'f1-score': 0.4265010351966875, 'support': 141.0, 'confusion_matrix': [[977, 239], [38, 103]], 'auc': 0.7954314809630458, 'n': 1357, 'tn': 977, 'fp': 239, 'fn': 38, 'tp': 103, 'dor': 11.080268663290026}, 'calibration': {'slope': 1.3710103106992422, 'intercept': 0.24946281868548953}, 'clinical_usefulness': {'treated': -0.3350528125767624, 'treated_all': -1.9869810857283219, 'untreated': 0.7079692599220971, 'overall': 0.37291644734533475, 'prevalence': 0.10390567428150331, 'adapt': 0.3950626381724392, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.943678000000091, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4883\n",
      "Class:1.0/N=542\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_adasyn.py\", line 133, in _fit_resample\n",
      "    raise ValueError(\"No samples will be generated with the\"\n",
      "ValueError: No samples will be generated with the provided ratio settings.\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 784.903ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 2, 23, 973259)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1736745886654479, 'recall': 0.76, 'f1-score': 0.28273809523809523, 'support': 125.0, 'confusion_matrix': [[780, 452], [30, 95]], 'auc': 0.7636103896103896, 'n': 1357, 'tn': 780, 'fp': 452, 'fn': 30, 'tp': 95, 'dor': 5.464601769911504}, 'calibration': {'slope': 0.9895608848777618, 'intercept': 0.25834209639558314}, 'clinical_usefulness': {'treated': -0.7071972488332103, 'treated_all': -2.0262834684352735, 'untreated': 0.5653226655437414, 'overall': -0.1418745832894689, 'prevalence': 0.09211495946941783, 'adapt': 0.18356669123065583, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.817803999999796, 'explain': 3.100000003541936e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4876\n",
      "Class:1.0/N=549\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_adasyn.py\", line 133, in _fit_resample\n",
      "    raise ValueError(\"No samples will be generated with the\"\n",
      "ValueError: No samples will be generated with the provided ratio settings.\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 576.306ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 2, 30, 371117)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1705989110707804, 'recall': 0.7966101694915254, 'f1-score': 0.28101644245142, 'support': 118.0, 'confusion_matrix': [[782, 457], [24, 94]], 'auc': 0.7799653903503372, 'n': 1357, 'tn': 782, 'fp': 457, 'fn': 24, 'tp': 94, 'dor': 6.702042304886944}, 'calibration': {'slope': 0.8936977773874664, 'intercept': 0.3439798902261317}, 'clinical_usefulness': {'treated': -0.7165315647261113, 'treated_all': -2.043478260869565, 'untreated': 0.5686914412043373, 'overall': -0.147840123521774, 'prevalence': 0.08695652173913043, 'adapt': 0.18312453942520268, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.621933000000354, 'explain': 2.100000028804061e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4894\n",
      "Class:1.0/N=531\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_adasyn.py\", line 133, in _fit_resample\n",
      "    raise ValueError(\"No samples will be generated with the\"\n",
      "ValueError: No samples will be generated with the provided ratio settings.\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 575.403ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 2, 36, 732367)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18149466192170818, 'recall': 0.75, 'f1-score': 0.2922636103151863, 'support': 136.0, 'confusion_matrix': [[761, 460], [34, 102]], 'auc': 0.7583706701353761, 'n': 1357, 'tn': 761, 'fp': 460, 'fn': 34, 'tp': 102, 'dor': 4.963043478260869}, 'calibration': {'slope': 0.7164567342216563, 'intercept': 0.32389857057225624}, 'clinical_usefulness': {'treated': -0.715794645050356, 'treated_all': -1.9992630803242442, 'untreated': 0.5500579008316664, 'overall': -0.16573674421868956, 'prevalence': 0.10022107590272661, 'adapt': 0.17030213706705966, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.619704000000183, 'explain': 2.500000027794158e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4891\n",
      "Class:1.0/N=534\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_adasyn.py\", line 133, in _fit_resample\n",
      "    raise ValueError(\"No samples will be generated with the\"\n",
      "ValueError: No samples will be generated with the provided ratio settings.\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 840.145ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 2, 43, 570381)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1970260223048327, 'recall': 0.7969924812030075, 'f1-score': 0.31594634873323396, 'support': 133.0, 'confusion_matrix': [[792, 432], [27, 106]], 'auc': 0.7825200255540814, 'n': 1357, 'tn': 792, 'fp': 432, 'fn': 27, 'tp': 106, 'dor': 7.197530864197532}, 'calibration': {'slope': 0.9678765554913619, 'intercept': 0.3188616651212859}, 'clinical_usefulness': {'treated': -0.6647015475313188, 'treated_all': -2.0066322770817977, 'untreated': 0.5751131698073482, 'overall': -0.08958837772397066, 'prevalence': 0.09801031687546058, 'adapt': 0.20316875460574801, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.880135999999766, 'explain': 2.300000005561742e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4886\n",
      "Class:1.0/N=539\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4886\n",
      "Class:1.0/N=1278\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 260.125ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 2, 49, 739684)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.26453488372093026, 'recall': 0.7109375, 'f1-score': 0.3855932203389831, 'support': 128.0, 'confusion_matrix': [[976, 253], [37, 91]], 'auc': 0.8268027868185517, 'n': 1357, 'tn': 976, 'fp': 253, 'fn': 37, 'tp': 91, 'dor': 9.487875227005661}, 'calibration': {'slope': 1.3940838796661437, 'intercept': 0.2661422612173731}, 'clinical_usefulness': {'treated': -0.3679685580938344, 'treated_all': -2.01891427167772, 'untreated': 0.7075481629645226, 'overall': 0.3395796048706882, 'prevalence': 0.09432571849668386, 'adapt': 0.38489314664701546, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.302469000000201, 'explain': 2.100000028804061e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=530\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=1251\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 798.093ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 2, 57, 466927)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19408502772643252, 'recall': 0.7664233576642335, 'f1-score': 0.3097345132743362, 'support': 137.0, 'confusion_matrix': [[784, 436], [32, 105]], 'auc': 0.7514359219815724, 'n': 1357, 'tn': 784, 'fp': 436, 'fn': 32, 'tp': 105, 'dor': 5.900229357798166}, 'calibration': {'slope': 0.8824699615486047, 'intercept': 0.3406930492596776}, 'clinical_usefulness': {'treated': -0.6723163841807908, 'treated_all': -1.9968066814050593, 'untreated': 0.5676386988104011, 'overall': -0.10467768537038968, 'prevalence': 0.10095799557848195, 'adapt': 0.1956521739130435, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.848597000000154, 'explain': 2.6000000161729986e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4897\n",
      "Class:1.0/N=528\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4897\n",
      "Class:1.0/N=1227\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 132.415ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 3, 5, 457901)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20106761565836298, 'recall': 0.8129496402877698, 'f1-score': 0.3223965763195435, 'support': 139.0, 'confusion_matrix': [[769, 449], [26, 113]], 'auc': 0.7807527377113087, 'n': 1357, 'tn': 769, 'fp': 449, 'fn': 26, 'tp': 113, 'dor': 7.443635429158815}, 'calibration': {'slope': 0.7885987494359259, 'intercept': 0.2906263781451667}, 'clinical_usefulness': {'treated': -0.6887742569393268, 'treated_all': -1.9918938835666908, 'untreated': 0.5584798399831561, 'overall': -0.13029441695617072, 'prevalence': 0.10243183492999262, 'adapt': 0.18430361090641115, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.201712000000043, 'explain': 1.9999999949504854e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4881\n",
      "Class:1.0/N=544\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4881\n",
      "Class:1.0/N=1277\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 925.578ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 3, 11, 272388)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19428571428571428, 'recall': 0.8292682926829268, 'f1-score': 0.3148148148148148, 'support': 123.0, 'confusion_matrix': [[811, 423], [21, 102]], 'auc': 0.7965206677998709, 'n': 1357, 'tn': 811, 'fp': 423, 'fn': 21, 'tp': 102, 'dor': 9.312394461330632}, 'calibration': {'slope': 1.020894642760467, 'intercept': 0.32607755704950353}, 'clinical_usefulness': {'treated': -0.6521739130434782, 'treated_all': -2.0311962662736427, 'untreated': 0.5910095799557848, 'overall': -0.06116433308769331, 'prevalence': 0.09064112011790715, 'adapt': 0.21805453205600586, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.9323850000000675, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=537\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=1263\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 544.931ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 3, 17, 702278)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1860036832412523, 'recall': 0.7769230769230769, 'f1-score': 0.300148588410104, 'support': 130.0, 'confusion_matrix': [[785, 442], [29, 101]], 'auc': 0.7861074540781142, 'n': 1357, 'tn': 785, 'fp': 442, 'fn': 29, 'tp': 101, 'dor': 6.185442346699953}, 'calibration': {'slope': 0.5929784284203781, 'intercept': 0.38993381585807396}, 'clinical_usefulness': {'treated': -0.6855809383443869, 'treated_all': -2.014001473839351, 'untreated': 0.569323086640699, 'overall': -0.11625785170368796, 'prevalence': 0.09579955784819455, 'adapt': 0.19285187914517318, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.5879329999997935, 'explain': 2.5999999706982635e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4883\n",
      "Class:1.0/N=542\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4883\n",
      "Class:1.0/N=2604\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 665.597ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 3, 24, 317763)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.23615160349854228, 'recall': 0.648, 'f1-score': 0.34615384615384615, 'support': 125.0, 'confusion_matrix': [[970, 262], [44, 81]], 'auc': 0.7924448051948052, 'n': 1357, 'tn': 970, 'fp': 262, 'fn': 44, 'tp': 81, 'dor': 6.81557945870923}, 'calibration': {'slope': 1.8083810967810512, 'intercept': 0.24236495740870795}, 'clinical_usefulness': {'treated': -0.39081306804225, 'treated_all': -2.0262834684352735, 'untreated': 0.7009158858827245, 'overall': 0.31010281784047444, 'prevalence': 0.09211495946941783, 'adapt': 0.3733971997052321, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.673322000000553, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=546\n",
      "Class:0.0/N=4879\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=2647\n",
      "Class:0.0/N=4879\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 21.395ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 3, 31, 201551)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1651705565529623, 'recall': 0.7603305785123967, 'f1-score': 0.2713864306784661, 'support': 121.0, 'confusion_matrix': [[771, 465], [29, 92]], 'auc': 0.7600564337104495, 'n': 1357, 'tn': 771, 'fp': 465, 'fn': 29, 'tp': 92, 'dor': 5.260066740823137}, 'calibration': {'slope': 0.9752924238945297, 'intercept': 0.35507660107203803}, 'clinical_usefulness': {'treated': -0.7317612380250551, 'treated_all': -2.036109064112011, 'untreated': 0.5590062111801242, 'overall': -0.17275502684493094, 'prevalence': 0.08916728076639646, 'adapt': 0.17177597641857034, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.065847999999278, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4887\n",
      "Class:1.0/N=538\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4887\n",
      "Class:1.0/N=2617\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 810.681ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 3, 37, 839852)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17918088737201365, 'recall': 0.813953488372093, 'f1-score': 0.2937062937062937, 'support': 129.0, 'confusion_matrix': [[747, 481], [24, 105]], 'auc': 0.7625116784082014, 'n': 1357, 'tn': 747, 'fp': 481, 'fn': 24, 'tp': 105, 'dor': 6.79443866943867}, 'calibration': {'slope': 0.7183467459852261, 'intercept': 0.3105980848652271}, 'clinical_usefulness': {'treated': -0.7496929501351018, 'treated_all': -2.016457872758535, 'untreated': 0.5428992525529003, 'overall': -0.20679369758220156, 'prevalence': 0.0950626381724392, 'adapt': 0.15512159174649962, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.817831999999726, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4906\n",
      "Class:1.0/N=519\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4906\n",
      "Class:1.0/N=2535\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 344.352ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 3, 45, 226002)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18065693430656934, 'recall': 0.668918918918919, 'f1-score': 0.28448275862068967, 'support': 148.0, 'confusion_matrix': [[760, 449], [49, 99]], 'auc': 0.7016101088681733, 'n': 1357, 'tn': 760, 'fp': 449, 'fn': 49, 'tp': 99, 'dor': 3.4198445525203396}, 'calibration': {'slope': 0.9997127565006199, 'intercept': 0.27408797368953125}, 'clinical_usefulness': {'treated': -0.6990911323999016, 'treated_all': -1.9697862932940307, 'untreated': 0.5445836403831983, 'overall': -0.15450749201670333, 'prevalence': 0.10906411201179071, 'adapt': 0.1714812085482683, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.386765000000196, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4898\n",
      "Class:1.0/N=527\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4898\n",
      "Class:1.0/N=2543\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 641.96ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 3, 51, 777125)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18312387791741472, 'recall': 0.7285714285714285, 'f1-score': 0.2926829268292683, 'support': 140.0, 'confusion_matrix': [[762, 455], [38, 102]], 'auc': 0.733604296278906, 'n': 1357, 'tn': 762, 'fp': 455, 'fn': 38, 'tp': 102, 'dor': 4.4953152111046855}, 'calibration': {'slope': 0.7400854444780646, 'intercept': 0.36672516798497123}, 'clinical_usefulness': {'treated': -0.7071972488332103, 'treated_all': -1.9894374846475065, 'untreated': 0.5495315296346984, 'overall': -0.1576657191985119, 'prevalence': 0.10316875460574797, 'adapt': 0.17251289609432574, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.685671000000184, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4883\n",
      "Class:1.0/N=542\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4883\n",
      "Class:1.0/N=3498\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 841.924ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 3, 59, 561013)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.24571428571428572, 'recall': 0.688, 'f1-score': 0.3621052631578947, 'support': 125.0, 'confusion_matrix': [[968, 264], [39, 86]], 'auc': 0.8139642857142857, 'n': 1357, 'tn': 968, 'fp': 264, 'fn': 39, 'tp': 86, 'dor': 8.085470085470085}, 'calibration': {'slope': 1.517571028728665, 'intercept': 0.2792088023492162}, 'clinical_usefulness': {'treated': -0.3905674281503316, 'treated_all': -2.0262834684352735, 'untreated': 0.7010211601221181, 'overall': 0.31045373197178655, 'prevalence': 0.09211495946941783, 'adapt': 0.3735445836403832, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.88184100000035, 'explain': 3.100000049016671e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4901\n",
      "Class:1.0/N=524\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4901\n",
      "Class:1.0/N=3749\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 906.984ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 4, 7, 796115)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21455223880597016, 'recall': 0.8041958041958042, 'f1-score': 0.3387334315169367, 'support': 143.0, 'confusion_matrix': [[793, 421], [28, 115]], 'auc': 0.7983519775117799, 'n': 1357, 'tn': 793, 'fp': 421, 'fn': 28, 'tp': 115, 'dor': 7.736257210722769}, 'calibration': {'slope': 0.43053043928511586, 'intercept': 0.48607793025963775}, 'clinical_usefulness': {'treated': -0.6391549987718005, 'treated_all': -1.9820682878899532, 'untreated': 0.5755342667649226, 'overall': -0.0636207320068779, 'prevalence': 0.105379513633014, 'adapt': 0.2111274871039056, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.944778999999471, 'explain': 2.0000000404252205e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4890\n",
      "Class:1.0/N=535\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4890\n",
      "Class:1.0/N=3826\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 164.639ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 4, 15, 315796)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1930783242258652, 'recall': 0.803030303030303, 'f1-score': 0.31130690161527164, 'support': 132.0, 'confusion_matrix': [[782, 443], [26, 106]], 'auc': 0.7937260358688929, 'n': 1357, 'tn': 782, 'fp': 443, 'fn': 26, 'tp': 106, 'dor': 7.196735544365341}, 'calibration': {'slope': 0.6909679162290681, 'intercept': 0.32181334622458674}, 'clinical_usefulness': {'treated': -0.6836158192090394, 'treated_all': -2.009088676000982, 'untreated': 0.5680597957679756, 'overall': -0.11555602344106375, 'prevalence': 0.09727339719970524, 'adapt': 0.1925571112748711, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.207495999999992, 'explain': 3.099999958067201e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=540\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=3539\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 357.103ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 4, 22, 486090)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1705989110707804, 'recall': 0.7401574803149606, 'f1-score': 0.27728613569321536, 'support': 127.0, 'confusion_matrix': [[773, 457], [33, 94]], 'auc': 0.7453908200499328, 'n': 1357, 'tn': 773, 'fp': 457, 'fn': 33, 'tp': 94, 'dor': 4.818115509581593}, 'calibration': {'slope': 0.7817364820792957, 'intercept': 0.3220280341071721}, 'clinical_usefulness': {'treated': -0.7165315647261113, 'treated_all': -2.021370670596905, 'untreated': 0.5592167596589114, 'overall': -0.15731480506719997, 'prevalence': 0.09358879882092852, 'adapt': 0.17649226234340448, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.3893400000006295, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4910\n",
      "Class:1.0/N=515\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4910\n",
      "Class:1.0/N=3686\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 252.124ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 4, 29, 609677)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19117647058823528, 'recall': 0.6842105263157895, 'f1-score': 0.29885057471264365, 'support': 152.0, 'confusion_matrix': [[765, 440], [48, 104]], 'auc': 0.7232037562786635, 'n': 1357, 'tn': 765, 'fp': 440, 'fn': 48, 'tp': 104, 'dor': 3.7670454545454546}, 'calibration': {'slope': 0.8828504105428919, 'intercept': 0.26812862588986497}, 'clinical_usefulness': {'treated': -0.6799312208302626, 'treated_all': -1.9599606976172925, 'untreated': 0.5485840614801557, 'overall': -0.13134715935010688, 'prevalence': 0.11201179071481208, 'adapt': 0.18002947678703018, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.260186000000431, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=538\n",
      "Class:0.0/N=4887\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=4774\n",
      "Class:0.0/N=4887\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 17.407ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 4, 36, 466002)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.29376854599406527, 'recall': 0.7674418604651163, 'f1-score': 0.4248927038626609, 'support': 129.0, 'confusion_matrix': [[990, 238], [30, 99]], 'auc': 0.8320013635330656, 'n': 1357, 'tn': 990, 'fp': 238, 'fn': 30, 'tp': 99, 'dor': 13.726890756302522}, 'calibration': {'slope': 1.409000590508037, 'intercept': 0.25893953336436865}, 'clinical_usefulness': {'treated': -0.33628101203635463, 'treated_all': -2.016457872758535, 'untreated': 0.7200757974523634, 'overall': 0.38379478541600875, 'prevalence': 0.0950626381724392, 'adapt': 0.40316875460574797, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.059580000000096, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=515\n",
      "Class:0.0/N=4910\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=4991\n",
      "Class:0.0/N=4910\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 791.471ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 4, 44, 87267)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1956124314442413, 'recall': 0.7039473684210527, 'f1-score': 0.30615164520743915, 'support': 152.0, 'confusion_matrix': [[765, 440], [45, 107]], 'auc': 0.742380978379559, 'n': 1357, 'tn': 765, 'fp': 440, 'fn': 45, 'tp': 107, 'dor': 4.13409090909091}, 'calibration': {'slope': 0.8518828829558273, 'intercept': 0.2979464629659647}, 'clinical_usefulness': {'treated': -0.6777204618029966, 'treated_all': -1.9599606976172925, 'untreated': 0.5495315296346983, 'overall': -0.1281889321682983, 'prevalence': 0.11201179071481208, 'adapt': 0.18135593220338977, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.839777999999569, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4899\n",
      "Class:1.0/N=526\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4899\n",
      "Class:1.0/N=4932\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 247.543ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 4, 52, 172858)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20566037735849058, 'recall': 0.7730496453900709, 'f1-score': 0.3248882265275708, 'support': 141.0, 'confusion_matrix': [[795, 421], [32, 109]], 'auc': 0.7719064949608061, 'n': 1357, 'tn': 795, 'fp': 421, 'fn': 32, 'tp': 109, 'dor': 6.4322298099762465}, 'calibration': {'slope': 0.6094818976530433, 'intercept': 0.3302019945255651}, 'clinical_usefulness': {'treated': -0.6435765168263325, 'treated_all': -1.9869810857283219, 'untreated': 0.5757448152437098, 'overall': -0.06783170158262275, 'prevalence': 0.10390567428150331, 'adapt': 0.20994841562269706, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.289040999999997, 'explain': 3.500000002532033e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4897\n",
      "Class:1.0/N=528\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4897\n",
      "Class:1.0/N=4977\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 593.175ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 5, 0, 624686)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1977401129943503, 'recall': 0.7553956834532374, 'f1-score': 0.3134328358208955, 'support': 139.0, 'confusion_matrix': [[792, 426], [34, 105]], 'auc': 0.7515622969604612, 'n': 1357, 'tn': 792, 'fp': 426, 'fn': 34, 'tp': 105, 'dor': 5.741507870753936}, 'calibration': {'slope': 0.7416991007898198, 'intercept': 0.33883882832131496}, 'clinical_usefulness': {'treated': -0.6551215917464996, 'treated_all': -1.9918938835666908, 'untreated': 0.5729024107800821, 'overall': -0.08221918096641756, 'prevalence': 0.10243183492999262, 'adapt': 0.20449521002210752, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.638396000000284, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4898\n",
      "Class:1.0/N=527\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4898\n",
      "Class:1.0/N=4873\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 802.598ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 5, 9, 306073)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20408163265306123, 'recall': 0.7857142857142857, 'f1-score': 0.3240058910162003, 'support': 140.0, 'confusion_matrix': [[788, 429], [30, 110]], 'auc': 0.7905505341002464, 'n': 1357, 'tn': 788, 'fp': 429, 'fn': 30, 'tp': 110, 'dor': 6.735042735042734}, 'calibration': {'slope': 0.4722710200882477, 'intercept': 0.38335584190123184}, 'clinical_usefulness': {'treated': -0.6565954310980102, 'treated_all': -1.9894374846475065, 'untreated': 0.5712180229497842, 'overall': -0.08537740814822603, 'prevalence': 0.10316875460574797, 'adapt': 0.2028739867354458, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.810107000000244, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4893\n",
      "Class:1.0/N=532\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_random_over_sampler.py\", line 111, in _fit_resample\n",
      "    low=0, high=target_stats[class_sample], size=num_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 587.328ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 5, 14, 368344)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.30793650793650795, 'recall': 0.7185185185185186, 'f1-score': 0.43111111111111117, 'support': 135.0, 'confusion_matrix': [[1004, 218], [38, 97]], 'auc': 0.8353276353276353, 'n': 1357, 'tn': 1004, 'fp': 218, 'fn': 38, 'tp': 97, 'dor': 11.756156446161274}, 'calibration': {'slope': 1.2976197581812285, 'intercept': 0.27306019623928457}, 'clinical_usefulness': {'treated': -0.30336526651928264, 'treated_all': -2.001719479243429, 'untreated': 0.7278660911674913, 'overall': 0.4245008246482087, 'prevalence': 0.09948415622697127, 'adapt': 0.41849668386145916, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.623354999999719, 'explain': 2.0000000404252205e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4890\n",
      "Class:1.0/N=535\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_random_over_sampler.py\", line 111, in _fit_resample\n",
      "    low=0, high=target_stats[class_sample], size=num_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 497.041ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 5, 20, 357047)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.16725978647686832, 'recall': 0.7121212121212122, 'f1-score': 0.27089337175792505, 'support': 132.0, 'confusion_matrix': [[757, 468], [38, 94]], 'auc': 0.7206617192331479, 'n': 1357, 'tn': 757, 'fp': 468, 'fn': 38, 'tp': 94, 'dor': 4.0012370670265405}, 'calibration': {'slope': 0.776099538901922, 'intercept': 0.3277881511662105}, 'clinical_usefulness': {'treated': -0.7354458364038318, 'treated_all': -2.009088676000982, 'untreated': 0.5458469312559217, 'overall': -0.1895989051479101, 'prevalence': 0.09727339719970524, 'adapt': 0.1614591009579956, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.5378890000001775, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=529\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_random_over_sampler.py\", line 111, in _fit_resample\n",
      "    low=0, high=target_stats[class_sample], size=num_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 788.883ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 5, 25, 857552)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18558558558558558, 'recall': 0.7463768115942029, 'f1-score': 0.2972582972582973, 'support': 138.0, 'confusion_matrix': [[767, 452], [35, 103]], 'auc': 0.7471971561389117, 'n': 1357, 'tn': 767, 'fp': 452, 'fn': 35, 'tp': 103, 'dor': 4.993742098609355}, 'calibration': {'slope': 0.7001657661249779, 'intercept': 0.3611987776391716}, 'clinical_usefulness': {'treated': -0.7013018914271676, 'treated_all': -1.9943502824858752, 'untreated': 0.5541635961680177, 'overall': -0.1471382952591499, 'prevalence': 0.1016949152542373, 'adapt': 0.17752394988946202, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.826958999999988, 'explain': 2.299999960087007e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=536\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_random_over_sampler.py\", line 111, in _fit_resample\n",
      "    low=0, high=target_stats[class_sample], size=num_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 227.332ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 5, 31, 582005)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1871559633027523, 'recall': 0.7786259541984732, 'f1-score': 0.30177514792899407, 'support': 131.0, 'confusion_matrix': [[783, 443], [29, 102]], 'auc': 0.7874550141339676, 'n': 1357, 'tn': 783, 'fp': 443, 'fn': 29, 'tp': 102, 'dor': 6.216704288939052}, 'calibration': {'slope': 1.0611969999638275, 'intercept': 0.26203672447147497}, 'clinical_usefulness': {'treated': -0.6865634979120607, 'treated_all': -2.011545074920167, 'untreated': 0.5678492472891883, 'overall': -0.11871425062287244, 'prevalence': 0.09653647752394989, 'adapt': 0.19152542372881357, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.264168000000609, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4902\n",
      "Class:1.0/N=523\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_random_over_sampler.py\", line 111, in _fit_resample\n",
      "    low=0, high=target_stats[class_sample], size=num_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 513.311ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 5, 37, 79104)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21206225680933852, 'recall': 0.7569444444444444, 'f1-score': 0.33130699088145893, 'support': 144.0, 'confusion_matrix': [[808, 405], [35, 109]], 'auc': 0.7695051296143629, 'n': 1357, 'tn': 808, 'fp': 405, 'fn': 35, 'tp': 109, 'dor': 6.213192239858907}, 'calibration': {'slope': 0.8174893275908761, 'intercept': 0.28993299545820805}, 'clinical_usefulness': {'treated': -0.6160648489314664, 'treated_all': -1.9796118889707683, 'untreated': 0.5843773028739868, 'overall': -0.03168754605747959, 'prevalence': 0.10611643330876934, 'adapt': 0.22424465733235083, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.555374000000484, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=537\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=1222\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 416.341ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 5, 43, 935)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2779552715654952, 'recall': 0.6692307692307692, 'f1-score': 0.39277652370203153, 'support': 130.0, 'confusion_matrix': [[1001, 226], [43, 87]], 'auc': 0.8107955614068084, 'n': 1357, 'tn': 1001, 'fp': 226, 'fn': 43, 'tp': 87, 'dor': 8.961411813130272}, 'calibration': {'slope': 1.3515725012980921, 'intercept': 0.265694277430336}, 'clinical_usefulness': {'treated': -0.32449029722426914, 'treated_all': -2.014001473839351, 'untreated': 0.7240762185493209, 'overall': 0.3995859213250518, 'prevalence': 0.09579955784819455, 'adapt': 0.40950626381724387, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.45736399999987, 'explain': 1.7999999727180693e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4872\n",
      "Class:1.0/N=553\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4872\n",
      "Class:1.0/N=1218\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 690.219ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 5, 49, 247057)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1464226289517471, 'recall': 0.7719298245614035, 'f1-score': 0.24615384615384617, 'support': 114.0, 'confusion_matrix': [[730, 513], [26, 88]], 'auc': 0.7501058559512216, 'n': 1357, 'tn': 730, 'fp': 513, 'fn': 26, 'tp': 88, 'dor': 4.8163142899985}, 'calibration': {'slope': 0.9470241223818833, 'intercept': 0.30254233539325676}, 'clinical_usefulness': {'treated': -0.8172439204126749, 'treated_all': -2.0533038565463024, 'untreated': 0.5297399726286978, 'overall': -0.28750394778397714, 'prevalence': 0.08400884303610906, 'adapt': 0.12564480471628592, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.729566999999406, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4881\n",
      "Class:1.0/N=544\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4881\n",
      "Class:1.0/N=1220\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 780.307ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 5, 54, 538437)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1717902350813743, 'recall': 0.7723577235772358, 'f1-score': 0.2810650887573964, 'support': 123.0, 'confusion_matrix': [[776, 458], [28, 95]], 'auc': 0.7610059163800714, 'n': 1357, 'tn': 776, 'fp': 458, 'fn': 28, 'tp': 95, 'dor': 5.748596381784155}, 'calibration': {'slope': 0.7533931742008023, 'intercept': 0.43528951574607394}, 'clinical_usefulness': {'treated': -0.7175141242937851, 'treated_all': -2.0311962662736427, 'untreated': 0.5630066322770818, 'overall': -0.15450749201670333, 'prevalence': 0.09064112011790715, 'adapt': 0.17885040530582164, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.821030999999493, 'explain': 1.7999999727180693e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4873\n",
      "Class:1.0/N=552\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4873\n",
      "Class:1.0/N=1218\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 572.333ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 6, 0, 657677)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.16725978647686832, 'recall': 0.8173913043478261, 'f1-score': 0.27769571639586405, 'support': 115.0, 'confusion_matrix': [[774, 468], [21, 94]], 'auc': 0.7957081845550655, 'n': 1357, 'tn': 774, 'fp': 468, 'fn': 21, 'tp': 94, 'dor': 7.402930402930403}, 'calibration': {'slope': 0.7393828986198201, 'intercept': 0.33477400719546146}, 'clinical_usefulness': {'treated': -0.7354458364038318, 'treated_all': -2.0508474576271185, 'untreated': 0.5637435519528372, 'overall': -0.17170228445099456, 'prevalence': 0.0847457627118644, 'adapt': 0.17398673544583648, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.525677999999971, 'explain': 3.7000000702391844e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4906\n",
      "Class:1.0/N=519\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4906\n",
      "Class:1.0/N=1226\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 640.937ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 6, 8, 7042)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21550094517958412, 'recall': 0.7702702702702703, 'f1-score': 0.33677991137370755, 'support': 148.0, 'confusion_matrix': [[794, 415], [34, 114]], 'auc': 0.7793659043659042, 'n': 1357, 'tn': 794, 'fp': 415, 'fn': 34, 'tp': 114, 'dor': 6.415024805102764}, 'calibration': {'slope': 0.7804524178447716, 'intercept': 0.3200177596228956}, 'clinical_usefulness': {'treated': -0.6295750429869811, 'treated_all': -1.9697862932940307, 'untreated': 0.5743762501315928, 'overall': -0.05519879285538831, 'prevalence': 0.10906411201179071, 'adapt': 0.21319086219602057, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.601352000000588, 'explain': 2.0000000404252205e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=536\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=2444\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 296.239ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 6, 14, 859916)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.304635761589404, 'recall': 0.7022900763358778, 'f1-score': 0.4249422632794457, 'support': 131.0, 'confusion_matrix': [[1016, 210], [39, 92]], 'auc': 0.8227089897015055, 'n': 1357, 'tn': 1016, 'fp': 210, 'fn': 39, 'tp': 92, 'dor': 11.412942612942613}, 'calibration': {'slope': 1.3958008479265434, 'intercept': 0.24259804422840658}, 'clinical_usefulness': {'treated': -0.2932940309506264, 'treated_all': -2.011545074920167, 'untreated': 0.7363933045583746, 'overall': 0.4430992736077482, 'prevalence': 0.09653647752394989, 'adapt': 0.42748710390567424, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.291780000000472, 'explain': 2.0000000404252205e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4883\n",
      "Class:1.0/N=542\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4883\n",
      "Class:1.0/N=2441\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 224.647ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 6, 20, 580909)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.16071428571428573, 'recall': 0.72, 'f1-score': 0.26277372262773724, 'support': 125.0, 'confusion_matrix': [[762, 470], [35, 90]], 'auc': 0.7175, 'n': 1357, 'tn': 762, 'fp': 470, 'fn': 35, 'tp': 90, 'dor': 4.168996960486322}, 'calibration': {'slope': 0.8725459149139827, 'intercept': 0.36239948616049045}, 'clinical_usefulness': {'treated': -0.7418324735937114, 'treated_all': -2.0262834684352735, 'untreated': 0.550478997789241, 'overall': -0.19135347580447037, 'prevalence': 0.09211495946941783, 'adapt': 0.16278555637435527, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.2631609999998545, 'explain': 2.0000000404252205e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4891\n",
      "Class:1.0/N=534\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4891\n",
      "Class:1.0/N=2445\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 125.536ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 6, 27, 207127)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17907801418439717, 'recall': 0.7593984962406015, 'f1-score': 0.2898134863701578, 'support': 133.0, 'confusion_matrix': [[761, 463], [32, 101]], 'auc': 0.73359255983095, 'n': 1357, 'tn': 761, 'fp': 463, 'fn': 32, 'tp': 101, 'dor': 5.187702483801296}, 'calibration': {'slope': 0.8174054556775628, 'intercept': 0.34457886971278584}, 'clinical_usefulness': {'treated': -0.7216900024563988, 'treated_all': -2.0066322770817977, 'untreated': 0.5506895462680281, 'overall': -0.17100045618837068, 'prevalence': 0.09801031687546058, 'adapt': 0.1689756816507, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.116966000000502, 'explain': 3.500000002532033e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4883\n",
      "Class:1.0/N=542\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4883\n",
      "Class:1.0/N=2441\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 721.7ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 6, 33, 422429)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1681260945709282, 'recall': 0.768, 'f1-score': 0.27586206896551724, 'support': 125.0, 'confusion_matrix': [[757, 475], [29, 96]], 'auc': 0.7343311688311689, 'n': 1357, 'tn': 757, 'fp': 475, 'fn': 29, 'tp': 96, 'dor': 5.275644283121597}, 'calibration': {'slope': 0.9368035020456479, 'intercept': 0.278406261654497}, 'clinical_usefulness': {'treated': -0.7460083517563251, 'treated_all': -2.0262834684352735, 'untreated': 0.5486893357195494, 'overall': -0.1973190160367757, 'prevalence': 0.09211495946941783, 'adapt': 0.160280029476787, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.68109800000002, 'explain': 1.7999999727180693e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4902\n",
      "Class:1.0/N=523\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4902\n",
      "Class:1.0/N=2451\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 224.126ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 6, 41, 148163)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17123287671232876, 'recall': 0.6944444444444444, 'f1-score': 0.2747252747252747, 'support': 144.0, 'confusion_matrix': [[729, 484], [44, 100]], 'auc': 0.7091691856737199, 'n': 1357, 'tn': 729, 'fp': 484, 'fn': 44, 'tp': 100, 'dor': 3.423178061607814}, 'calibration': {'slope': 1.1206026620525602, 'intercept': 0.2495359491335939}, 'clinical_usefulness': {'treated': -0.7585359862441658, 'treated_all': -1.9796118889707683, 'untreated': 0.5233182440256869, 'overall': -0.2352177422184789, 'prevalence': 0.10611643330876934, 'adapt': 0.13876197494473103, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.13750600000003, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4901\n",
      "Class:1.0/N=524\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4901\n",
      "Class:1.0/N=3675\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 440.874ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 6, 49, 238104)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2930513595166163, 'recall': 0.6783216783216783, 'f1-score': 0.4092827004219409, 'support': 143.0, 'confusion_matrix': [[980, 234], [46, 97]], 'auc': 0.8127815347749449, 'n': 1357, 'tn': 980, 'fp': 234, 'fn': 46, 'tp': 97, 'dor': 8.831289483463397}, 'calibration': {'slope': 1.2821302731087167, 'intercept': 0.275264039557616}, 'clinical_usefulness': {'treated': -0.3308769344141488, 'treated_all': -1.9820682878899532, 'untreated': 0.7076534372039162, 'overall': 0.3767765027897674, 'prevalence': 0.105379513633014, 'adapt': 0.3960943257184966, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.485174999999799, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=527\n",
      "Class:0.0/N=4898\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=3673\n",
      "Class:0.0/N=4898\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 912.326ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 6, 55, 741410)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18596491228070175, 'recall': 0.7571428571428571, 'f1-score': 0.29859154929577464, 'support': 140.0, 'confusion_matrix': [[753, 464], [34, 106]], 'auc': 0.7422144617912901, 'n': 1357, 'tn': 753, 'fp': 464, 'fn': 34, 'tp': 106, 'dor': 5.059457403651115}, 'calibration': {'slope': 1.1624416091291656, 'intercept': 0.276889990940253}, 'clinical_usefulness': {'treated': -0.7197248833210511, 'treated_all': -1.9894374846475065, 'untreated': 0.5441625434256236, 'overall': -0.17556233989542747, 'prevalence': 0.10316875460574797, 'adapt': 0.16499631540162119, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.960431000000426, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=534\n",
      "Class:0.0/N=4891\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=3668\n",
      "Class:0.0/N=4891\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 458.991ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 7, 2, 712819)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1840607210626186, 'recall': 0.7293233082706767, 'f1-score': 0.29393939393939394, 'support': 133.0, 'confusion_matrix': [[794, 430], [36, 97]], 'auc': 0.7746848739495799, 'n': 1357, 'tn': 794, 'fp': 430, 'fn': 36, 'tp': 97, 'dor': 4.975322997416021}, 'calibration': {'slope': 0.634955071751907, 'intercept': 0.34302447716273926}, 'clinical_usefulness': {'treated': -0.6678948661262589, 'treated_all': -2.0066322770817977, 'untreated': 0.5737446046952311, 'overall': -0.09415026143102778, 'prevalence': 0.09801031687546058, 'adapt': 0.20125276344878407, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.499080000000504, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=530\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=3671\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 47.7ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 7, 9, 245371)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1829059829059829, 'recall': 0.781021897810219, 'f1-score': 0.296398891966759, 'support': 137.0, 'confusion_matrix': [[742, 478], [30, 107]], 'auc': 0.7678203900921383, 'n': 1357, 'tn': 742, 'fp': 478, 'fn': 30, 'tp': 107, 'dor': 5.536541143654115}, 'calibration': {'slope': 0.7835608211411627, 'intercept': 0.27771511833833573}, 'clinical_usefulness': {'treated': -0.7430606730533037, 'treated_all': -1.9968066814050593, 'untreated': 0.5373197178650384, 'overall': -0.2057409551882653, 'prevalence': 0.10095799557848195, 'adapt': 0.1532056005895357, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.054065000000264, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4882\n",
      "Class:1.0/N=543\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4882\n",
      "Class:1.0/N=3661\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 177.249ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 7, 15, 886086)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.175, 'recall': 0.7338709677419355, 'f1-score': 0.2826086956521739, 'support': 124.0, 'confusion_matrix': [[804, 429], [33, 91]], 'auc': 0.7593497370693039, 'n': 1357, 'tn': 804, 'fp': 429, 'fn': 33, 'tp': 91, 'dor': 5.1680440771349865}, 'calibration': {'slope': 1.0125110499158925, 'intercept': 0.3239473242774743}, 'clinical_usefulness': {'treated': -0.6705969049373618, 'treated_all': -2.028739867354458, 'untreated': 0.5820612696073271, 'overall': -0.08853563533003472, 'prevalence': 0.09137803979366249, 'adapt': 0.20626381724392034, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 6.18484399999943, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4882\n",
      "Class:1.0/N=543\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4882\n",
      "Class:1.0/N=4882\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 903.935ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 7, 24, 281670)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.30293159609120524, 'recall': 0.75, 'f1-score': 0.4315545243619489, 'support': 124.0, 'confusion_matrix': [[1019, 214], [31, 93]], 'auc': 0.8556955236376005, 'n': 1357, 'tn': 1019, 'fp': 214, 'fn': 31, 'tp': 93, 'dor': 14.285046728971961}, 'calibration': {'slope': 1.5755078869421988, 'intercept': 0.22542250442071377}, 'clinical_usefulness': {'treated': -0.2994350282485876, 'treated_all': -2.028739867354458, 'untreated': 0.7411306453310874, 'overall': 0.4416956170824998, 'prevalence': 0.09137803979366249, 'adapt': 0.4289609432571848, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.951079000000391, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4886\n",
      "Class:1.0/N=539\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4886\n",
      "Class:1.0/N=4886\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 561.269ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 7, 32, 350865)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.16666666666666666, 'recall': 0.7578125, 'f1-score': 0.2732394366197183, 'support': 128.0, 'confusion_matrix': [[744, 485], [31, 97]], 'auc': 0.740169217860049, 'n': 1357, 'tn': 744, 'fp': 485, 'fn': 31, 'tp': 97, 'dor': 4.800000000000001}, 'calibration': {'slope': 0.6872831982602137, 'intercept': 0.3208721270687622}, 'clinical_usefulness': {'treated': -0.7624662245148611, 'treated_all': -2.01891427167772, 'untreated': 0.5384777344983682, 'overall': -0.2239884900164929, 'prevalence': 0.09432571849668386, 'adapt': 0.1481945467943994, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.605075999999826, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4901\n",
      "Class:1.0/N=524\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4901\n",
      "Class:1.0/N=4901\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 241.855ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 7, 41, 601545)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19964973730297722, 'recall': 0.7972027972027972, 'f1-score': 0.31932773109243695, 'support': 143.0, 'confusion_matrix': [[757, 457], [29, 114]], 'auc': 0.7686345779426504, 'n': 1357, 'tn': 757, 'fp': 457, 'fn': 29, 'tp': 114, 'dor': 6.5115822832566215}, 'calibration': {'slope': 0.7522071140529624, 'intercept': 0.31083432902674024}, 'clinical_usefulness': {'treated': -0.7017931712110046, 'treated_all': -1.9820682878899532, 'untreated': 0.5486893357195494, 'overall': -0.15310383549145523, 'prevalence': 0.105379513633014, 'adapt': 0.17354458364038314, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 8.282508000000234, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=537\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=4888\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 228.013ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 7, 49, 823112)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19813084112149532, 'recall': 0.8153846153846154, 'f1-score': 0.31879699248120297, 'support': 130.0, 'confusion_matrix': [[798, 429], [24, 106]], 'auc': 0.8239044574007899, 'n': 1357, 'tn': 798, 'fp': 429, 'fn': 24, 'tp': 106, 'dor': 8.215617715617716}, 'calibration': {'slope': 0.7273692552640708, 'intercept': 0.3135963775376247}, 'clinical_usefulness': {'treated': -0.6595431098010316, 'treated_all': -2.014001473839351, 'untreated': 0.5804821560164228, 'overall': -0.07906095378460876, 'prevalence': 0.09579955784819455, 'adapt': 0.20847457627118646, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 7.270057000000634, 'explain': 2.3999999939405825e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4900\n",
      "Class:1.0/N=525\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4900\n",
      "Class:1.0/N=4900\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 712.386ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 8, 0, 50159)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19715808170515098, 'recall': 0.7816901408450704, 'f1-score': 0.3148936170212766, 'support': 142.0, 'confusion_matrix': [[763, 452], [31, 111]], 'auc': 0.7734451979365907, 'n': 1357, 'tn': 763, 'fp': 452, 'fn': 31, 'tp': 111, 'dor': 6.044319155009991}, 'calibration': {'slope': 0.6830899171677962, 'intercept': 0.32497548233639995}, 'clinical_usefulness': {'treated': -0.6954065340211248, 'treated_all': -1.9845246868091375, 'untreated': 0.5524792083377197, 'overall': -0.14292732568340516, 'prevalence': 0.10464259395725865, 'adapt': 0.17811348563006624, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 9.764563999999154, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4899\n",
      "Class:1.0/N=526\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_selection/_random_under_sampler.py\", line 123, in _fit_resample\n",
      "    replace=self.replacement)\n",
      "  File \"mtrand.pyx\", line 1168, in mtrand.RandomState.choice\n",
      "ValueError: Cannot take a larger sample than population when 'replace=False'\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 262.752ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 8, 5, 820718)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.3220858895705521, 'recall': 0.7446808510638298, 'f1-score': 0.449678800856531, 'support': 141.0, 'confusion_matrix': [[995, 221], [36, 105]], 'auc': 0.8370427398282942, 'n': 1357, 'tn': 995, 'fp': 221, 'fn': 36, 'tp': 105, 'dor': 13.1315987933635}, 'calibration': {'slope': 1.2364684479619061, 'intercept': 0.2593160347332228}, 'clinical_usefulness': {'treated': -0.3026283468435273, 'treated_all': -1.9869810857283219, 'untreated': 0.7218654595220549, 'overall': 0.41923711267852765, 'prevalence': 0.10390567428150331, 'adapt': 0.41451731761238025, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.300422999999682, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=529\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_selection/_random_under_sampler.py\", line 123, in _fit_resample\n",
      "    replace=self.replacement)\n",
      "  File \"mtrand.pyx\", line 1168, in mtrand.RandomState.choice\n",
      "ValueError: Cannot take a larger sample than population when 'replace=False'\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 24.411ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 8, 11, 330958)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19107142857142856, 'recall': 0.7753623188405797, 'f1-score': 0.30659025787965616, 'support': 138.0, 'confusion_matrix': [[766, 453], [31, 107]], 'auc': 0.7659610514677033, 'n': 1357, 'tn': 766, 'fp': 453, 'fn': 31, 'tp': 107, 'dor': 5.836502171900591}, 'calibration': {'slope': 0.9776387728009824, 'intercept': 0.26905009018949355}, 'clinical_usefulness': {'treated': -0.7000736919675754, 'treated_all': -1.9943502824858752, 'untreated': 0.5546899673649858, 'overall': -0.14538372460258964, 'prevalence': 0.1016949152542373, 'adapt': 0.1782608695652174, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.05935799999952, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=540\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_selection/_random_under_sampler.py\", line 123, in _fit_resample\n",
      "    replace=self.replacement)\n",
      "  File \"mtrand.pyx\", line 1168, in mtrand.RandomState.choice\n",
      "ValueError: Cannot take a larger sample than population when 'replace=False'\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 693.082ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 8, 17, 511322)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17137809187279152, 'recall': 0.7637795275590551, 'f1-score': 0.27994227994227994, 'support': 127.0, 'confusion_matrix': [[761, 469], [30, 97]], 'auc': 0.7653351257922029, 'n': 1357, 'tn': 761, 'fp': 469, 'fn': 30, 'tp': 97, 'dor': 5.246410803127221}, 'calibration': {'slope': 0.6152970926764761, 'intercept': 0.3551107602165066}, 'clinical_usefulness': {'treated': -0.734954556619995, 'treated_all': -2.021370670596905, 'untreated': 0.5513211917043899, 'overall': -0.1836333649156051, 'prevalence': 0.09358879882092852, 'adapt': 0.16543846720707436, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.695733999999902, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4899\n",
      "Class:1.0/N=526\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_selection/_random_under_sampler.py\", line 123, in _fit_resample\n",
      "    replace=self.replacement)\n",
      "  File \"mtrand.pyx\", line 1168, in mtrand.RandomState.choice\n",
      "ValueError: Cannot take a larger sample than population when 'replace=False'\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 940.338ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 8, 22, 938007)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18072289156626506, 'recall': 0.7446808510638298, 'f1-score': 0.2908587257617728, 'support': 141.0, 'confusion_matrix': [[740, 476], [36, 105]], 'auc': 0.7350544746173945, 'n': 1357, 'tn': 740, 'fp': 476, 'fn': 36, 'tp': 105, 'dor': 4.534313725490196}, 'calibration': {'slope': 0.9788405118598072, 'intercept': 0.275501279785874}, 'clinical_usefulness': {'treated': -0.7410955539179561, 'treated_all': -1.9869810857283219, 'untreated': 0.5339509422044426, 'overall': -0.2071446117135135, 'prevalence': 0.10390567428150331, 'adapt': 0.15143699336772293, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.976781000000301, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4891\n",
      "Class:1.0/N=534\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_selection/_random_under_sampler.py\", line 123, in _fit_resample\n",
      "    replace=self.replacement)\n",
      "  File \"mtrand.pyx\", line 1168, in mtrand.RandomState.choice\n",
      "ValueError: Cannot take a larger sample than population when 'replace=False'\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 148.809ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 8, 27, 574488)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21113243761996162, 'recall': 0.8270676691729323, 'f1-score': 0.3363914373088685, 'support': 133.0, 'confusion_matrix': [[813, 411], [23, 110]], 'auc': 0.8272150965649416, 'n': 1357, 'tn': 813, 'fp': 411, 'fn': 23, 'tp': 110, 'dor': 9.460488733735323}, 'calibration': {'slope': 0.4222140058736947, 'intercept': 0.4508447464485534}, 'clinical_usefulness': {'treated': -0.6256448047162859, 'treated_all': -2.0066322770817977, 'untreated': 0.5918517738709338, 'overall': -0.03379303084535212, 'prevalence': 0.09801031687546058, 'adapt': 0.22660280029476781, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.184922999999799, 'explain': 1.700000029813964e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4881\n",
      "Class:1.0/N=544\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2176\n",
      "Class:1.0/N=544\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 757.949ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 8, 31, 827268)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2913907284768212, 'recall': 0.7154471544715447, 'f1-score': 0.41411764705882353, 'support': 123.0, 'confusion_matrix': [[1020, 214], [35, 88]], 'auc': 0.8334486302723643, 'n': 1357, 'tn': 1020, 'fp': 214, 'fn': 35, 'tp': 88, 'dor': 11.983978638184244}, 'calibration': {'slope': 1.216377496816804, 'intercept': 0.2805323241809947}, 'clinical_usefulness': {'treated': -0.3031196266273643, 'treated_all': -2.0311962662736427, 'untreated': 0.7406042741341194, 'overall': 0.43748464750675514, 'prevalence': 0.09064112011790715, 'adapt': 0.42748710390567435, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.795711000000665, 'explain': 2.0000000404252205e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4878\n",
      "Class:1.0/N=547\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2188\n",
      "Class:1.0/N=547\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 240.838ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 8, 36, 564407)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17790262172284643, 'recall': 0.7916666666666666, 'f1-score': 0.290519877675841, 'support': 120.0, 'confusion_matrix': [[798, 439], [25, 95]], 'auc': 0.7676030719482619, 'n': 1357, 'tn': 798, 'fp': 439, 'fn': 25, 'tp': 95, 'dor': 6.9075170842824605}, 'calibration': {'slope': 1.0203460773976771, 'intercept': 0.3088124378404552}, 'clinical_usefulness': {'treated': -0.6848440186686316, 'treated_all': -2.038565463031196, 'untreated': 0.580166333298242, 'overall': -0.10467768537038968, 'prevalence': 0.08843036109064112, 'adapt': 0.20066322770817982, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.245025000000169, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4893\n",
      "Class:1.0/N=532\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2128\n",
      "Class:1.0/N=532\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 613.417ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 8, 40, 687569)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21272365805168986, 'recall': 0.7925925925925926, 'f1-score': 0.335423197492163, 'support': 135.0, 'confusion_matrix': [[826, 396], [28, 107]], 'auc': 0.8131205673758866, 'n': 1357, 'tn': 826, 'fp': 396, 'fn': 28, 'tp': 107, 'dor': 7.970959595959597}, 'calibration': {'slope': 0.9105196724795719, 'intercept': 0.2810762072427201}, 'clinical_usefulness': {'treated': -0.6020633750921149, 'treated_all': -2.001719479243429, 'untreated': 0.599852616064849, 'overall': -0.002210759027265974, 'prevalence': 0.09948415622697127, 'adapt': 0.23927781871775972, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.6553649999996196, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4891\n",
      "Class:1.0/N=534\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2136\n",
      "Class:1.0/N=534\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 393.262ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 8, 45, 34705)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2084130019120459, 'recall': 0.8195488721804511, 'f1-score': 0.3323170731707317, 'support': 133.0, 'confusion_matrix': [[810, 414], [24, 109]], 'auc': 0.825642537716841, 'n': 1357, 'tn': 810, 'fp': 414, 'fn': 24, 'tp': 109, 'dor': 8.88586956521739}, 'calibration': {'slope': 0.6460878207938786, 'intercept': 0.34585542316748935}, 'clinical_usefulness': {'treated': -0.6315401621223287, 'treated_all': -2.0066322770817977, 'untreated': 0.589325192125487, 'overall': -0.04221496999684171, 'prevalence': 0.09801031687546058, 'adapt': 0.22306558585114222, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.436152999999649, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=538\n",
      "Class:0.0/N=4887\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2152\n",
      "Class:1.0/N=538\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 254.255ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 8, 48, 815634)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18545454545454546, 'recall': 0.7906976744186046, 'f1-score': 0.3004418262150221, 'support': 129.0, 'confusion_matrix': [[780, 448], [27, 102]], 'auc': 0.7655291265813196, 'n': 1357, 'tn': 780, 'fp': 448, 'fn': 27, 'tp': 102, 'dor': 6.577380952380952}, 'calibration': {'slope': 0.8095022730095939, 'intercept': 0.27105198425987537}, 'clinical_usefulness': {'treated': -0.6951608941292063, 'treated_all': -2.016457872758535, 'untreated': 0.566270133698284, 'overall': -0.1288907604309223, 'prevalence': 0.0950626381724392, 'adapt': 0.18784082535003688, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.2584349999997357, 'explain': 2.0000000404252205e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4899\n",
      "Class:1.0/N=526\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=1052\n",
      "Class:1.0/N=526\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 504.93ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 8, 52, 840916)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.28615384615384615, 'recall': 0.6595744680851063, 'f1-score': 0.3991416309012875, 'support': 141.0, 'confusion_matrix': [[984, 232], [48, 93]], 'auc': 0.7860004899216124, 'n': 1357, 'tn': 984, 'fp': 232, 'fn': 48, 'tp': 93, 'dor': 8.217672413793103}, 'calibration': {'slope': 1.3929720125377678, 'intercept': 0.2552172538117954}, 'clinical_usefulness': {'treated': -0.3303856546303119, 'treated_all': -1.9869810857283219, 'untreated': 0.7099694704705758, 'overall': 0.3795838158402639, 'prevalence': 0.10390567428150331, 'adapt': 0.39786293294030944, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.547540000000481, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4905\n",
      "Class:1.0/N=520\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=1040\n",
      "Class:1.0/N=520\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 703.233ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 8, 56, 49673)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.22287968441814596, 'recall': 0.7687074829931972, 'f1-score': 0.34556574923547395, 'support': 147.0, 'confusion_matrix': [[816, 394], [34, 113]], 'auc': 0.7957609490077022, 'n': 1357, 'tn': 816, 'fp': 394, 'fn': 34, 'tp': 113, 'dor': 6.883248730964468}, 'calibration': {'slope': 0.6424014759765008, 'intercept': 0.3255313723859818}, 'clinical_usefulness': {'treated': -0.5942028985507246, 'treated_all': -1.972242692213215, 'untreated': 0.5905884829982103, 'overall': -0.003614415552514294, 'prevalence': 0.10832719233603537, 'adapt': 0.2351510685335298, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.7420539999993707, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4900\n",
      "Class:1.0/N=525\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=1050\n",
      "Class:1.0/N=525\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 990.561ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 8, 59, 546321)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18426103646833014, 'recall': 0.676056338028169, 'f1-score': 0.2895927601809955, 'support': 142.0, 'confusion_matrix': [[790, 425], [46, 96]], 'auc': 0.6966846345563091, 'n': 1357, 'tn': 790, 'fp': 425, 'fn': 46, 'tp': 96, 'dor': 3.879283887468031}, 'calibration': {'slope': 1.2295832874380859, 'intercept': 0.23028743778538624}, 'clinical_usefulness': {'treated': -0.6600343895848685, 'treated_all': -1.9845246868091375, 'untreated': 0.5676386988104011, 'overall': -0.09239569077446741, 'prevalence': 0.10464259395725865, 'adapt': 0.19933677229182015, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.0296220000000176, 'explain': 2.299999960087007e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4873\n",
      "Class:1.0/N=552\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=1104\n",
      "Class:1.0/N=552\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 662.656ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 9, 2, 713784)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17077798861480076, 'recall': 0.782608695652174, 'f1-score': 0.2803738317757009, 'support': 115.0, 'confusion_matrix': [[805, 437], [25, 90]], 'auc': 0.7947139956591753, 'n': 1357, 'tn': 805, 'fp': 437, 'fn': 25, 'tp': 90, 'dor': 6.631578947368421}, 'calibration': {'slope': 0.683001355885494, 'intercept': 0.3519241696517818}, 'clinical_usefulness': {'treated': -0.68508965856055, 'treated_all': -2.0508474576271185, 'untreated': 0.5853247710285293, 'overall': -0.09976488753202073, 'prevalence': 0.0847457627118644, 'adapt': 0.20420044215180547, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.699174000000312, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4901\n",
      "Class:1.0/N=524\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=1048\n",
      "Class:1.0/N=524\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 386.814ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 9, 6, 928254)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21082089552238806, 'recall': 0.7902097902097902, 'f1-score': 0.3328424153166421, 'support': 143.0, 'confusion_matrix': [[791, 423], [30, 113]], 'auc': 0.7933779564751557, 'n': 1357, 'tn': 791, 'fp': 423, 'fn': 30, 'tp': 113, 'dor': 7.043577620173364}, 'calibration': {'slope': 0.6669725752151373, 'intercept': 0.3386973031607647}, 'clinical_usefulness': {'treated': -0.6440677966101694, 'treated_all': -1.9820682878899532, 'untreated': 0.5734287819770502, 'overall': -0.07063901463311928, 'prevalence': 0.105379513633014, 'adapt': 0.20817980840088424, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.3918469999998706, 'explain': 2.299999960087007e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=530\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=706\n",
      "Class:1.0/N=530\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 566.201ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 9, 11, 1718)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.31, 'recall': 0.6788321167883211, 'f1-score': 0.42562929061784893, 'support': 137.0, 'confusion_matrix': [[1013, 207], [44, 93]], 'auc': 0.8188704080411632, 'n': 1357, 'tn': 1013, 'fp': 207, 'fn': 44, 'tp': 93, 'dor': 10.343544137022398}, 'calibration': {'slope': 1.2495543719482105, 'intercept': 0.2642659556534974}, 'clinical_usefulness': {'treated': -0.28739867354458365, 'treated_all': -1.9968066814050593, 'untreated': 0.7326034319402042, 'overall': 0.4452047583956205, 'prevalence': 0.10095799557848195, 'adapt': 0.4266028002947678, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.608444999999847, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4901\n",
      "Class:1.0/N=524\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=698\n",
      "Class:1.0/N=524\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 717.205ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 9, 14, 675306)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18307426597582038, 'recall': 0.7412587412587412, 'f1-score': 0.2936288088642659, 'support': 143.0, 'confusion_matrix': [[741, 473], [37, 106]], 'auc': 0.708499902074861, 'n': 1357, 'tn': 741, 'fp': 473, 'fn': 37, 'tp': 106, 'dor': 4.4880863950631396}, 'calibration': {'slope': 0.646650161966748, 'intercept': 0.34560002624361863}, 'clinical_usefulness': {'treated': -0.7352001965119134, 'treated_all': -1.9820682878899532, 'untreated': 0.534372039162017, 'overall': -0.20082815734989634, 'prevalence': 0.105379513633014, 'adapt': 0.15350036845983783, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.7538500000000568, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4900\n",
      "Class:1.0/N=525\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=700\n",
      "Class:1.0/N=525\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 734.879ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 9, 17, 915256)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.22007722007722008, 'recall': 0.8028169014084507, 'f1-score': 0.34545454545454546, 'support': 142.0, 'confusion_matrix': [[811, 404], [28, 114]], 'auc': 0.7929490523387238, 'n': 1357, 'tn': 811, 'fp': 404, 'fn': 28, 'tp': 114, 'dor': 8.173090523338049}, 'calibration': {'slope': 0.2471903248897893, 'intercept': 0.4140058189916682}, 'clinical_usefulness': {'treated': -0.6106607713092607, 'treated_all': -1.9845246868091375, 'untreated': 0.5887988209285188, 'overall': -0.0218619503807419, 'prevalence': 0.10464259395725865, 'adapt': 0.22896094325718488, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.738581000000522, 'explain': 1.8000000636675395e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=543\n",
      "Class:0.0/N=4882\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=724\n",
      "Class:1.0/N=543\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 694.984ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 9, 21, 122901)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17142857142857143, 'recall': 0.7741935483870968, 'f1-score': 0.2807017543859649, 'support': 124.0, 'confusion_matrix': [[769, 464], [28, 96]], 'auc': 0.8003885095361432, 'n': 1357, 'tn': 769, 'fp': 464, 'fn': 28, 'tp': 96, 'dor': 5.682266009852217}, 'calibration': {'slope': 0.657190783768964, 'intercept': 0.350106581891373}, 'clinical_usefulness': {'treated': -0.7270940800786045, 'treated_all': -2.028739867354458, 'untreated': 0.5578481945467944, 'overall': -0.1692458855318102, 'prevalence': 0.09137803979366249, 'adapt': 0.17236551215917462, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.730362000000241, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4900\n",
      "Class:1.0/N=525\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=700\n",
      "Class:1.0/N=525\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 63.464ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 9, 25, 191211)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2019607843137255, 'recall': 0.7253521126760564, 'f1-score': 0.3159509202453987, 'support': 142.0, 'confusion_matrix': [[808, 407], [39, 103]], 'auc': 0.7612849939141019, 'n': 1357, 'tn': 808, 'fp': 407, 'fn': 39, 'tp': 103, 'dor': 5.243117243117243}, 'calibration': {'slope': 0.5138385581808906, 'intercept': 0.38069417798631655}, 'clinical_usefulness': {'treated': -0.6239253254728567, 'treated_all': -1.9845246868091375, 'untreated': 0.5831140120012633, 'overall': -0.04081131347159339, 'prevalence': 0.10464259395725865, 'adapt': 0.22100221075902726, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.1011379999999917, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=537\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=537\n",
      "Class:1.0/N=537\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 523.979ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 9, 28, 410122)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.292358803986711, 'recall': 0.676923076923077, 'f1-score': 0.4083526682134571, 'support': 130.0, 'confusion_matrix': [[1014, 213], [42, 88]], 'auc': 0.8072001755375839, 'n': 1357, 'tn': 1014, 'fp': 213, 'fn': 42, 'tp': 88, 'dor': 9.974513749161636}, 'calibration': {'slope': 1.5031987231673063, 'intercept': 0.24426842015968359}, 'clinical_usefulness': {'treated': -0.30140014738393517, 'treated_all': -2.014001473839351, 'untreated': 0.7339719970523213, 'overall': 0.43257184966838613, 'prevalence': 0.09579955784819455, 'adapt': 0.4233603537214443, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.5621089999995093, 'explain': 2.0000000404252205e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4884\n",
      "Class:1.0/N=541\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=541\n",
      "Class:1.0/N=541\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 917.924ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 9, 31, 838384)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1840607210626186, 'recall': 0.7698412698412699, 'f1-score': 0.29709035222052066, 'support': 126.0, 'confusion_matrix': [[801, 430], [29, 97]], 'auc': 0.7557831418513792, 'n': 1357, 'tn': 801, 'fp': 430, 'fn': 29, 'tp': 97, 'dor': 6.230713712910986}, 'calibration': {'slope': 0.5762455665386553, 'intercept': 0.42328761900247236}, 'clinical_usefulness': {'treated': -0.6678948661262589, 'treated_all': -2.023827069516089, 'untreated': 0.5811138014527845, 'overall': -0.08678106467347446, 'prevalence': 0.09285187914517318, 'adapt': 0.2064112011790714, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.9216829999995753, 'explain': 1.7999999727180693e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4887\n",
      "Class:1.0/N=538\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=538\n",
      "Class:1.0/N=538\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 916.928ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 9, 35, 264108)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19160583941605838, 'recall': 0.813953488372093, 'f1-score': 0.310192023633678, 'support': 129.0, 'confusion_matrix': [[785, 443], [24, 105]], 'auc': 0.8120060348963462, 'n': 1357, 'tn': 785, 'fp': 443, 'fn': 24, 'tp': 105, 'dor': 7.7525395033860045}, 'calibration': {'slope': 0.7316745776017284, 'intercept': 0.3722337686474295}, 'clinical_usefulness': {'treated': -0.6843527388847948, 'treated_all': -2.016457872758535, 'untreated': 0.5709022002316033, 'overall': -0.11345053865319144, 'prevalence': 0.0950626381724392, 'adapt': 0.19432571849668387, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.953081000000566, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=532\n",
      "Class:0.0/N=4893\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=532\n",
      "Class:1.0/N=532\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 910.824ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 9, 38, 684052)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17, 'recall': 0.7555555555555555, 'f1-score': 0.27755102040816326, 'support': 135.0, 'confusion_matrix': [[724, 498], [33, 102]], 'auc': 0.7452415590713464, 'n': 1357, 'tn': 724, 'fp': 498, 'fn': 33, 'tp': 102, 'dor': 4.493610806863819}, 'calibration': {'slope': 1.1534107643543974, 'intercept': 0.2802423207259658}, 'clinical_usefulness': {'treated': -0.781134856300663, 'treated_all': -2.001719479243429, 'untreated': 0.5231076955468996, 'overall': -0.2580271607537634, 'prevalence': 0.09948415622697127, 'adapt': 0.13183492999263074, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.95478600000024, 'explain': 2.0000000404252205e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4903\n",
      "Class:1.0/N=522\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=522\n",
      "Class:1.0/N=522\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 261.722ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 9, 42, 462099)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21428571428571427, 'recall': 0.7655172413793103, 'f1-score': 0.334841628959276, 'support': 145.0, 'confusion_matrix': [[805, 407], [34, 111]], 'auc': 0.7926852167975419, 'n': 1357, 'tn': 805, 'fp': 407, 'fn': 34, 'tp': 111, 'dor': 6.457219251336897}, 'calibration': {'slope': 0.59217734605463, 'intercept': 0.3960164444489719}, 'clinical_usefulness': {'treated': -0.618029968066814, 'treated_all': -1.9771554900515838, 'untreated': 0.5824823665649015, 'overall': -0.035547601501912496, 'prevalence': 0.10685335298452468, 'adapt': 0.22232866617538682, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.2973799999999756, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=529\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_generation/_cluster_centroids.py\", line 156, in _fit_resample\n",
      "    self.estimator_.fit(X[y == target_class])\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 971, in fit\n",
      "    return_n_iter=True)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 315, in k_means\n",
      "    _num_samples(X), n_clusters))\n",
      "ValueError: n_samples=4896 should be >= n_clusters=5290\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 767.613ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 9, 47, 682075)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.3157894736842105, 'recall': 0.6956521739130435, 'f1-score': 0.43438914027149317, 'support': 138.0, 'confusion_matrix': [[1011, 208], [42, 96]], 'auc': 0.837149718823935, 'n': 1357, 'tn': 1011, 'fp': 208, 'fn': 42, 'tp': 96, 'dor': 11.109890109890111}, 'calibration': {'slope': 1.3671365971083325, 'intercept': 0.2577353504748612}, 'clinical_usefulness': {'treated': -0.28690739376074675, 'treated_all': -1.9943502824858752, 'untreated': 0.7317612380250552, 'overall': 0.44485384426430846, 'prevalence': 0.1016949152542373, 'adapt': 0.4261606484893146, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.803700999999819, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4893\n",
      "Class:1.0/N=532\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_generation/_cluster_centroids.py\", line 156, in _fit_resample\n",
      "    self.estimator_.fit(X[y == target_class])\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 971, in fit\n",
      "    return_n_iter=True)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 315, in k_means\n",
      "    _num_samples(X), n_clusters))\n",
      "ValueError: n_samples=4893 should be >= n_clusters=5320\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 481.402ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 9, 53, 148068)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1950354609929078, 'recall': 0.8148148148148148, 'f1-score': 0.3147353361945637, 'support': 135.0, 'confusion_matrix': [[768, 454], [25, 110]], 'auc': 0.7775625871370552, 'n': 1357, 'tn': 768, 'fp': 454, 'fn': 25, 'tp': 110, 'dor': 7.4431718061674}, 'calibration': {'slope': 0.9657009531324477, 'intercept': 0.2518317380247762}, 'clinical_usefulness': {'treated': -0.6995824121837384, 'treated_all': -2.001719479243429, 'untreated': 0.5580587430255817, 'overall': -0.14152366915815673, 'prevalence': 0.09948415622697127, 'adapt': 0.18076639646278558, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.520045999999638, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4890\n",
      "Class:1.0/N=535\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_generation/_cluster_centroids.py\", line 156, in _fit_resample\n",
      "    self.estimator_.fit(X[y == target_class])\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 971, in fit\n",
      "    return_n_iter=True)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 315, in k_means\n",
      "    _num_samples(X), n_clusters))\n",
      "ValueError: n_samples=4890 should be >= n_clusters=5350\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 882.302ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 9, 58, 519931)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17224080267558528, 'recall': 0.7803030303030303, 'f1-score': 0.2821917808219178, 'support': 132.0, 'confusion_matrix': [[730, 495], [29, 103]], 'auc': 0.7479035250463821, 'n': 1357, 'tn': 730, 'fp': 495, 'fn': 29, 'tp': 103, 'dor': 5.237896203413444}, 'calibration': {'slope': 0.8635532210964307, 'intercept': 0.2906628364754129}, 'clinical_usefulness': {'treated': -0.7752394988946204, 'treated_all': -2.009088676000982, 'untreated': 0.5287925044741552, 'overall': -0.24644699442046525, 'prevalence': 0.09727339719970524, 'adapt': 0.13758290346352245, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.913731000000553, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4892\n",
      "Class:1.0/N=533\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_generation/_cluster_centroids.py\", line 156, in _fit_resample\n",
      "    self.estimator_.fit(X[y == target_class])\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 971, in fit\n",
      "    return_n_iter=True)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 315, in k_means\n",
      "    _num_samples(X), n_clusters))\n",
      "ValueError: n_samples=4892 should be >= n_clusters=5330\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 313.92ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 10, 4, 538072)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.184070796460177, 'recall': 0.7761194029850746, 'f1-score': 0.29756795422031473, 'support': 134.0, 'confusion_matrix': [[762, 461], [30, 104]], 'auc': 0.7725802711707205, 'n': 1357, 'tn': 762, 'fp': 461, 'fn': 30, 'tp': 104, 'dor': 5.730151843817787}, 'calibration': {'slope': 0.7063263339319413, 'intercept': 0.30960679028937055}, 'clinical_usefulness': {'treated': -0.7160402849422745, 'treated_all': -2.0041758781626133, 'untreated': 0.5520581113801453, 'overall': -0.16398217356212919, 'prevalence': 0.09874723655121592, 'adapt': 0.17162859248341927, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.348952000000281, 'explain': 2.2000000171829015e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4894\n",
      "Class:1.0/N=531\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_generation/_cluster_centroids.py\", line 156, in _fit_resample\n",
      "    self.estimator_.fit(X[y == target_class])\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 971, in fit\n",
      "    return_n_iter=True)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 315, in k_means\n",
      "    _num_samples(X), n_clusters))\n",
      "ValueError: n_samples=4894 should be >= n_clusters=5310\n",
      "\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 5.391ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 10, 10, 71998)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19642857142857142, 'recall': 0.8088235294117647, 'f1-score': 0.3160919540229885, 'support': 136.0, 'confusion_matrix': [[771, 450], [26, 110]], 'auc': 0.7689363829069712, 'n': 1357, 'tn': 771, 'fp': 450, 'fn': 26, 'tp': 110, 'dor': 7.248717948717949}, 'calibration': {'slope': 0.9267112796000594, 'intercept': 0.2714464078170391}, 'clinical_usefulness': {'treated': -0.6927044952100219, 'treated_all': -1.9992630803242442, 'untreated': 0.5599536793346668, 'overall': -0.1327508158753551, 'prevalence': 0.10022107590272661, 'adapt': 0.1841562269712601, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 5.0455879999999524, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4891\n",
      "Class:1.0/N=534\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2136\n",
      "Class:1.0/N=534\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 332.112ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 28, 27, 672089)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.3111111111111111, 'recall': 0.631578947368421, 'f1-score': 0.41687344913151364, 'support': 133.0, 'confusion_matrix': [[1038, 186], [49, 84]], 'auc': 0.7858678559142955, 'n': 1357, 'tn': 1038, 'fp': 186, 'fn': 49, 'tp': 84, 'dor': 9.566820276497696}, 'calibration': {'slope': 1.23452703693007, 'intercept': 0.23082846206899005}, 'clinical_usefulness': {'treated': -0.2579218865143699, 'treated_all': -2.0066322770817977, 'untreated': 0.7494473102431836, 'overall': 0.49152542372881364, 'prevalence': 0.09801031687546058, 'adapt': 0.44723655121591754, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 4.365399999999681, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4882\n",
      "Class:1.0/N=543\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2172\n",
      "Class:1.0/N=543\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 889.696ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 16, 46, 19, 899034)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.15901060070671377, 'recall': 0.7258064516129032, 'f1-score': 0.2608695652173913, 'support': 124.0, 'confusion_matrix': [[757, 476], [34, 90]], 'auc': 0.705049969913403, 'n': 1357, 'tn': 757, 'fp': 476, 'fn': 34, 'tp': 90, 'dor': 4.209713297083539}, 'calibration': {'slope': 0.7750149533590395, 'intercept': 0.3029770822266102}, 'clinical_usefulness': {'treated': -0.7521493490542862, 'treated_all': -2.028739867354458, 'untreated': 0.547110222128645, 'overall': -0.2050391269256412, 'prevalence': 0.09137803979366249, 'adapt': 0.15733235077376562, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.923800999999912, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4901\n",
      "Class:1.0/N=524\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2096\n",
      "Class:1.0/N=524\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 836.868ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 17, 4, 29, 327184)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18840579710144928, 'recall': 0.7272727272727273, 'f1-score': 0.2992805755395683, 'support': 143.0, 'confusion_matrix': [[766, 448], [39, 104]], 'auc': 0.728145413071278, 'n': 1357, 'tn': 766, 'fp': 448, 'fn': 39, 'tp': 104, 'dor': 4.55952380952381}, 'calibration': {'slope': 0.6905643526823122, 'intercept': 0.31788755662459356}, 'clinical_usefulness': {'treated': -0.6936870547776957, 'treated_all': -1.9820682878899532, 'untreated': 0.5521633856195389, 'overall': -0.14152366915815673, 'prevalence': 0.105379513633014, 'adapt': 0.17840825350036849, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.8793409999998403, 'explain': 1.900000006571645e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4893\n",
      "Class:1.0/N=532\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2128\n",
      "Class:1.0/N=532\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 406.886ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 17, 22, 33, 185442)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18147448015122875, 'recall': 0.7111111111111111, 'f1-score': 0.28915662650602414, 'support': 135.0, 'confusion_matrix': [[789, 433], [39, 96]], 'auc': 0.7476813966175668, 'n': 1357, 'tn': 789, 'fp': 433, 'fn': 39, 'tp': 96, 'dor': 4.485343755551608}, 'calibration': {'slope': 0.5680031730350391, 'intercept': 0.3434377425647665}, 'clinical_usefulness': {'treated': -0.6737902235323014, 'treated_all': -2.001719479243429, 'untreated': 0.5691125381619118, 'overall': -0.10467768537038968, 'prevalence': 0.09948415622697127, 'adapt': 0.19624170965364776, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.4496579999995447, 'explain': 1.4999999621068127e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=540\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2160\n",
      "Class:1.0/N=540\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 798.168ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 17, 41, 23, 12821)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.16399286987522282, 'recall': 0.7244094488188977, 'f1-score': 0.26744186046511625, 'support': 127.0, 'confusion_matrix': [[761, 469], [35, 92]], 'auc': 0.7107099417450866, 'n': 1357, 'tn': 761, 'fp': 469, 'fn': 35, 'tp': 92, 'dor': 4.265123362777947}, 'calibration': {'slope': 0.6805401694586829, 'intercept': 0.3596528381341148}, 'clinical_usefulness': {'treated': -0.7386391549987716, 'treated_all': -2.021370670596905, 'untreated': 0.5497420781134856, 'overall': -0.188897076885286, 'prevalence': 0.09358879882092852, 'adapt': 0.16322770817980836, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.8412250000001222, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=537\n",
      "Class:0.0/N=4888\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=1074\n",
      "Class:1.0/N=537\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 214.058ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 17, 50, 43, 451572)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.28664495114006516, 'recall': 0.676923076923077, 'f1-score': 0.402745995423341, 'support': 130.0, 'confusion_matrix': [[1008, 219], [42, 88]], 'auc': 0.8118299793116419, 'n': 1357, 'tn': 1008, 'fp': 219, 'fn': 42, 'tp': 88, 'dor': 9.643835616438356}, 'calibration': {'slope': 1.125849986391279, 'intercept': 0.26871283763790793}, 'clinical_usefulness': {'treated': -0.31171702284450986, 'treated_all': -2.014001473839351, 'untreated': 0.7295504789977892, 'overall': 0.4178334561532794, 'prevalence': 0.09579955784819455, 'adapt': 0.41717022844509943, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.254782999998497, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4891\n",
      "Class:1.0/N=534\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=1068\n",
      "Class:1.0/N=534\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 770.419ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 18, 0, 28, 199386)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.14084507042253522, 'recall': 0.6766917293233082, 'f1-score': 0.23316062176165803, 'support': 133.0, 'confusion_matrix': [[675, 549], [43, 90]], 'auc': 0.6316772322964274, 'n': 1357, 'tn': 675, 'fp': 549, 'fn': 43, 'tp': 90, 'dor': 2.5733892489515817}, 'calibration': {'slope': 1.0764490771196296, 'intercept': 0.26748935693017617}, 'clinical_usefulness': {'treated': -0.877671333824613, 'treated_all': -2.0066322770817977, 'untreated': 0.4838404042530793, 'overall': -0.39383092957153376, 'prevalence': 0.09801031687546058, 'adapt': 0.07538688282977152, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.810968000001594, 'explain': 2.4000000848900527e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4874\n",
      "Class:1.0/N=551\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=1102\n",
      "Class:1.0/N=551\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 376.359ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 18, 10, 45, 438023)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.11764705882352941, 'recall': 0.6379310344827587, 'f1-score': 0.19865771812080535, 'support': 116.0, 'confusion_matrix': [[686, 555], [42, 74]], 'auc': 0.649517908249743, 'n': 1357, 'tn': 686, 'fp': 555, 'fn': 42, 'tp': 74, 'dor': 2.1777777777777776}, 'calibration': {'slope': 1.229016108203632, 'intercept': 0.22353530984359085}, 'clinical_usefulness': {'treated': -0.8997789240972733, 'treated_all': -2.0483910587079337, 'untreated': 0.49226234340456887, 'overall': -0.40751658069270447, 'prevalence': 0.08548268238761975, 'adapt': 0.07464996315401612, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.4148199999999633, 'explain': 1.8000000636675395e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4893\n",
      "Class:1.0/N=532\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=1064\n",
      "Class:1.0/N=532\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 729.735ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 18, 20, 29, 834990)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1312, 'recall': 0.6074074074074074, 'f1-score': 0.21578947368421056, 'support': 135.0, 'confusion_matrix': [[679, 543], [53, 82]], 'auc': 0.6129447778383948, 'n': 1357, 'tn': 679, 'fp': 543, 'fn': 53, 'tp': 82, 'dor': 1.9346745891101151}, 'calibration': {'slope': 0.622132000874059, 'intercept': 0.30924355728544783}, 'clinical_usefulness': {'treated': -0.873249815770081, 'treated_all': -2.001719479243429, 'untreated': 0.4836298557742921, 'overall': -0.3896199599957889, 'prevalence': 0.09948415622697127, 'adapt': 0.07656595431098007, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.7702620000000024, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4890\n",
      "Class:1.0/N=535\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=1070\n",
      "Class:1.0/N=535\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 404.406ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 18, 30, 5, 172182)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.14214876033057852, 'recall': 0.6515151515151515, 'f1-score': 0.23337856173677068, 'support': 132.0, 'confusion_matrix': [[706, 519], [46, 86]], 'auc': 0.6487662337662338, 'n': 1357, 'tn': 706, 'fp': 519, 'fn': 46, 'tp': 86, 'dor': 2.5431850548714086}, 'calibration': {'slope': 0.798379436164353, 'intercept': 0.2828327040750319}, 'clinical_usefulness': {'treated': -0.8290346352247604, 'treated_all': -2.009088676000982, 'untreated': 0.5057374460469523, 'overall': -0.32329718917780814, 'prevalence': 0.09727339719970524, 'adapt': 0.10530582166543839, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.4466990000000806, 'explain': 2.0000001313746907e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=534\n",
      "Class:0.0/N=4891\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=712\n",
      "Class:1.0/N=534\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 18.801ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 18, 36, 11, 387156)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2743362831858407, 'recall': 0.6992481203007519, 'f1-score': 0.3940677966101695, 'support': 133.0, 'confusion_matrix': [[978, 246], [40, 93]], 'auc': 0.8082092486117254, 'n': 1357, 'tn': 978, 'fp': 246, 'fn': 40, 'tp': 93, 'dor': 9.243292682926828}, 'calibration': {'slope': 0.9237934137346054, 'intercept': 0.29495863860243204}, 'clinical_usefulness': {'treated': -0.35445836403831976, 'treated_all': -2.0066322770817977, 'untreated': 0.7080745341614907, 'overall': 0.3536161701231709, 'prevalence': 0.09801031687546058, 'adapt': 0.3893146647015475, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.023783000000549, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4906\n",
      "Class:1.0/N=519\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=692\n",
      "Class:1.0/N=519\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 918.538ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 18, 42, 7, 559117)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17109634551495018, 'recall': 0.6959459459459459, 'f1-score': 0.27466666666666667, 'support': 148.0, 'confusion_matrix': [[710, 499], [45, 103]], 'auc': 0.6654734759573468, 'n': 1357, 'tn': 710, 'fp': 499, 'fn': 45, 'tp': 103, 'dor': 3.2567356936094414}, 'calibration': {'slope': 0.6616627313497456, 'intercept': 0.2990423225430957}, 'clinical_usefulness': {'treated': -0.7821174158683369, 'treated_all': -1.9697862932940307, 'untreated': 0.5090009474681545, 'overall': -0.27311646840018244, 'prevalence': 0.10906411201179071, 'adapt': 0.12166543846720704, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.959584000000177, 'explain': 4.3000000005122274e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4908\n",
      "Class:1.0/N=517\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=689\n",
      "Class:1.0/N=517\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 512.465ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 18, 47, 48, 976573)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.16912972085385877, 'recall': 0.6866666666666666, 'f1-score': 0.2714097496706192, 'support': 150.0, 'confusion_matrix': [[701, 506], [47, 103]], 'auc': 0.69, 'n': 1357, 'tn': 701, 'fp': 506, 'fn': 47, 'tp': 103, 'dor': 3.0360356572197458}, 'calibration': {'slope': 0.6513057284715056, 'intercept': 0.2825614261837397}, 'clinical_usefulness': {'treated': -0.7941537705723408, 'treated_all': -1.9648734954556617, 'untreated': 0.5017370249499947, 'overall': -0.2924167456223461, 'prevalence': 0.1105379513633014, 'adapt': 0.11296978629329402, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.5519469999999274, 'explain': 3.300000025774352e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4873\n",
      "Class:1.0/N=552\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=736\n",
      "Class:1.0/N=552\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 811.033ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 18, 53, 29, 620114)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.13175675675675674, 'recall': 0.6782608695652174, 'f1-score': 0.22065063649222064, 'support': 115.0, 'confusion_matrix': [[728, 514], [37, 78]], 'auc': 0.6925750892669608, 'n': 1357, 'tn': 728, 'fp': 514, 'fn': 37, 'tp': 78, 'dor': 2.985802923546114}, 'calibration': {'slope': 1.0125404972620642, 'intercept': 0.2241714646551249}, 'clinical_usefulness': {'treated': -0.8263325964136574, 'treated_all': -2.0508474576271185, 'untreated': 0.5247920833771976, 'overall': -0.3015405130364598, 'prevalence': 0.0847457627118644, 'adapt': 0.11945467943994104, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.8511170000001584, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4892\n",
      "Class:1.0/N=533\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=710\n",
      "Class:1.0/N=533\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 794.925ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 18, 58, 56, 355188)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.15371621621621623, 'recall': 0.6791044776119403, 'f1-score': 0.25068870523415976, 'support': 134.0, 'confusion_matrix': [[722, 501], [43, 91]], 'auc': 0.6654116986612318, 'n': 1357, 'tn': 722, 'fp': 501, 'fn': 43, 'tp': 91, 'dor': 3.049807362020146}, 'calibration': {'slope': 0.5649371527567905, 'intercept': 0.35769438348938787}, 'clinical_usefulness': {'treated': -0.7943994104642593, 'treated_all': -2.0041758781626133, 'untreated': 0.5184756290135804, 'overall': -0.275923781450679, 'prevalence': 0.09874723655121592, 'adapt': 0.12461311717022841, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.8355850000007194, 'explain': 3.300000025774352e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4879\n",
      "Class:1.0/N=546\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=546\n",
      "Class:1.0/N=546\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 212.225ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 3, 43, 427974)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2314540059347181, 'recall': 0.6446280991735537, 'f1-score': 0.34061135371179035, 'support': 121.0, 'confusion_matrix': [[977, 259], [43, 78]], 'auc': 0.782051539222766, 'n': 1357, 'tn': 977, 'fp': 259, 'fn': 43, 'tp': 78, 'dor': 6.842596749573494}, 'calibration': {'slope': 1.4761493105128423, 'intercept': 0.2527911843628927}, 'clinical_usefulness': {'treated': -0.38786538933922865, 'treated_all': -2.036109064112011, 'untreated': 0.7063901463311928, 'overall': 0.31852475699196414, 'prevalence': 0.08916728076639646, 'adapt': 0.3781134856300663, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.2488419999990583, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4878\n",
      "Class:1.0/N=547\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=547\n",
      "Class:1.0/N=547\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 895.786ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 8, 21, 733690)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1228878648233487, 'recall': 0.6666666666666666, 'f1-score': 0.20752269779507135, 'support': 120.0, 'confusion_matrix': [[666, 571], [40, 80]], 'auc': 0.626347345728914, 'n': 1357, 'tn': 666, 'fp': 571, 'fn': 40, 'tp': 80, 'dor': 2.3327495621716285}, 'calibration': {'slope': 0.5206827809967519, 'intercept': 0.34226982634786496}, 'clinical_usefulness': {'treated': -0.9228690739376073, 'treated_all': -2.038565463031196, 'untreated': 0.4781555953258238, 'overall': -0.4447134786117835, 'prevalence': 0.08843036109064112, 'adapt': 0.05784819454679441, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.8999620000013238, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4876\n",
      "Class:1.0/N=549\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=549\n",
      "Class:1.0/N=549\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 382.345ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 13, 1, 1188)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.12135922330097088, 'recall': 0.635593220338983, 'f1-score': 0.20380434782608695, 'support': 118.0, 'confusion_matrix': [[696, 543], [43, 75]], 'auc': 0.6213252896677199, 'n': 1357, 'tn': 696, 'fp': 543, 'fn': 43, 'tp': 75, 'dor': 2.2356417833740205}, 'calibration': {'slope': 0.32369863933373055, 'intercept': 0.32356894790575924}, 'clinical_usefulness': {'treated': -0.8784082535003684, 'treated_all': -2.043478260869565, 'untreated': 0.49931571744394143, 'overall': -0.379092536056427, 'prevalence': 0.08695652173913043, 'adapt': 0.0859985261606484, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.4196159999992233, 'explain': 2.199999835283961e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4879\n",
      "Class:1.0/N=546\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=546\n",
      "Class:1.0/N=546\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 256.366ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 17, 32, 755483)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1332263242375602, 'recall': 0.6859504132231405, 'f1-score': 0.2231182795698925, 'support': 121.0, 'confusion_matrix': [[696, 540], [38, 83]], 'auc': 0.6629757415282569, 'n': 1357, 'tn': 696, 'fp': 540, 'fn': 38, 'tp': 83, 'dor': 2.815204678362573}, 'calibration': {'slope': 0.32092468682166897, 'intercept': 0.39143169208694284}, 'clinical_usefulness': {'treated': -0.8673544583640382, 'treated_all': -2.036109064112011, 'untreated': 0.5008948310348458, 'overall': -0.36645962732919246, 'prevalence': 0.08916728076639646, 'adapt': 0.09042004421518052, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 3.29272200000014, 'explain': 9.800000043469481e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4915\n",
      "Class:1.0/N=510\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=510\n",
      "Class:1.0/N=510\n",
      "*** Training of model 'LogisticRegression' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 519.344ms\n",
      "\n",
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'LogisticRegression', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 48, 754913)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.16974789915966387, 'recall': 0.643312101910828, 'f1-score': 0.26861702127659576, 'support': 157.0, 'confusion_matrix': [[706, 494], [56, 101]], 'auc': 0.6386013800424628, 'n': 1357, 'tn': 706, 'fp': 494, 'fn': 56, 'tp': 101, 'dor': 2.5775737420474263}, 'calibration': {'slope': 0.3140976410286634, 'intercept': 0.38420213738797093}, 'clinical_usefulness': {'treated': -0.7749938590027019, 'treated_all': -1.9476787030213703, 'untreated': 0.5025792188651437, 'overall': -0.27241464013755823, 'prevalence': 0.1156963890935888, 'adapt': 0.11930729550478991, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 2.5231839999996737, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.53ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 49, 159160)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.6060606060606061, 'recall': 0.16129032258064516, 'f1-score': 0.25477707006369427, 'support': 124.0, 'confusion_matrix': [[1220, 13], [104, 20]], 'auc': 0.5753734662376057, 'n': 1357, 'tn': 1220, 'fp': 13, 'fn': 104, 'tp': 20, 'dor': 18.04733727810651}, 'calibration': {'slope': 1.8956959389101007, 'intercept': -0.14890662964248524}, 'clinical_usefulness': {'treated': -0.007614836649471874, 'treated_all': -2.028739867354458, 'untreated': 0.8661964417307084, 'overall': 0.8585816050812366, 'prevalence': 0.09137803979366249, 'adapt': 0.6040530582166543, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.02286600000115868, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.47ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 49, 633155)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2237354085603113, 'recall': 0.7615894039735099, 'f1-score': 0.3458646616541354, 'support': 151.0, 'confusion_matrix': [[807, 399], [36, 115]], 'auc': 0.724185364567889, 'n': 1357, 'tn': 807, 'fp': 399, 'fn': 36, 'tp': 115, 'dor': 6.4609440267335}, 'calibration': {'slope': 5.5238410928813195, 'intercept': -0.23589356915044735}, 'clinical_usefulness': {'treated': -0.6013264554163595, 'treated_all': -1.9624170965364773, 'untreated': 0.5833245604800505, 'overall': -0.018001894936308993, 'prevalence': 0.11127487103905674, 'adapt': 0.2279292557111275, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.022928000000320026, 'explain': 2.300000051036477e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 21.592ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 50, 90042)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2074074074074074, 'recall': 0.7777777777777778, 'f1-score': 0.32748538011695905, 'support': 144.0, 'confusion_matrix': [[785, 428], [32, 112]], 'auc': 0.7120832188330128, 'n': 1357, 'tn': 785, 'fp': 428, 'fn': 32, 'tp': 112, 'dor': 6.419392523364485}, 'calibration': {'slope': 3.4955819403585098, 'intercept': 0.209467889332061}, 'clinical_usefulness': {'treated': -0.6534021125030705, 'treated_all': -1.9796118889707683, 'untreated': 0.5683756184861564, 'overall': -0.08502649401691409, 'prevalence': 0.10611643330876934, 'adapt': 0.20184229918938829, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.024787000000287662, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 21.149ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 50, 540231)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19366852886405958, 'recall': 0.8062015503875969, 'f1-score': 0.31231231231231227, 'support': 129.0, 'confusion_matrix': [[795, 433], [25, 104]], 'auc': 0.7280729995202383, 'n': 1357, 'tn': 795, 'fp': 433, 'fn': 25, 'tp': 104, 'dor': 7.6378752886836025}, 'calibration': {'slope': 0.08322119780331012, 'intercept': 0.445107538783614}, 'clinical_usefulness': {'treated': -0.6678948661262587, 'treated_all': -2.016457872758535, 'untreated': 0.5779555742709759, 'overall': -0.08993929185528282, 'prevalence': 0.0950626381724392, 'adapt': 0.20420044215180547, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.02347100000042701, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 25.948ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 50, 965676)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19813084112149532, 'recall': 0.8217054263565892, 'f1-score': 0.3192771084337349, 'support': 129.0, 'confusion_matrix': [[799, 429], [23, 106]], 'auc': 0.7390033583314396, 'n': 1357, 'tn': 799, 'fp': 429, 'fn': 23, 'tp': 106, 'dor': 8.583561366170061}, 'calibration': {'slope': 5.877102722950402, 'intercept': -0.16444448008246798}, 'clinical_usefulness': {'treated': -0.6595431098010316, 'treated_all': -2.016457872758535, 'untreated': 0.581534898410359, 'overall': -0.0780082113906726, 'prevalence': 0.0950626381724392, 'adapt': 0.20921149594694174, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.025078999999095686, 'explain': 1.8000000636675395e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 18.745ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 51, 362750)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.5, 'recall': 0.03007518796992481, 'f1-score': 0.05673758865248227, 'support': 133.0, 'confusion_matrix': [[1220, 4], [129, 4]], 'auc': 0.5134036070568578, 'n': 1357, 'tn': 1220, 'fp': 4, 'fn': 129, 'tp': 4, 'dor': 9.45736434108527}, 'calibration': {'slope': 2.472960586617782, 'intercept': -0.23648029330889098}, 'clinical_usefulness': {'treated': -0.00393023827069516, 'treated_all': -2.0066322770817977, 'untreated': 0.8583008737761869, 'overall': 0.8543706355054917, 'prevalence': 0.09801031687546058, 'adapt': 0.5996315401621223, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.020910000001094886, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.944ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 51, 777138)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20078740157480315, 'recall': 0.816, 'f1-score': 0.3222748815165877, 'support': 125.0, 'confusion_matrix': [[826, 406], [23, 102]], 'auc': 0.7497142857142857, 'n': 1357, 'tn': 826, 'fp': 406, 'fn': 23, 'tp': 102, 'dor': 9.02248875562219}, 'calibration': {'slope': 2.4306451704854863, 'intercept': 0.44253838726036226}, 'clinical_usefulness': {'treated': -0.6229427659051829, 'treated_all': -2.0262834684352735, 'untreated': 0.6014317296557533, 'overall': -0.021511036249429627, 'prevalence': 0.09211495946941783, 'adapt': 0.23411938098747237, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.024222000000008848, 'explain': 1.8000000636675395e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.717ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 52, 199031)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20943396226415095, 'recall': 0.8409090909090909, 'f1-score': 0.3353474320241692, 'support': 132.0, 'confusion_matrix': [[806, 419], [21, 111]], 'auc': 0.7454761904761904, 'n': 1357, 'tn': 806, 'fp': 419, 'fn': 21, 'tp': 111, 'dor': 10.167746334810774}, 'calibration': {'slope': 5.433563988655094, 'intercept': -0.137972835475758}, 'clinical_usefulness': {'treated': -0.6386637189879636, 'treated_all': -2.009088676000982, 'untreated': 0.5873249815770082, 'overall': -0.051338737410955404, 'prevalence': 0.09727339719970524, 'adapt': 0.21952837140751663, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.023477000000639237, 'explain': 2.4000000848900527e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 21.075ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 52, 690600)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2015065913370998, 'recall': 0.7697841726618705, 'f1-score': 0.3194029850746269, 'support': 139.0, 'confusion_matrix': [[794, 424], [32, 107]], 'auc': 0.7178355837497489, 'n': 1357, 'tn': 794, 'fp': 424, 'fn': 32, 'tp': 107, 'dor': 6.261645047169812}, 'calibration': {'slope': 6.1437398593845955, 'intercept': -0.23801413498634522}, 'clinical_usefulness': {'treated': -0.6502087939081307, 'treated_all': -1.9918938835666908, 'untreated': 0.5750078955679545, 'overall': -0.07520089834017618, 'prevalence': 0.10243183492999262, 'adapt': 0.2074428887251289, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.024815999999191263, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 21.515ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 53, 157806)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19318181818181818, 'recall': 0.8031496062992126, 'f1-score': 0.3114503816793893, 'support': 127.0, 'confusion_matrix': [[804, 426], [25, 102]], 'auc': 0.7287177517444466, 'n': 1357, 'tn': 804, 'fp': 426, 'fn': 25, 'tp': 102, 'dor': 7.700281690140844}, 'calibration': {'slope': 3.9821293702683596, 'intercept': 0.18328562812395222}, 'clinical_usefulness': {'treated': -0.6573323507737656, 'treated_all': -2.021370670596905, 'untreated': 0.584587851352774, 'overall': -0.07274449942099159, 'prevalence': 0.09358879882092852, 'adapt': 0.21201179071481208, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.024338000001080218, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.653ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 53, 560319)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.6875, 'recall': 0.17054263565891473, 'f1-score': 0.2732919254658385, 'support': 129.0, 'confusion_matrix': [[1218, 10], [107, 22]], 'auc': 0.5811996565916724, 'n': 1357, 'tn': 1218, 'fp': 10, 'fn': 107, 'tp': 22, 'dor': 25.042990654205607}, 'calibration': {'slope': 1.64813807043458, 'intercept': -0.1330949234237736}, 'clinical_usefulness': {'treated': -0.0009825595676737874, 'treated_all': -2.016457872758535, 'untreated': 0.8637751342246552, 'overall': 0.8627925746569814, 'prevalence': 0.0950626381724392, 'adapt': 0.6043478260869565, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.023188999999547377, 'explain': 1.8000000636675395e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 21.758ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 53, 975938)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20801526717557253, 'recall': 0.8195488721804511, 'f1-score': 0.3318112633181126, 'support': 133.0, 'confusion_matrix': [[809, 415], [24, 109]], 'auc': 0.7485932969679099, 'n': 1357, 'tn': 809, 'fp': 415, 'fn': 24, 'tp': 109, 'dor': 8.853514056224899}, 'calibration': {'slope': 5.580240590051592, 'intercept': -0.1607752390890232}, 'clinical_usefulness': {'treated': -0.6332596413657577, 'treated_all': -2.0066322770817977, 'untreated': 0.5885882724497316, 'overall': -0.04467136891602619, 'prevalence': 0.09801031687546058, 'adapt': 0.22203389830508474, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.024767000000792905, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 19.932ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 54, 391099)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17988394584139264, 'recall': 0.788135593220339, 'f1-score': 0.2929133858267716, 'support': 118.0, 'confusion_matrix': [[815, 424], [25, 93]], 'auc': 0.7299387149286604, 'n': 1357, 'tn': 815, 'fp': 424, 'fn': 25, 'tp': 93, 'dor': 7.150471698113208}, 'calibration': {'slope': 6.66124169248858, 'intercept': -0.19825043984810398}, 'clinical_usefulness': {'treated': -0.6605256693687055, 'treated_all': -2.043478260869565, 'untreated': 0.5926939677860827, 'overall': -0.06783170158262275, 'prevalence': 0.08695652173913043, 'adapt': 0.21672807663964622, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.022434000000430387, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 21.508ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 54, 818142)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21468926553672316, 'recall': 0.8382352941176471, 'f1-score': 0.3418290854572714, 'support': 136.0, 'confusion_matrix': [[804, 417], [22, 114]], 'auc': 0.7489551717492894, 'n': 1357, 'tn': 804, 'fp': 417, 'fn': 22, 'tp': 114, 'dor': 9.990843688685416}, 'calibration': {'slope': 5.317226317662239, 'intercept': -0.14155141843836738}, 'clinical_usefulness': {'treated': -0.6330140014738392, 'treated_all': -1.9992630803242442, 'untreated': 0.5855353195073166, 'overall': -0.04747868196652261, 'prevalence': 0.10022107590272661, 'adapt': 0.2199705232129698, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.024746999999479158, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 22.639ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 55, 247463)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1950286806883365, 'recall': 0.7611940298507462, 'f1-score': 0.3105022831050228, 'support': 134.0, 'confusion_matrix': [[802, 421], [32, 102]], 'auc': 0.7064900355133572, 'n': 1357, 'tn': 802, 'fp': 421, 'fn': 32, 'tp': 102, 'dor': 6.072149643705464}, 'calibration': {'slope': 6.383202551884596, 'intercept': -0.2449075722605325}, 'clinical_usefulness': {'treated': -0.6487349545566199, 'treated_all': -2.0041758781626133, 'untreated': 0.5809032529739973, 'overall': -0.06783170158262264, 'prevalence': 0.09874723655121592, 'adapt': 0.21201179071481205, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.025971999999455875, 'explain': 2.2000000171829015e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 21.496ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 55, 663548)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.5964912280701754, 'recall': 0.25757575757575757, 'f1-score': 0.35978835978835977, 'support': 132.0, 'confusion_matrix': [[1202, 23], [98, 34]], 'auc': 0.619400123685838, 'n': 1357, 'tn': 1202, 'fp': 23, 'fn': 98, 'tp': 34, 'dor': 18.13132209405501}, 'calibration': {'slope': 1.9189931113067802, 'intercept': -0.14466255762158808}, 'clinical_usefulness': {'treated': -0.0144927536231884, 'treated_all': -2.009088676000982, 'untreated': 0.8548268238761975, 'overall': 0.8403340702530091, 'prevalence': 0.09727339719970524, 'adapt': 0.5940309506263817, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.02439799999956449, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.144ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 56, 73443)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18081180811808117, 'recall': 0.7480916030534351, 'f1-score': 0.2912332838038633, 'support': 131.0, 'confusion_matrix': [[782, 444], [33, 98]], 'auc': 0.698389225807255, 'n': 1357, 'tn': 782, 'fp': 444, 'fn': 33, 'tp': 98, 'dor': 5.230412230412231}, 'calibration': {'slope': 7.126455613722658, 'intercept': -0.28854734109492985}, 'clinical_usefulness': {'treated': -0.6912306558585112, 'treated_all': -2.011545074920167, 'untreated': 0.5658490367407095, 'overall': -0.12538161911780166, 'prevalence': 0.09653647752394989, 'adapt': 0.18872512896094323, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.02241899999899033, 'explain': 3.099999958067201e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 22.664ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 56, 505003)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20801526717557253, 'recall': 0.7956204379562044, 'f1-score': 0.329803328290469, 'support': 137.0, 'confusion_matrix': [[805, 415], [28, 109]], 'auc': 0.7309949742730645, 'n': 1357, 'tn': 805, 'fp': 415, 'fn': 28, 'tp': 109, 'dor': 7.551204819277109}, 'calibration': {'slope': 2.8745647613344354, 'intercept': 0.331597788338445}, 'clinical_usefulness': {'treated': -0.6332596413657577, 'treated_all': -1.9968066814050593, 'untreated': 0.5843773028739867, 'overall': -0.04888233849177104, 'prevalence': 0.10095799557848195, 'adapt': 0.21908621960206331, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.025456999999732943, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 33.149ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 56, 978797)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20555555555555555, 'recall': 0.7928571428571428, 'f1-score': 0.3264705882352941, 'support': 140.0, 'confusion_matrix': [[788, 429], [29, 111]], 'auc': 0.7185966662753844, 'n': 1357, 'tn': 788, 'fp': 429, 'fn': 29, 'tp': 111, 'dor': 7.030624547865927}, 'calibration': {'slope': 5.88028309808469, 'intercept': -0.20872485905074178}, 'clinical_usefulness': {'treated': -0.6558585114222549, 'treated_all': -1.9894374846475065, 'untreated': 0.5715338456679651, 'overall': -0.08432466575428987, 'prevalence': 0.10316875460574797, 'adapt': 0.20331613854089903, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.036391999999978, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 21.66ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 57, 407670)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1947069943289225, 'recall': 0.7923076923076923, 'f1-score': 0.31259484066767834, 'support': 130.0, 'confusion_matrix': [[801, 426], [27, 103]], 'auc': 0.7276691116544416, 'n': 1357, 'tn': 801, 'fp': 426, 'fn': 27, 'tp': 103, 'dor': 7.172926447574335}, 'calibration': {'slope': 6.169092474132372, 'intercept': -0.201166058939099}, 'clinical_usefulness': {'treated': -0.6565954310980103, 'treated_all': -2.014001473839351, 'untreated': 0.5817454468891462, 'overall': -0.07484998420886413, 'prevalence': 0.09579955784819455, 'adapt': 0.2102431834929992, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.02438399999846297, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 22.022ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 57, 820775)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.5238095238095238, 'recall': 0.17886178861788618, 'f1-score': 0.2666666666666667, 'support': 123.0, 'confusion_matrix': [[1214, 20], [101, 22]], 'auc': 0.5809944525701335, 'n': 1357, 'tn': 1214, 'fp': 20, 'fn': 101, 'tp': 22, 'dor': 13.221782178217824}, 'calibration': {'slope': 2.2371192482177573, 'intercept': -0.17182436811406354}, 'clinical_usefulness': {'treated': -0.018177352001965113, 'treated_all': -2.0311962662736427, 'untreated': 0.862722391830719, 'overall': 0.8445450398287538, 'prevalence': 0.09064112011790715, 'adapt': 0.5984524686809137, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.025287000000389526, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 24.986ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 58, 242152)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1958174904942966, 'recall': 0.8110236220472441, 'f1-score': 0.31546707503828486, 'support': 127.0, 'confusion_matrix': [[807, 423], [24, 103]], 'auc': 0.7389091607451507, 'n': 1357, 'tn': 807, 'fp': 423, 'fn': 24, 'tp': 103, 'dor': 8.187647754137116}, 'calibration': {'slope': 5.9900676667585095, 'intercept': -0.17299834416631077}, 'clinical_usefulness': {'treated': -0.6514369933677229, 'treated_all': -2.021370670596905, 'untreated': 0.5871144330982209, 'overall': -0.064322560269502, 'prevalence': 0.09358879882092852, 'adapt': 0.21554900515843772, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.02790599999934784, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 21.061ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 58, 664613)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1947565543071161, 'recall': 0.8, 'f1-score': 0.3132530120481928, 'support': 130.0, 'confusion_matrix': [[797, 430], [26, 104]], 'auc': 0.7240862641840637, 'n': 1357, 'tn': 797, 'fp': 430, 'fn': 26, 'tp': 104, 'dor': 7.413953488372093}, 'calibration': {'slope': 6.12877184965184, 'intercept': -0.1936185517440171}, 'clinical_usefulness': {'treated': -0.6627364283959715, 'treated_all': -2.014001473839351, 'untreated': 0.5791135909043057, 'overall': -0.08362283749166577, 'prevalence': 0.09579955784819455, 'adapt': 0.20655858511422248, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.023823999999876833, 'explain': 3.199999991920777e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.569ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 59, 81288)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21946564885496184, 'recall': 0.7876712328767124, 'f1-score': 0.3432835820895523, 'support': 146.0, 'confusion_matrix': [[802, 409], [31, 115]], 'auc': 0.7378737146929403, 'n': 1357, 'tn': 802, 'fp': 409, 'fn': 31, 'tp': 115, 'dor': 7.274232983673792}, 'calibration': {'slope': 5.485646393792687, 'intercept': -0.20391338283730176}, 'clinical_usefulness': {'treated': -0.6185212478506509, 'treated_all': -1.9746990911323994, 'untreated': 0.5812190756921781, 'overall': -0.03730217215847276, 'prevalence': 0.10759027266028003, 'adapt': 0.2212969786293294, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.02302100000088103, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.051ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': None, 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 21, 59, 495247)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20037105751391465, 'recall': 0.7883211678832117, 'f1-score': 0.3195266272189349, 'support': 137.0, 'confusion_matrix': [[789, 431], [29, 108]], 'auc': 0.716818236209166, 'n': 1357, 'tn': 789, 'fp': 431, 'fn': 29, 'tp': 108, 'dor': 6.817505400432034}, 'calibration': {'slope': 4.232307933633468, 'intercept': 0.10641516956899708}, 'clinical_usefulness': {'treated': -0.6615082289363792, 'treated_all': -1.9968066814050593, 'untreated': 0.5722707653437203, 'overall': -0.08923746359265883, 'prevalence': 0.10095799557848195, 'adapt': 0.20213706705969045, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.022417000000132248, 'explain': 2.0000001313746907e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4881\n",
      "Class:1.0/N=544\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 796, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 814, in _sample\n",
      "    X_class, nns, n_samples, 1.0)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 21.963ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 0, 3379)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.6875, 'recall': 0.17886178861788618, 'f1-score': 0.2838709677419355, 'support': 123.0, 'confusion_matrix': [[1224, 10], [101, 22]], 'auc': 0.5853790304515687, 'n': 1357, 'tn': 1224, 'fp': 10, 'fn': 101, 'tp': 22, 'dor': 26.661386138613864}, 'calibration': {'slope': 1.6359286982020218, 'intercept': -0.12470098001388996}, 'clinical_usefulness': {'treated': -0.0009825595676737874, 'treated_all': -2.0311962662736427, 'untreated': 0.8700915885882724, 'overall': 0.8691090290205986, 'prevalence': 0.09064112011790715, 'adapt': 0.6087693441414885, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.026310999999623164, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4883\n",
      "Class:1.0/N=542\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 796, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 814, in _sample\n",
      "    X_class, nns, n_samples, 1.0)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 22.087ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 0, 544458)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.197265625, 'recall': 0.808, 'f1-score': 0.31711145996860285, 'support': 125.0, 'confusion_matrix': [[821, 411], [24, 101]], 'auc': 0.7376071428571428, 'n': 1357, 'tn': 821, 'fp': 411, 'fn': 24, 'tp': 101, 'dor': 8.406427412814274}, 'calibration': {'slope': 5.921922313787716, 'intercept': -0.16819170644777226}, 'clinical_usefulness': {'treated': -0.632277081798084, 'treated_all': -2.0262834684352735, 'untreated': 0.5974313085587957, 'overall': -0.03484577323928828, 'prevalence': 0.09211495946941783, 'adapt': 0.22851879145173176, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.025706000000354834, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=544\n",
      "Class:0.0/N=4881\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 796, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 814, in _sample\n",
      "    X_class, nns, n_samples, 1.0)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 21.69ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 1, 39283)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1801470588235294, 'recall': 0.7967479674796748, 'f1-score': 0.29385307346326833, 'support': 123.0, 'confusion_matrix': [[788, 446], [25, 98]], 'auc': 0.7196769050348526, 'n': 1357, 'tn': 788, 'fp': 446, 'fn': 25, 'tp': 98, 'dor': 6.925919282511211}, 'calibration': {'slope': 6.693389492054031, 'intercept': -0.20579443575617284}, 'clinical_usefulness': {'treated': -0.6946696143453694, 'treated_all': -2.0311962662736427, 'untreated': 0.5727971365406885, 'overall': -0.12187247780468091, 'prevalence': 0.09064112011790715, 'adapt': 0.19255711127487107, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.026208999999653315, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=520\n",
      "Class:0.0/N=4905\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 796, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 814, in _sample\n",
      "    X_class, nns, n_samples, 1.0)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.863ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 1, 523970)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.22023809523809523, 'recall': 0.7551020408163265, 'f1-score': 0.3410138248847926, 'support': 147.0, 'confusion_matrix': [[817, 393], [36, 111]], 'auc': 0.720543093270366, 'n': 1357, 'tn': 817, 'fp': 393, 'fn': 36, 'tp': 111, 'dor': 6.409881255301102}, 'calibration': {'slope': 5.616901181954547, 'intercept': -0.2370556177951343}, 'clinical_usefulness': {'treated': -0.5939572586588061, 'treated_all': -1.972242692213215, 'untreated': 0.590693757237604, 'overall': -0.0032635014212021307, 'prevalence': 0.10832719233603537, 'adapt': 0.23529845246868092, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.024396000000706408, 'explain': 2.2000000171829015e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4878\n",
      "Class:1.0/N=547\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 796, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 814, in _sample\n",
      "    X_class, nns, n_samples, 1.0)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 23.274ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 2, 10122)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18045112781954886, 'recall': 0.8, 'f1-score': 0.294478527607362, 'support': 120.0, 'confusion_matrix': [[801, 436], [24, 96]], 'auc': 0.7299178119105363, 'n': 1357, 'tn': 801, 'fp': 436, 'fn': 24, 'tp': 96, 'dor': 7.348623853211009}, 'calibration': {'slope': 6.605289203743345, 'intercept': -0.19204026806542707}, 'clinical_usefulness': {'treated': -0.6789486612625888, 'treated_all': -2.038565463031196, 'untreated': 0.5826929150436888, 'overall': -0.09625574621889998, 'prevalence': 0.08843036109064112, 'adapt': 0.2042004421518055, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.027596000001722132, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=537\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=1222\n",
      "*** Training of model 'SGDClassifier' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 25.116ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 2, 498864)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.326271186440678, 'recall': 0.5923076923076923, 'f1-score': 0.4207650273224044, 'support': 130.0, 'confusion_matrix': [[1068, 159], [53, 77]], 'auc': 0.7308632687605793, 'n': 1357, 'tn': 1068, 'fp': 159, 'fn': 53, 'tp': 77, 'dor': 9.758632965468138}, 'calibration': {'slope': 3.5843325339728214, 'intercept': -0.1694644284572342}, 'clinical_usefulness': {'treated': -0.21665438467207068, 'treated_all': -2.014001473839351, 'untreated': 0.7702916096431204, 'overall': 0.5536372249710497, 'prevalence': 0.09579955784819455, 'adapt': 0.47420781134856305, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03184700000019802, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4883\n",
      "Class:1.0/N=542\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4883\n",
      "Class:1.0/N=1220\n",
      "*** Training of model 'SGDClassifier' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 24.464ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 2, 994352)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19066147859922178, 'recall': 0.784, 'f1-score': 0.30672926447574334, 'support': 125.0, 'confusion_matrix': [[816, 416], [27, 98]], 'auc': 0.7240649350649351, 'n': 1357, 'tn': 816, 'fp': 416, 'fn': 27, 'tp': 98, 'dor': 7.119658119658119}, 'calibration': {'slope': 6.303858240223362, 'intercept': -0.20190293296089074}, 'clinical_usefulness': {'treated': -0.6430852370424956, 'treated_all': -2.0262834684352735, 'untreated': 0.5927992420254764, 'overall': -0.05028599501701925, 'prevalence': 0.09211495946941783, 'adapt': 0.22203389830508474, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03157199999986915, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=532\n",
      "Class:0.0/N=4893\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=1223\n",
      "Class:0.0/N=4893\n",
      "*** Training of model 'SGDClassifier' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 24.414ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 3, 497387)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1890909090909091, 'recall': 0.7703703703703704, 'f1-score': 0.30364963503649633, 'support': 135.0, 'confusion_matrix': [[776, 446], [31, 104]], 'auc': 0.7034703279384131, 'n': 1357, 'tn': 776, 'fp': 446, 'fn': 31, 'tp': 104, 'dor': 5.8371184724432235}, 'calibration': {'slope': 5.124905916594082, 'intercept': -0.007616835141004197}, 'clinical_usefulness': {'treated': -0.6902480962908374, 'treated_all': -2.001719479243429, 'untreated': 0.5620591641225392, 'overall': -0.1281889321682982, 'prevalence': 0.09948415622697127, 'adapt': 0.1863669859985262, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.031070000000909204, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4893\n",
      "Class:1.0/N=532\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4893\n",
      "Class:1.0/N=1223\n",
      "*** Training of model 'SGDClassifier' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 24.507ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 4, 1847)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1989051094890511, 'recall': 0.8074074074074075, 'f1-score': 0.3191800878477306, 'support': 135.0, 'confusion_matrix': [[783, 439], [26, 109]], 'auc': 0.7275959265320968, 'n': 1357, 'tn': 783, 'fp': 439, 'fn': 26, 'tp': 109, 'dor': 7.477396180129666}, 'calibration': {'slope': 5.99640101141894, 'intercept': -0.1927149892402774}, 'clinical_usefulness': {'treated': -0.6745271432080568, 'treated_all': -2.001719479243429, 'untreated': 0.5687967154437309, 'overall': -0.10573042776432595, 'prevalence': 0.09948415622697127, 'adapt': 0.1957995578481945, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03052399999978661, 'explain': 2.700000004551839e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=537\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=1222\n",
      "*** Training of model 'SGDClassifier' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 23.338ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 4, 502041)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1927927927927928, 'recall': 0.823076923076923, 'f1-score': 0.31240875912408755, 'support': 130.0, 'confusion_matrix': [[779, 448], [23, 107]], 'auc': 0.7302394834179675, 'n': 1357, 'tn': 779, 'fp': 448, 'fn': 23, 'tp': 107, 'dor': 8.089382763975156}, 'calibration': {'slope': 6.093307232092842, 'intercept': -0.17474571862610383}, 'clinical_usefulness': {'treated': -0.6914762957504297, 'treated_all': -2.014001473839351, 'untreated': 0.5667965048952521, 'overall': -0.12467979085517755, 'prevalence': 0.09579955784819455, 'adapt': 0.1893146647015475, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.030058000000281027, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4901\n",
      "Class:1.0/N=524\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4901\n",
      "Class:1.0/N=2450\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 31.122ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 5, 28155)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.45517241379310347, 'recall': 0.46153846153846156, 'f1-score': 0.45833333333333337, 'support': 143.0, 'confusion_matrix': [[1135, 79], [77, 66]], 'auc': 0.7015011347795532, 'n': 1357, 'tn': 1135, 'fp': 79, 'fn': 77, 'tp': 66, 'dor': 12.314647377938519}, 'calibration': {'slope': 2.5533584203873483, 'intercept': -0.1622183154866551}, 'clinical_usefulness': {'treated': -0.08720216163104885, 'treated_all': -1.9820682878899532, 'untreated': 0.8120854826823877, 'overall': 0.7248833210513388, 'prevalence': 0.105379513633014, 'adapt': 0.5422991893883566, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03745399999934307, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4879\n",
      "Class:1.0/N=546\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4879\n",
      "Class:1.0/N=2439\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 30.269ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 5, 558824)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1830188679245283, 'recall': 0.8016528925619835, 'f1-score': 0.2980030721966206, 'support': 121.0, 'confusion_matrix': [[803, 433], [24, 97]], 'auc': 0.7355271603947686, 'n': 1357, 'tn': 803, 'fp': 433, 'fn': 24, 'tp': 97, 'dor': 7.495284834488068}, 'calibration': {'slope': 4.983275446971463, 'intercept': 0.05608401367604343}, 'clinical_usefulness': {'treated': -0.6730533038565462, 'treated_all': -2.036109064112011, 'untreated': 0.5841667543951995, 'overall': -0.08888654946134666, 'prevalence': 0.08916728076639646, 'adapt': 0.20700073691967577, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03749700000116718, 'explain': 2.2999998691375367e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=540\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=2442\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 31.044ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 6, 95582)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18297101449275363, 'recall': 0.7952755905511811, 'f1-score': 0.2974963181148748, 'support': 127.0, 'confusion_matrix': [[779, 451], [26, 101]], 'auc': 0.7118910441072914, 'n': 1357, 'tn': 779, 'fp': 451, 'fn': 26, 'tp': 101, 'dor': 6.70979020979021}, 'calibration': {'slope': 6.6368945379594635, 'intercept': -0.21435932669185842}, 'clinical_usefulness': {'treated': -0.7010562515352492, 'treated_all': -2.021370670596905, 'untreated': 0.5658490367407095, 'overall': -0.13520721479453968, 'prevalence': 0.09358879882092852, 'adapt': 0.18577745025792183, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03796700000020792, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4887\n",
      "Class:1.0/N=538\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4887\n",
      "Class:1.0/N=2443\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 29.535ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 6, 613225)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2099236641221374, 'recall': 0.8527131782945736, 'f1-score': 0.33690658499234305, 'support': 129.0, 'confusion_matrix': [[814, 414], [19, 110]], 'auc': 0.7557855465495038, 'n': 1357, 'tn': 814, 'fp': 414, 'fn': 19, 'tp': 110, 'dor': 11.383168065090263}, 'calibration': {'slope': 5.344319648683292, 'intercept': -0.12189924768884802}, 'clinical_usefulness': {'treated': -0.6308032424465733, 'treated_all': -2.016457872758535, 'untreated': 0.5938519844194126, 'overall': -0.036951258027160705, 'prevalence': 0.0950626381724392, 'adapt': 0.22645541635961675, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.036102000000028056, 'explain': 2.700000004551839e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4887\n",
      "Class:1.0/N=538\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4887\n",
      "Class:1.0/N=2443\n",
      "*** Training of model 'SGDClassifier' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 29.956ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 7, 124322)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19705340699815838, 'recall': 0.8294573643410853, 'f1-score': 0.318452380952381, 'support': 129.0, 'confusion_matrix': [[792, 436], [22, 107]], 'auc': 0.7432801807943843, 'n': 1357, 'tn': 792, 'fp': 436, 'fn': 22, 'tp': 107, 'dor': 8.8348623853211}, 'calibration': {'slope': 5.881440184559576, 'intercept': -0.15895784282593445}, 'clinical_usefulness': {'treated': -0.6708425448292801, 'treated_all': -2.016457872758535, 'untreated': 0.5766922833982525, 'overall': -0.09415026143102756, 'prevalence': 0.0950626381724392, 'adapt': 0.2024318349299927, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.035944999999628635, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4886\n",
      "Class:1.0/N=539\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4886\n",
      "Class:1.0/N=3664\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 33.497ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 7, 645126)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.6349206349206349, 'recall': 0.3125, 'f1-score': 0.418848167539267, 'support': 128.0, 'confusion_matrix': [[1206, 23], [88, 40]], 'auc': 0.646613100081367, 'n': 1357, 'tn': 1206, 'fp': 23, 'fn': 88, 'tp': 40, 'dor': 23.83399209486166}, 'calibration': {'slope': 1.7639345681149388, 'intercept': -0.11995845594599275}, 'clinical_usefulness': {'treated': -0.010071235568656346, 'treated_all': -2.01891427167772, 'untreated': 0.8609327297610274, 'overall': 0.8508614941923711, 'prevalence': 0.09432571849668386, 'adapt': 0.5996315401621222, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04019900000093912, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=529\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=3672\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 36.86ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 8, 228888)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20866141732283464, 'recall': 0.7681159420289855, 'f1-score': 0.32817337461300305, 'support': 138.0, 'confusion_matrix': [[817, 402], [32, 106]], 'auc': 0.7280973951088442, 'n': 1357, 'tn': 817, 'fp': 402, 'fn': 32, 'tp': 106, 'dor': 6.7321206467661705}, 'calibration': {'slope': 5.848975401202777, 'intercept': -0.22045608107884174}, 'clinical_usefulness': {'treated': -0.613117170228445, 'treated_all': -1.9943502824858752, 'untreated': 0.5919570481103273, 'overall': -0.021160122118117686, 'prevalence': 0.1016949152542373, 'adapt': 0.2304347826086956, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.044135000000096625, 'explain': 3.199999991920777e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=524\n",
      "Class:0.0/N=4901\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=3675\n",
      "Class:0.0/N=4901\n",
      "*** Training of model 'SGDClassifier' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 34.152ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 8, 740599)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21454545454545454, 'recall': 0.8251748251748252, 'f1-score': 0.34054834054834054, 'support': 143.0, 'confusion_matrix': [[782, 432], [25, 118]], 'auc': 0.7449107729173626, 'n': 1357, 'tn': 782, 'fp': 432, 'fn': 25, 'tp': 118, 'dor': 8.544074074074073}, 'calibration': {'slope': 5.447264511625873, 'intercept': -0.16875044955470392}, 'clinical_usefulness': {'treated': -0.6558585114222548, 'treated_all': -1.9820682878899532, 'untreated': 0.5683756184861565, 'overall': -0.08748289293609834, 'prevalence': 0.105379513633014, 'adapt': 0.20110537951363303, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04146700000092096, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4881\n",
      "Class:1.0/N=544\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4881\n",
      "Class:1.0/N=3660\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 33.321ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 9, 257301)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1678832116788321, 'recall': 0.7479674796747967, 'f1-score': 0.27421758569299554, 'support': 123.0, 'confusion_matrix': [[778, 456], [31, 92]], 'auc': 0.694153456931652, 'n': 1357, 'tn': 778, 'fp': 456, 'fn': 31, 'tp': 92, 'dor': 5.063384267119411}, 'calibration': {'slope': 7.717966531886771, 'intercept': -0.2957170091679252}, 'clinical_usefulness': {'treated': -0.7162859248341928, 'treated_all': -2.0311962662736427, 'untreated': 0.5635330034740499, 'overall': -0.15275292136014296, 'prevalence': 0.09064112011790715, 'adapt': 0.17958732498157703, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.041379000000233646, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=540\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=3663\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 32.939ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 9, 777201)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20475319926873858, 'recall': 0.8818897637795275, 'f1-score': 0.33234421364985167, 'support': 127.0, 'confusion_matrix': [[795, 435], [15, 112]], 'auc': 0.7718327891940338, 'n': 1357, 'tn': 795, 'fp': 435, 'fn': 15, 'tp': 112, 'dor': 13.645977011494253}, 'calibration': {'slope': 5.369176377321494, 'intercept': -0.09942919217235713}, 'clinical_usefulness': {'treated': -0.6654384672070743, 'treated_all': -2.021370670596905, 'untreated': 0.5811138014527845, 'overall': -0.08432466575428987, 'prevalence': 0.09358879882092852, 'adapt': 0.20714812085482678, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.039576999999553664, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=512\n",
      "Class:0.0/N=4913\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=4913\n",
      "Class:0.0/N=4913\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 40.337ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 10, 313090)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19166666666666668, 'recall': 0.8903225806451613, 'f1-score': 0.31542857142857145, 'support': 155.0, 'confusion_matrix': [[620, 582], [17, 138]], 'auc': 0.7024260640867371, 'n': 1357, 'tn': 620, 'fp': 582, 'fn': 17, 'tp': 138, 'dor': 8.647665251667677}, 'calibration': {'slope': 6.061374990087994, 'intercept': -0.16176353976686564}, 'clinical_usefulness': {'treated': -0.8990420044215179, 'treated_all': -1.9525915008597392, 'untreated': 0.4515212127592378, 'overall': -0.44752079166228015, 'prevalence': 0.11422254974207811, 'adapt': 0.046352247605011, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.048049999999420834, 'explain': 2.0000001313746907e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=537\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=4888\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 38.953ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 10, 851555)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20415879017013233, 'recall': 0.8307692307692308, 'f1-score': 0.3277693474962064, 'support': 130.0, 'confusion_matrix': [[806, 421], [22, 108]], 'auc': 0.7462604225440411, 'n': 1357, 'tn': 806, 'fp': 421, 'fn': 22, 'tp': 108, 'dor': 9.398402072986396}, 'calibration': {'slope': 3.8229687196589315, 'intercept': 0.18247855937000046}, 'clinical_usefulness': {'treated': -0.6443134365020879, 'treated_all': -2.014001473839351, 'untreated': 0.5870091588588273, 'overall': -0.057304277643260626, 'prevalence': 0.09579955784819455, 'adapt': 0.21761238025055268, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04610600000160048, 'explain': 1.8000000636675395e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4886\n",
      "Class:1.0/N=539\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4886\n",
      "Class:1.0/N=4886\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 40.51ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 11, 391480)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18333333333333332, 'recall': 0.7734375, 'f1-score': 0.29640718562874246, 'support': 128.0, 'confusion_matrix': [[788, 441], [29, 99]], 'auc': 0.7124345250203417, 'n': 1357, 'tn': 788, 'fp': 441, 'fn': 29, 'tp': 99, 'dor': 6.099929627023223}, 'calibration': {'slope': 4.668544217366724, 'intercept': 0.09376158082208491}, 'clinical_usefulness': {'treated': -0.6853352984524685, 'treated_all': -2.01891427167772, 'untreated': 0.5715338456679651, 'overall': -0.11380145278450349, 'prevalence': 0.09432571849668386, 'adapt': 0.19447310243183494, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04780199999913748, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4886\n",
      "Class:1.0/N=539\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4886\n",
      "Class:1.0/N=4886\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 39.844ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 11, 939933)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18231046931407943, 'recall': 0.7890625, 'f1-score': 0.2961876832844575, 'support': 128.0, 'confusion_matrix': [[776, 453], [27, 101]], 'auc': 0.7101651495117982, 'n': 1357, 'tn': 776, 'fp': 453, 'fn': 27, 'tp': 101, 'dor': 6.407979723653012}, 'calibration': {'slope': 6.725531093043486, 'intercept': -0.22613472995919148}, 'clinical_usefulness': {'treated': -0.7044952100221075, 'treated_all': -2.01891427167772, 'untreated': 0.5633224549952627, 'overall': -0.1411727550268448, 'prevalence': 0.09432571849668386, 'adapt': 0.18297715549005159, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.047602000000551925, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with SMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=530\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=4895\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 39.961ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'SMOTE', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 12, 480755)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2071563088512241, 'recall': 0.8029197080291971, 'f1-score': 0.32934131736526945, 'support': 137.0, 'confusion_matrix': [[799, 421], [27, 110]], 'auc': 0.7322902955606079, 'n': 1357, 'tn': 799, 'fp': 421, 'fn': 27, 'tp': 110, 'dor': 7.732031318729655}, 'calibration': {'slope': 5.73166504188872, 'intercept': -0.18735466842430543}, 'clinical_usefulness': {'treated': -0.6428395971505771, 'treated_all': -1.9968066814050593, 'untreated': 0.5802716075376355, 'overall': -0.06256798961294163, 'prevalence': 0.10095799557848195, 'adapt': 0.21333824613117167, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04672699999900942, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4869\n",
      "Class:1.0/N=556\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 335, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 364, in _sample\n",
      "    class_sample, X_class, nns, n_samples)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 22.181ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 13, 204161)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.5333333333333333, 'recall': 0.2882882882882883, 'f1-score': 0.3742690058479532, 'support': 111.0, 'confusion_matrix': [[1218, 28], [79, 32]], 'auc': 0.632622590487759, 'n': 1357, 'tn': 1218, 'fp': 28, 'fn': 79, 'tp': 32, 'dor': 17.62025316455696}, 'calibration': {'slope': 2.116744641497117, 'intercept': -0.12893047546512892}, 'clinical_usefulness': {'treated': -0.024563989191844743, 'treated_all': -2.0606730533038564, 'untreated': 0.8726181703337194, 'overall': 0.8480541811418746, 'prevalence': 0.08179808400884303, 'adapt': 0.6034635224760501, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.025432999998884043, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=529\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 335, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 364, in _sample\n",
      "    class_sample, X_class, nns, n_samples)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 21.285ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 13, 928513)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.22684310018903592, 'recall': 0.8695652173913043, 'f1-score': 0.35982008995502246, 'support': 138.0, 'confusion_matrix': [[810, 409], [18, 120]], 'auc': 0.7752434283268539, 'n': 1357, 'tn': 810, 'fp': 409, 'fn': 18, 'tp': 120, 'dor': 13.202933985330073}, 'calibration': {'slope': 4.875576036553789, 'intercept': -0.10599078333923384}, 'clinical_usefulness': {'treated': -0.6148366494718742, 'treated_all': -1.9943502824858752, 'untreated': 0.5912201284345721, 'overall': -0.023616521037302163, 'prevalence': 0.1016949152542373, 'adapt': 0.22940309506263812, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.024527999999918393, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4880\n",
      "Class:1.0/N=545\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 335, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 364, in _sample\n",
      "    class_sample, X_class, nns, n_samples)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.407ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 14, 640875)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20300751879699247, 'recall': 0.8852459016393442, 'f1-score': 0.33027522935779813, 'support': 122.0, 'confusion_matrix': [[811, 424], [14, 108]], 'auc': 0.7703192407247628, 'n': 1357, 'tn': 811, 'fp': 424, 'fn': 14, 'tp': 108, 'dor': 14.755390835579517}, 'calibration': {'slope': 5.374324213639611, 'intercept': -0.091196937466136}, 'clinical_usefulness': {'treated': -0.6494718742323753, 'treated_all': -2.0336526651928266, 'untreated': 0.5932203389830508, 'overall': -0.05625153524932447, 'prevalence': 0.0899042004421518, 'adapt': 0.22041267501842293, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.023482000000512926, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4882\n",
      "Class:1.0/N=543\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 335, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 364, in _sample\n",
      "    class_sample, X_class, nns, n_samples)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 25.263ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 15, 397521)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19305019305019305, 'recall': 0.8064516129032258, 'f1-score': 0.3115264797507788, 'support': 124.0, 'confusion_matrix': [[815, 418], [24, 100]], 'auc': 0.7411473458388927, 'n': 1357, 'tn': 815, 'fp': 418, 'fn': 24, 'tp': 100, 'dor': 8.124003189792663}, 'calibration': {'slope': 6.081048283485651, 'intercept': -0.17395132157665344}, 'clinical_usefulness': {'treated': -0.6450503561778432, 'treated_all': -2.028739867354458, 'untreated': 0.5930097905042636, 'overall': -0.05204056567357962, 'prevalence': 0.09137803979366249, 'adapt': 0.22159174649963154, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.028467000000091502, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=534\n",
      "Class:0.0/N=4891\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 335, in _fit_resample\n",
      "    return self._sample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 364, in _sample\n",
      "    class_sample, X_class, nns, n_samples)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\", line 108, in _make_samples\n",
      "    low=0, high=len(nn_num.flatten()), size=n_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 21.83ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 16, 178554)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2007366482504604, 'recall': 0.8195488721804511, 'f1-score': 0.3224852071005917, 'support': 133.0, 'confusion_matrix': [[790, 434], [24, 109]], 'auc': 0.7314149343948105, 'n': 1357, 'tn': 790, 'fp': 434, 'fn': 24, 'tp': 109, 'dor': 8.267089093701998}, 'calibration': {'slope': 5.8393267630195265, 'intercept': -0.17216688244775014}, 'clinical_usefulness': {'treated': -0.6659297469909111, 'treated_all': -2.0066322770817977, 'untreated': 0.5745867986103801, 'overall': -0.09134294838053103, 'prevalence': 0.09801031687546058, 'adapt': 0.2024318349299927, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.025247999999919557, 'explain': 1.799999881768599e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=540\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=1221\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 24.14ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 16, 912228)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.782608695652174, 'recall': 0.14173228346456693, 'f1-score': 0.24000000000000002, 'support': 127.0, 'confusion_matrix': [[1225, 5], [109, 18]], 'auc': 0.5684847320914154, 'n': 1357, 'tn': 1225, 'fp': 5, 'fn': 109, 'tp': 18, 'dor': 40.45871559633028}, 'calibration': {'slope': 1.4267379679144385, 'intercept': -0.11657754010695187}, 'clinical_usefulness': {'treated': 0.004667157946450505, 'treated_all': -2.021370670596905, 'untreated': 0.868301926518581, 'overall': 0.8729690844650314, 'prevalence': 0.09358879882092852, 'adapt': 0.6092114959469418, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.030118999999103835, 'explain': 3.5000000934815034e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4878\n",
      "Class:1.0/N=547\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4878\n",
      "Class:1.0/N=1219\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 25.123ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 17, 749263)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.16977611940298507, 'recall': 0.7583333333333333, 'f1-score': 0.2774390243902439, 'support': 120.0, 'confusion_matrix': [[792, 445], [29, 91]], 'auc': 0.6997372675828617, 'n': 1357, 'tn': 792, 'fp': 445, 'fn': 29, 'tp': 91, 'dor': 5.584812088337854}, 'calibration': {'slope': 7.437524295488542, 'intercept': -0.2627140128735296}, 'clinical_usefulness': {'treated': -0.6981085728322278, 'treated_all': -2.038565463031196, 'untreated': 0.5744815243709864, 'overall': -0.1236270484612414, 'prevalence': 0.08843036109064112, 'adapt': 0.19270449521002211, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.030831000000034692, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4897\n",
      "Class:1.0/N=528\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4897\n",
      "Class:1.0/N=1224\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 25.04ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 18, 523401)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1903914590747331, 'recall': 0.7697841726618705, 'f1-score': 0.30527817403708984, 'support': 139.0, 'confusion_matrix': [[763, 455], [32, 107]], 'auc': 0.7033437289577206, 'n': 1357, 'tn': 763, 'fp': 455, 'fn': 32, 'tp': 107, 'dor': 5.607211538461538}, 'calibration': {'slope': 0.12687407796506106, 'intercept': 0.44353311626232794}, 'clinical_usefulness': {'treated': -0.7035126504544337, 'treated_all': -1.9918938835666908, 'untreated': 0.5521633856195388, 'overall': -0.15134926483489486, 'prevalence': 0.10243183492999262, 'adapt': 0.17546057479734703, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03111400000125286, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4883\n",
      "Class:1.0/N=542\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4883\n",
      "Class:1.0/N=1220\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 26.868ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 19, 326932)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2049335863377609, 'recall': 0.864, 'f1-score': 0.3312883435582822, 'support': 125.0, 'confusion_matrix': [[813, 419], [17, 108]], 'auc': 0.7646331168831169, 'n': 1357, 'tn': 813, 'fp': 419, 'fn': 17, 'tp': 108, 'dor': 12.326828583462024}, 'calibration': {'slope': 5.421474695881817, 'intercept': -0.1110422526664826}, 'clinical_usefulness': {'treated': -0.6408744780152296, 'treated_all': -2.0262834684352735, 'untreated': 0.5937467101800189, 'overall': -0.047127767835210665, 'prevalence': 0.09211495946941783, 'adapt': 0.22336035372144428, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03312200000073062, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=547\n",
      "Class:0.0/N=4878\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=1219\n",
      "Class:0.0/N=4878\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 24.25ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 20, 128807)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18518518518518517, 'recall': 0.8333333333333334, 'f1-score': 0.303030303030303, 'support': 120.0, 'confusion_matrix': [[797, 440], [20, 100]], 'auc': 0.7468842630018864, 'n': 1357, 'tn': 797, 'fp': 440, 'fn': 20, 'tp': 100, 'dor': 9.056818181818182}, 'calibration': {'slope': 3.2194373200274926, 'intercept': 0.3465738759176827}, 'clinical_usefulness': {'treated': -0.682878899533284, 'treated_all': -2.038565463031196, 'untreated': 0.5810085272133908, 'overall': -0.10187037231989315, 'prevalence': 0.08843036109064112, 'adapt': 0.20184229918938834, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.029780000000755535, 'explain': 0.0}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4897\n",
      "Class:1.0/N=528\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4897\n",
      "Class:1.0/N=2448\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 28.611ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 20, 916022)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.5076923076923077, 'recall': 0.23741007194244604, 'f1-score': 0.3235294117647059, 'support': 139.0, 'confusion_matrix': [[1186, 32], [106, 33]], 'auc': 0.6055687469728651, 'n': 1357, 'tn': 1186, 'fp': 32, 'fn': 106, 'tp': 33, 'dor': 11.538325471698114}, 'calibration': {'slope': 2.349353773848822, 'intercept': -0.19274883903094053}, 'clinical_usefulness': {'treated': -0.030704986489805935, 'treated_all': -1.9918938835666908, 'untreated': 0.8405095273186651, 'overall': 0.8098045408288592, 'prevalence': 0.10243183492999262, 'adapt': 0.5791451731761237, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.035079000001132954, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4894\n",
      "Class:1.0/N=531\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4894\n",
      "Class:1.0/N=2447\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 33.442ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 21, 673327)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2018018018018018, 'recall': 0.8235294117647058, 'f1-score': 0.32416787264833574, 'support': 136.0, 'confusion_matrix': [[778, 443], [24, 112]], 'auc': 0.7348003083297201, 'n': 1357, 'tn': 778, 'fp': 443, 'fn': 24, 'tp': 112, 'dor': 8.19563581640331}, 'calibration': {'slope': 5.8174639250304425, 'intercept': -0.17398056622946134}, 'clinical_usefulness': {'treated': -0.6791943011545074, 'treated_all': -1.9992630803242442, 'untreated': 0.565743762501316, 'overall': -0.11345053865319144, 'prevalence': 0.10022107590272661, 'adapt': 0.1922623434045689, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.040033999999650405, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=540\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=2442\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 29.133ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 22, 431122)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1968503937007874, 'recall': 0.7874015748031497, 'f1-score': 0.31496062992125984, 'support': 127.0, 'confusion_matrix': [[822, 408], [27, 100]], 'auc': 0.7340055054093848, 'n': 1357, 'tn': 822, 'fp': 408, 'fn': 27, 'tp': 100, 'dor': 7.461873638344226}, 'calibration': {'slope': 6.0588330742625285, 'intercept': -0.19268372504891051}, 'clinical_usefulness': {'treated': -0.6278555637435519, 'treated_all': -2.021370670596905, 'untreated': 0.5972207600800085, 'overall': -0.03063480366354343, 'prevalence': 0.09358879882092852, 'adapt': 0.2296978629329403, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03519599999890488, 'explain': 1.700000029813964e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4886\n",
      "Class:1.0/N=539\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4886\n",
      "Class:1.0/N=2443\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 28.58ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 23, 177422)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2, 'recall': 0.859375, 'f1-score': 0.32448377581120946, 'support': 128.0, 'confusion_matrix': [[789, 440], [18, 110]], 'auc': 0.7519801413751017, 'n': 1357, 'tn': 789, 'fp': 440, 'fn': 18, 'tp': 110, 'dor': 10.958333333333332}, 'calibration': {'slope': 5.627615062761505, 'intercept': -0.12552301255230114}, 'clinical_usefulness': {'treated': -0.6755097027757306, 'treated_all': -2.01891427167772, 'untreated': 0.5757448152437098, 'overall': -0.09976488753202084, 'prevalence': 0.09432571849668386, 'adapt': 0.20036845983787763, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.035275000000183354, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4878\n",
      "Class:1.0/N=547\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4878\n",
      "Class:1.0/N=2439\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 26.44ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 23, 975792)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18281535648994515, 'recall': 0.8333333333333334, 'f1-score': 0.2998500749625187, 'support': 120.0, 'confusion_matrix': [[790, 447], [20, 100]], 'auc': 0.7424077068175694, 'n': 1357, 'tn': 790, 'fp': 447, 'fn': 20, 'tp': 100, 'dor': 8.83668903803132}, 'calibration': {'slope': 6.324148261483075, 'intercept': -0.15615153313105934}, 'clinical_usefulness': {'treated': -0.694915254237288, 'treated_all': -2.038565463031196, 'untreated': 0.5758500894831035, 'overall': -0.1190651647541845, 'prevalence': 0.08843036109064112, 'adapt': 0.19462048636698598, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03263399999923422, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4876\n",
      "Class:1.0/N=549\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4876\n",
      "Class:1.0/N=3657\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 33.906ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 24, 749185)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.8, 'recall': 0.06779661016949153, 'f1-score': 0.125, 'support': 118.0, 'confusion_matrix': [[1237, 2], [110, 8]], 'auc': 0.533091202582728, 'n': 1357, 'tn': 1237, 'fp': 2, 'fn': 110, 'tp': 8, 'dor': 44.98181818181818}, 'calibration': {'slope': 1.3921041752790408, 'intercept': -0.11368334022323268}, 'clinical_usefulness': {'treated': 0.002456398919184476, 'treated_all': -2.043478260869565, 'untreated': 0.8768291399094641, 'overall': 0.8792855388286486, 'prevalence': 0.08695652173913043, 'adapt': 0.6145173176123802, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.041274999999586726, 'explain': 1.8000000636675395e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4903\n",
      "Class:1.0/N=522\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4903\n",
      "Class:1.0/N=3677\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 33.439ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 25, 558650)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.22935779816513763, 'recall': 0.8620689655172413, 'f1-score': 0.36231884057971014, 'support': 145.0, 'confusion_matrix': [[792, 420], [20, 125]], 'auc': 0.7560743143279844, 'n': 1357, 'tn': 792, 'fp': 420, 'fn': 20, 'tp': 125, 'dor': 11.785714285714286}, 'calibration': {'slope': 4.884547460968067, 'intercept': -0.12030905068074937}, 'clinical_usefulness': {'treated': -0.630066322770818, 'treated_all': -1.9771554900515838, 'untreated': 0.5773239288346141, 'overall': -0.052742393936203835, 'prevalence': 0.10685335298452468, 'adapt': 0.21510685335298446, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.040865999999368796, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4879\n",
      "Class:1.0/N=546\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4879\n",
      "Class:1.0/N=3659\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 35.318ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 26, 355343)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1860036832412523, 'recall': 0.8347107438016529, 'f1-score': 0.3042168674698795, 'support': 121.0, 'confusion_matrix': [[794, 442], [20, 101]], 'auc': 0.7386530797828237, 'n': 1357, 'tn': 794, 'fp': 442, 'fn': 20, 'tp': 101, 'dor': 9.071719457013574}, 'calibration': {'slope': 6.194495052033278, 'intercept': -0.15219889549790255}, 'clinical_usefulness': {'treated': -0.6855809383443869, 'treated_all': -2.036109064112011, 'untreated': 0.5787977681861248, 'overall': -0.10678317015826211, 'prevalence': 0.08916728076639646, 'adapt': 0.19948415622697127, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.043002999998861924, 'explain': 1.8000000636675395e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4901\n",
      "Class:1.0/N=524\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4901\n",
      "Class:1.0/N=3675\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 36.721ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 27, 133719)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20323741007194246, 'recall': 0.7902097902097902, 'f1-score': 0.32331902718168815, 'support': 143.0, 'confusion_matrix': [[771, 443], [30, 113]], 'auc': 0.7179957604175067, 'n': 1357, 'tn': 771, 'fp': 443, 'fn': 30, 'tp': 113, 'dor': 6.555530474040632}, 'calibration': {'slope': 6.031936934075681, 'intercept': -0.22591524019899123}, 'clinical_usefulness': {'treated': -0.678457381478752, 'treated_all': -1.9820682878899532, 'untreated': 0.5586903884619433, 'overall': -0.11976699301680871, 'prevalence': 0.105379513633014, 'adapt': 0.18754605747973466, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04633099999955448, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4892\n",
      "Class:1.0/N=533\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4892\n",
      "Class:1.0/N=3669\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 33.571ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 27, 947555)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20300751879699247, 'recall': 0.8059701492537313, 'f1-score': 0.3243243243243243, 'support': 134.0, 'confusion_matrix': [[799, 424], [26, 108]], 'auc': 0.7329297909471448, 'n': 1357, 'tn': 799, 'fp': 424, 'fn': 26, 'tp': 108, 'dor': 7.827648766328012}, 'calibration': {'slope': 2.9630002369301813, 'intercept': 0.33151837838955317}, 'clinical_usefulness': {'treated': -0.6494718742323753, 'treated_all': -2.0041758781626133, 'untreated': 0.5805874302558164, 'overall': -0.0688844439765589, 'prevalence': 0.09874723655121592, 'adapt': 0.21156963890935881, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.040369999998802086, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=529\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=4896\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 38.697ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 28, 773682)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.4307692307692308, 'recall': 0.4057971014492754, 'f1-score': 0.417910447761194, 'support': 138.0, 'confusion_matrix': [[1145, 74], [82, 56]], 'auc': 0.672545802570413, 'n': 1357, 'tn': 1145, 'fp': 74, 'fn': 82, 'tp': 56, 'dor': 10.566908371786422}, 'calibration': {'slope': 2.7477089505960173, 'intercept': -0.18362847102597668}, 'clinical_usefulness': {'treated': -0.08597396217145664, 'treated_all': -1.9943502824858752, 'untreated': 0.8178755658490368, 'overall': 0.7319016036775801, 'prevalence': 0.1016949152542373, 'adapt': 0.5467207074428887, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04630600000018603, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4905\n",
      "Class:1.0/N=520\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4905\n",
      "Class:1.0/N=4905\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 39.009ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 29, 565815)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21851851851851853, 'recall': 0.8027210884353742, 'f1-score': 0.3435225618631732, 'support': 147.0, 'confusion_matrix': [[788, 422], [29, 118]], 'auc': 0.7286023500309214, 'n': 1357, 'tn': 788, 'fp': 422, 'fn': 29, 'tp': 118, 'dor': 7.5979735250857985}, 'calibration': {'slope': 5.463800063556136, 'intercept': -0.1939414955240244}, 'clinical_usefulness': {'treated': -0.6386637189879636, 'treated_all': -1.972242692213215, 'untreated': 0.5715338456679651, 'overall': -0.06712987331999853, 'prevalence': 0.10832719233603537, 'adapt': 0.20847457627118643, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04587100000026112, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4898\n",
      "Class:1.0/N=527\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4898\n",
      "Class:1.0/N=4898\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 39.981ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 30, 353408)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19710669077757687, 'recall': 0.7785714285714286, 'f1-score': 0.3145743145743146, 'support': 140.0, 'confusion_matrix': [[773, 444], [31, 109]], 'auc': 0.704460617443362, 'n': 1357, 'tn': 773, 'fp': 444, 'fn': 31, 'tp': 109, 'dor': 6.121548968323162}, 'calibration': {'slope': 6.307151411713127, 'intercept': -0.24318618627251148}, 'clinical_usefulness': {'treated': -0.6831245394252025, 'treated_all': -1.9894374846475065, 'untreated': 0.5598484050952731, 'overall': -0.12327613432992934, 'prevalence': 0.10316875460574797, 'adapt': 0.18695652173913038, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04773100000056729, 'explain': 3.099999958067201e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=536\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=4889\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 39.844ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 31, 176774)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1920152091254753, 'recall': 0.7709923664122137, 'f1-score': 0.3074581430745814, 'support': 131.0, 'confusion_matrix': [[801, 425], [30, 101]], 'auc': 0.7107330983898484, 'n': 1357, 'tn': 801, 'fp': 425, 'fn': 30, 'tp': 101, 'dor': 6.3451764705882345}, 'calibration': {'slope': 6.41378703173834, 'intercept': -0.23154465818549874}, 'clinical_usefulness': {'treated': -0.6563497912060918, 'treated_all': -2.011545074920167, 'untreated': 0.5807979787346036, 'overall': -0.07555181247148823, 'prevalence': 0.09653647752394989, 'adapt': 0.20965364775239492, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04836799999975483, 'explain': 1.8000000636675395e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with BorderlineSMOTE...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4892\n",
      "Class:1.0/N=533\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4892\n",
      "Class:1.0/N=4892\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 40.302ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'BorderlineSMOTE', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 31, 980114)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20517560073937152, 'recall': 0.8283582089552238, 'f1-score': 0.32888888888888884, 'support': 134.0, 'confusion_matrix': [[793, 430], [23, 111]], 'auc': 0.7388456328333801, 'n': 1357, 'tn': 793, 'fp': 430, 'fn': 23, 'tp': 111, 'dor': 8.900202224469162}, 'calibration': {'slope': 5.650000706673333, 'intercept': -0.15924228916958194}, 'clinical_usefulness': {'treated': -0.6575779906656841, 'treated_all': -2.0041758781626133, 'untreated': 0.5771133803558269, 'overall': -0.08046461030985719, 'prevalence': 0.09874723655121592, 'adapt': 0.20670596904937355, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04873600000064471, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4879\n",
      "Class:1.0/N=546\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_adasyn.py\", line 133, in _fit_resample\n",
      "    raise ValueError(\"No samples will be generated with the\"\n",
      "ValueError: No samples will be generated with the provided ratio settings.\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 22.384ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 32, 785649)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.56, 'recall': 0.11570247933884298, 'f1-score': 0.1917808219178082, 'support': 121.0, 'confusion_matrix': [[1225, 11], [107, 14]], 'auc': 0.5574968573644654, 'n': 1357, 'tn': 1225, 'fp': 11, 'fn': 107, 'tp': 14, 'dor': 14.570943075615972}, 'calibration': {'slope': 2.0847680460777562, 'intercept': -0.1674701058035435}, 'clinical_usefulness': {'treated': -0.008597396217145663, 'treated_all': -2.036109064112011, 'untreated': 0.8689335719549427, 'overall': 0.8603361757377971, 'prevalence': 0.08916728076639646, 'adapt': 0.6056742815033161, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.025345000000015716, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4897\n",
      "Class:1.0/N=528\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_adasyn.py\", line 133, in _fit_resample\n",
      "    raise ValueError(\"No samples will be generated with the\"\n",
      "ValueError: No samples will be generated with the provided ratio settings.\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 21.43ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 33, 545084)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1944954128440367, 'recall': 0.762589928057554, 'f1-score': 0.30994152046783624, 'support': 139.0, 'confusion_matrix': [[779, 439], [33, 106]], 'auc': 0.7032610364910042, 'n': 1357, 'tn': 779, 'fp': 439, 'fn': 33, 'tp': 106, 'dor': 5.699868847932629}, 'calibration': {'slope': 6.499625479165309, 'intercept': -0.26414734090187675}, 'clinical_usefulness': {'treated': -0.6767379022353228, 'treated_all': -1.9918938835666908, 'untreated': 0.5636382777134434, 'overall': -0.11309962452187938, 'prevalence': 0.10243183492999262, 'adapt': 0.1915254237288135, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.024660999999468913, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=540\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_adasyn.py\", line 133, in _fit_resample\n",
      "    raise ValueError(\"No samples will be generated with the\"\n",
      "ValueError: No samples will be generated with the provided ratio settings.\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.02ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 34, 249679)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19884169884169883, 'recall': 0.8110236220472441, 'f1-score': 0.3193798449612403, 'support': 127.0, 'confusion_matrix': [[815, 415], [24, 103]], 'auc': 0.7368574355034888, 'n': 1357, 'tn': 815, 'fp': 415, 'fn': 24, 'tp': 103, 'dor': 8.428212851405622}, 'calibration': {'slope': 5.8741907129173825, 'intercept': -0.1680340608302454}, 'clinical_usefulness': {'treated': -0.6376811594202898, 'treated_all': -2.021370670596905, 'untreated': 0.5930097905042636, 'overall': -0.04467136891602619, 'prevalence': 0.09358879882092852, 'adapt': 0.22380250552689757, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.023677999999563326, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=536\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_adasyn.py\", line 133, in _fit_resample\n",
      "    raise ValueError(\"No samples will be generated with the\"\n",
      "ValueError: No samples will be generated with the provided ratio settings.\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 22.058ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 34, 977977)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2033898305084746, 'recall': 0.8244274809160306, 'f1-score': 0.3262839879154079, 'support': 131.0, 'confusion_matrix': [[803, 423], [23, 108]], 'auc': 0.7444304695964037, 'n': 1357, 'tn': 803, 'fp': 423, 'fn': 23, 'tp': 108, 'dor': 8.913968547641073}, 'calibration': {'slope': 5.696534616494256, 'intercept': -0.15861721013444263}, 'clinical_usefulness': {'treated': -0.6477523949889461, 'treated_all': -2.011545074920167, 'untreated': 0.5844825771133804, 'overall': -0.06326981787556574, 'prevalence': 0.09653647752394989, 'adapt': 0.21481208548268235, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.025877000000036787, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4899\n",
      "Class:1.0/N=526\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_adasyn.py\", line 133, in _fit_resample\n",
      "    raise ValueError(\"No samples will be generated with the\"\n",
      "ValueError: No samples will be generated with the provided ratio settings.\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 24.722ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 35, 686663)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2277992277992278, 'recall': 0.8368794326241135, 'f1-score': 0.3581183611532625, 'support': 141.0, 'confusion_matrix': [[816, 400], [23, 118]], 'auc': 0.7538843784994401, 'n': 1357, 'tn': 816, 'fp': 400, 'fn': 23, 'tp': 118, 'dor': 10.466086956521739}, 'calibration': {'slope': 4.990377549099974, 'intercept': -0.13680415212073588}, 'clinical_usefulness': {'treated': -0.6008351756325228, 'treated_all': -1.9869810857283219, 'untreated': 0.5940625328981999, 'overall': -0.006772642734322876, 'prevalence': 0.10390567428150331, 'adapt': 0.23559322033898303, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.028466000001571956, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=530\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=1241\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 31.602ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 36, 515965)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.44, 'recall': 0.40145985401459855, 'f1-score': 0.4198473282442748, 'support': 137.0, 'confusion_matrix': [[1150, 70], [82, 55]], 'auc': 0.6720414024171354, 'n': 1357, 'tn': 1150, 'fp': 70, 'fn': 82, 'tp': 55, 'dor': 11.019163763066203}, 'calibration': {'slope': 2.6777951660580768, 'intercept': -0.17822987306555382}, 'clinical_usefulness': {'treated': -0.07983296487349544, 'treated_all': -1.9968066814050593, 'untreated': 0.8215601642278134, 'overall': 0.741727199354318, 'prevalence': 0.10095799557848195, 'adapt': 0.5511422254974206, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03734699999949953, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=545\n",
      "Class:0.0/N=4880\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=1275\n",
      "Class:0.0/N=4880\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 25.886ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 37, 345820)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17647058823529413, 'recall': 0.8114754098360656, 'f1-score': 0.28989751098096633, 'support': 122.0, 'confusion_matrix': [[773, 462], [23, 99]], 'auc': 0.7180526979491605, 'n': 1357, 'tn': 773, 'fp': 462, 'fn': 23, 'tp': 99, 'dor': 7.2018633540372665}, 'calibration': {'slope': 6.776164117198784, 'intercept': -0.19579368680348247}, 'clinical_usefulness': {'treated': -0.7214443625644803, 'treated_all': -2.0336526651928266, 'untreated': 0.5623749868407201, 'overall': -0.15906937572376023, 'prevalence': 0.0899042004421518, 'adapt': 0.17722918201915988, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03193900000042049, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=537\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=1269\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 26.098ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 38, 136711)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19454545454545455, 'recall': 0.823076923076923, 'f1-score': 0.31470588235294117, 'support': 130.0, 'confusion_matrix': [[784, 443], [23, 107]], 'auc': 0.7374051783587237, 'n': 1357, 'tn': 784, 'fp': 443, 'fn': 23, 'tp': 107, 'dor': 8.233192658749632}, 'calibration': {'slope': -0.009154205436614996, 'intercept': 0.4539141492297563}, 'clinical_usefulness': {'treated': -0.6828788995332841, 'treated_all': -2.014001473839351, 'untreated': 0.5704811032740289, 'overall': -0.11239779625925517, 'prevalence': 0.09579955784819455, 'adapt': 0.19447310243183494, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03187900000011723, 'explain': 2.2000000171829015e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=529\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=1259\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 28.177ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 38, 945565)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20155038759689922, 'recall': 0.7536231884057971, 'f1-score': 0.31804281345565744, 'support': 138.0, 'confusion_matrix': [[807, 412], [34, 104]], 'auc': 0.7091284136438752, 'n': 1357, 'tn': 807, 'fp': 412, 'fn': 34, 'tp': 104, 'dor': 5.99143346659052}, 'calibration': {'slope': 6.206464530891979, 'intercept': -0.25091533180768566}, 'clinical_usefulness': {'treated': -0.631785802014247, 'treated_all': -1.9943502824858752, 'untreated': 0.5839562059164122, 'overall': -0.04782959609783488, 'prevalence': 0.1016949152542373, 'adapt': 0.21923360353721438, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.036159999999654246, 'explain': 3.300000025774352e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4897\n",
      "Class:1.0/N=528\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4897\n",
      "Class:1.0/N=1235\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 25.811ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 39, 734777)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2100371747211896, 'recall': 0.8129496402877698, 'f1-score': 0.3338257016248154, 'support': 139.0, 'confusion_matrix': [[793, 425], [26, 113]], 'auc': 0.7350267569195875, 'n': 1357, 'tn': 793, 'fp': 425, 'fn': 26, 'tp': 113, 'dor': 8.109411764705882}, 'calibration': {'slope': 5.608069046554366, 'intercept': -0.17803393746756097}, 'clinical_usefulness': {'treated': -0.6475067550970277, 'treated_all': -1.9918938835666908, 'untreated': 0.5761659122012843, 'overall': -0.07134084289574338, 'prevalence': 0.10243183492999262, 'adapt': 0.20906411201179065, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03185800000028394, 'explain': 2.2000000171829015e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=530\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=2593\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 33.316ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 40, 546296)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.6785714285714286, 'recall': 0.2773722627737226, 'f1-score': 0.3937823834196891, 'support': 137.0, 'confusion_matrix': [[1202, 18], [99, 38]], 'auc': 0.6313090822065333, 'n': 1357, 'tn': 1202, 'fp': 18, 'fn': 99, 'tp': 38, 'dor': 25.631874298540968}, 'calibration': {'slope': 1.659816831457602, 'intercept': -0.12630427848908732}, 'clinical_usefulness': {'treated': -0.0029476787030213655, 'treated_all': -1.9968066814050593, 'untreated': 0.8545110011580166, 'overall': 0.8515633224549952, 'prevalence': 0.10095799557848195, 'adapt': 0.5972733971997052, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03991599999972095, 'explain': 2.0000001313746907e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=530\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=2587\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 29.179ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 41, 336437)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21941747572815534, 'recall': 0.8248175182481752, 'f1-score': 0.34662576687116564, 'support': 137.0, 'confusion_matrix': [[818, 402], [24, 113]], 'auc': 0.753179968888357, 'n': 1357, 'tn': 818, 'fp': 402, 'fn': 24, 'tp': 113, 'dor': 9.58063847429519}, 'calibration': {'slope': 5.2379618472780045, 'intercept': -0.1493005651405413}, 'clinical_usefulness': {'treated': -0.6079587324981577, 'treated_all': -1.9968066814050593, 'untreated': 0.5952205495315297, 'overall': -0.012738182966627987, 'prevalence': 0.10095799557848195, 'adapt': 0.23426676492262344, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.035969000000477536, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4879\n",
      "Class:1.0/N=546\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4879\n",
      "Class:1.0/N=2446\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 30.915ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 42, 161953)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18371212121212122, 'recall': 0.8016528925619835, 'f1-score': 0.2989214175654854, 'support': 121.0, 'confusion_matrix': [[805, 431], [24, 97]], 'auc': 0.7293020674529942, 'n': 1357, 'tn': 805, 'fp': 431, 'fn': 24, 'tp': 97, 'dor': 7.548820572312452}, 'calibration': {'slope': 3.8036214621017077, 'intercept': 0.2441766143981982}, 'clinical_usefulness': {'treated': -0.669614345369688, 'treated_all': -2.036109064112011, 'untreated': 0.5856405937467102, 'overall': -0.08397375162297782, 'prevalence': 0.08916728076639646, 'adapt': 0.2090641120117907, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03745800000069721, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=536\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=2622\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 30.268ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 42, 963842)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19056261343012704, 'recall': 0.8015267175572519, 'f1-score': 0.30791788856304986, 'support': 131.0, 'confusion_matrix': [[780, 446], [26, 105]], 'auc': 0.7194220639328543, 'n': 1357, 'tn': 780, 'fp': 446, 'fn': 26, 'tp': 105, 'dor': 7.062780269058297}, 'calibration': {'slope': 5.0493422793483616, 'intercept': 0.008615861391326751}, 'clinical_usefulness': {'treated': -0.6895111766150821, 'treated_all': -2.011545074920167, 'untreated': 0.5665859564164649, 'overall': -0.12292522019861718, 'prevalence': 0.09653647752394989, 'adapt': 0.18975681650700077, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03613299999960873, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4880\n",
      "Class:1.0/N=545\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4880\n",
      "Class:1.0/N=2649\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 28.423ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 43, 805804)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18198874296435272, 'recall': 0.7950819672131147, 'f1-score': 0.2961832061068702, 'support': 122.0, 'confusion_matrix': [[799, 436], [25, 97]], 'auc': 0.7225492798831884, 'n': 1357, 'tn': 799, 'fp': 436, 'fn': 25, 'tp': 97, 'dor': 7.110366972477064}, 'calibration': {'slope': 6.594064956248464, 'intercept': -0.20006265025553138}, 'clinical_usefulness': {'treated': -0.6782117415868335, 'treated_all': -2.0336526651928266, 'untreated': 0.5809032529739973, 'overall': -0.09730848861283625, 'prevalence': 0.0899042004421518, 'adapt': 0.203168754605748, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03528799999912735, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=530\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=3758\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 36.282ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 44, 644901)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.5222222222222223, 'recall': 0.34306569343065696, 'f1-score': 0.4140969162995595, 'support': 137.0, 'confusion_matrix': [[1177, 43], [90, 47]], 'auc': 0.6574308962546368, 'n': 1357, 'tn': 1177, 'fp': 43, 'fn': 90, 'tp': 47, 'dor': 14.294315245478035}, 'calibration': {'slope': 2.2163696087387508, 'intercept': -0.1574374623413477}, 'clinical_usefulness': {'treated': -0.0393023827069516, 'treated_all': -1.9968066814050593, 'untreated': 0.8389304137277609, 'overall': 0.7996280310208093, 'prevalence': 0.10095799557848195, 'adapt': 0.5754605747973471, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04356799999914074, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4886\n",
      "Class:1.0/N=539\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4886\n",
      "Class:1.0/N=3815\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 34.969ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 45, 443492)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17584369449378331, 'recall': 0.7734375, 'f1-score': 0.2865412445730825, 'support': 128.0, 'confusion_matrix': [[765, 464], [29, 99]], 'auc': 0.6980713486574451, 'n': 1357, 'tn': 765, 'fp': 464, 'fn': 29, 'tp': 99, 'dor': 5.628344233055886}, 'calibration': {'slope': 7.17773246198558, 'intercept': -0.2621589942035035}, 'clinical_usefulness': {'treated': -0.7248833210513386, 'treated_all': -2.01891427167772, 'untreated': 0.5545846931255921, 'overall': -0.17029862792574646, 'prevalence': 0.09432571849668386, 'adapt': 0.17074428887251286, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04165300000022398, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=529\n",
      "Class:0.0/N=4896\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=3784\n",
      "Class:0.0/N=4896\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 35.064ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 46, 267814)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20257826887661143, 'recall': 0.7971014492753623, 'f1-score': 0.32305433186490456, 'support': 138.0, 'confusion_matrix': [[786, 433], [28, 110]], 'auc': 0.7198404489305799, 'n': 1357, 'tn': 786, 'fp': 433, 'fn': 28, 'tp': 110, 'dor': 7.1313097987462895}, 'calibration': {'slope': 5.946001821846171, 'intercept': -0.2045307566536385}, 'clinical_usefulness': {'treated': -0.6634733480717268, 'treated_all': -1.9943502824858752, 'untreated': 0.5703758290346352, 'overall': -0.09309751903709151, 'prevalence': 0.1016949152542373, 'adapt': 0.20022107590272656, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.042670999999245396, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4891\n",
      "Class:1.0/N=534\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4891\n",
      "Class:1.0/N=3793\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 35.053ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 47, 110763)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20810313075506445, 'recall': 0.849624060150376, 'f1-score': 0.3343195266272189, 'support': 133.0, 'confusion_matrix': [[794, 430], [20, 113]], 'auc': 0.7474169492358347, 'n': 1357, 'tn': 794, 'fp': 430, 'fn': 20, 'tp': 113, 'dor': 10.432790697674418}, 'calibration': {'slope': 5.448262192379813, 'intercept': -0.13380603211580278}, 'clinical_usefulness': {'treated': -0.6561041513141734, 'treated_all': -2.0066322770817977, 'untreated': 0.5787977681861248, 'overall': -0.0773063831280486, 'prevalence': 0.09801031687546058, 'adapt': 0.2083271923360353, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04236999999920954, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4894\n",
      "Class:1.0/N=531\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4894\n",
      "Class:1.0/N=3711\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 34.604ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 47, 948494)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2077922077922078, 'recall': 0.8235294117647058, 'f1-score': 0.33185185185185184, 'support': 136.0, 'confusion_matrix': [[794, 427], [24, 112]], 'auc': 0.7412258515199691, 'n': 1357, 'tn': 794, 'fp': 427, 'fn': 24, 'tp': 112, 'dor': 8.6775956284153}, 'calibration': {'slope': 5.6037366033216855, 'intercept': -0.1644128098774088}, 'clinical_usefulness': {'treated': -0.6516826332596413, 'treated_all': -1.9992630803242442, 'untreated': 0.5775344773134015, 'overall': -0.0741481559462398, 'prevalence': 0.10022107590272661, 'adapt': 0.2087693441414886, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.041449000000284286, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=545\n",
      "Class:0.0/N=4880\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=4747\n",
      "Class:0.0/N=4880\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 41.029ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 48, 739989)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.7352941176470589, 'recall': 0.20491803278688525, 'f1-score': 0.32051282051282054, 'support': 122.0, 'confusion_matrix': [[1226, 9], [97, 25]], 'auc': 0.5988152916970864, 'n': 1357, 'tn': 1226, 'fp': 9, 'fn': 97, 'tp': 25, 'dor': 35.10882016036655}, 'calibration': {'slope': 1.510629008966652, 'intercept': -0.1107566242401854}, 'clinical_usefulness': {'treated': 0.002947678703021374, 'treated_all': -2.0336526651928266, 'untreated': 0.8728287188125066, 'overall': 0.8757763975155279, 'prevalence': 0.0899042004421518, 'adapt': 0.6118644067796609, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04798599999958242, 'explain': 2.0000001313746907e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4897\n",
      "Class:1.0/N=528\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4897\n",
      "Class:1.0/N=4853\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 39.188ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 49, 565288)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20471014492753623, 'recall': 0.8129496402877698, 'f1-score': 0.3270622286541245, 'support': 139.0, 'confusion_matrix': [[779, 439], [26, 113]], 'auc': 0.7362937236417763, 'n': 1357, 'tn': 779, 'fp': 439, 'fn': 26, 'tp': 113, 'dor': 7.712195549325391}, 'calibration': {'slope': 5.800059981502825, 'intercept': -0.1873311194259093}, 'clinical_usefulness': {'treated': -0.6715794645050355, 'treated_all': -1.9918938835666908, 'untreated': 0.5658490367407095, 'overall': -0.10573042776432595, 'prevalence': 0.10243183492999262, 'adapt': 0.19462048636698595, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.046145999998771, 'explain': 2.199999835283961e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4877\n",
      "Class:1.0/N=548\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4877\n",
      "Class:1.0/N=4838\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 41.165ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 50, 416256)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19047619047619047, 'recall': 0.8403361344537815, 'f1-score': 0.31055900621118016, 'support': 119.0, 'confusion_matrix': [[813, 425], [19, 100]], 'auc': 0.7612644411561069, 'n': 1357, 'tn': 813, 'fp': 425, 'fn': 19, 'tp': 100, 'dor': 10.06811145510836}, 'calibration': {'slope': 5.9649741012556055, 'intercept': -0.13618554931462123}, 'clinical_usefulness': {'treated': -0.6570867108818471, 'treated_all': -2.0410218619503806, 'untreated': 0.5931150647436572, 'overall': -0.06397164613818995, 'prevalence': 0.08769344141488578, 'adapt': 0.2180545320560058, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04814599999917846, 'explain': 2.2000000171829015e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4890\n",
      "Class:1.0/N=535\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4890\n",
      "Class:1.0/N=4723\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 39.543ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 51, 255228)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19924098671726756, 'recall': 0.7954545454545454, 'f1-score': 0.3186646433990895, 'support': 132.0, 'confusion_matrix': [[803, 422], [27, 105]], 'auc': 0.730330859616574, 'n': 1357, 'tn': 803, 'fp': 422, 'fn': 27, 'tp': 105, 'dor': 7.3999473407056335}, 'calibration': {'slope': 3.1189257131186, 'intercept': 0.3103002916672441}, 'clinical_usefulness': {'treated': -0.6482436747727831, 'treated_all': -2.009088676000982, 'untreated': 0.5832192862406569, 'overall': -0.06502438853212622, 'prevalence': 0.09727339719970524, 'adapt': 0.21378039793662484, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04709999999977299, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ADASYN...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=532\n",
      "Class:0.0/N=4893\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=4863\n",
      "Class:0.0/N=4893\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 42.242ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ADASYN', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 52, 322135)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19708029197080293, 'recall': 0.8, 'f1-score': 0.31625183016105424, 'support': 135.0, 'confusion_matrix': [[782, 440], [27, 108]], 'auc': 0.7294356549675698, 'n': 1357, 'tn': 782, 'fp': 440, 'fn': 27, 'tp': 108, 'dor': 7.109090909090909}, 'calibration': {'slope': 6.10852063043307, 'intercept': -0.2038690294075335}, 'clinical_usefulness': {'treated': -0.6769835421272412, 'treated_all': -2.001719479243429, 'untreated': 0.5677439730497947, 'overall': -0.10923956907744647, 'prevalence': 0.09948415622697127, 'adapt': 0.1943257184966839, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.05041400000118301, 'explain': 2.4000000848900527e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4894\n",
      "Class:1.0/N=531\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_random_over_sampler.py\", line 111, in _fit_resample\n",
      "    low=0, high=target_stats[class_sample], size=num_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 22.673ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 52, 762715)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.38311688311688313, 'recall': 0.4338235294117647, 'f1-score': 0.4068965517241379, 'support': 136.0, 'confusion_matrix': [[1126, 95], [77, 59]], 'auc': 0.6845582213229272, 'n': 1357, 'tn': 1126, 'fp': 95, 'fn': 77, 'tp': 59, 'dor': 9.081886534518114}, 'calibration': {'slope': 3.1337133578037513, 'intercept': -0.20057849422351515}, 'clinical_usefulness': {'treated': -0.1198722672562024, 'treated_all': -1.9992630803242442, 'untreated': 0.8054532056005895, 'overall': 0.6855809383443872, 'prevalence': 0.10022107590272661, 'adapt': 0.5278555637435519, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.024655999999595224, 'explain': 2.2000000171829015e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4912\n",
      "Class:1.0/N=513\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_random_over_sampler.py\", line 111, in _fit_resample\n",
      "    low=0, high=target_stats[class_sample], size=num_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 21.209ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 53, 202107)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.22988505747126436, 'recall': 0.7792207792207793, 'f1-score': 0.3550295857988166, 'support': 154.0, 'confusion_matrix': [[801, 402], [34, 120]], 'auc': 0.7250164631710767, 'n': 1357, 'tn': 801, 'fp': 402, 'fn': 34, 'tp': 120, 'dor': 7.032484635645302}, 'calibration': {'slope': -0.08061297504521658, 'intercept': 0.4332416271434844}, 'clinical_usefulness': {'treated': -0.6028002947678703, 'treated_all': -1.9550478997789236, 'untreated': 0.5795346878618801, 'overall': -0.02326560690599022, 'prevalence': 0.11348563006632277, 'adapt': 0.22483419307295496, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.023482000000512926, 'explain': 2.300000051036477e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4879\n",
      "Class:1.0/N=546\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_random_over_sampler.py\", line 111, in _fit_resample\n",
      "    low=0, high=target_stats[class_sample], size=num_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 21.432ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 53, 641005)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18097014925373134, 'recall': 0.8016528925619835, 'f1-score': 0.2952815829528158, 'support': 121.0, 'confusion_matrix': [[797, 439], [24, 97]], 'auc': 0.7364432052207869, 'n': 1357, 'tn': 797, 'fp': 439, 'fn': 24, 'tp': 97, 'dor': 7.337604403948368}, 'calibration': {'slope': 6.590328420632769, 'intercept': -0.1926527187517461}, 'clinical_usefulness': {'treated': -0.683370179317121, 'treated_all': -2.036109064112011, 'untreated': 0.5797452363406674, 'overall': -0.10362494297645353, 'prevalence': 0.08916728076639646, 'adapt': 0.2008106116433309, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.02338199999940116, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=536\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_random_over_sampler.py\", line 111, in _fit_resample\n",
      "    low=0, high=target_stats[class_sample], size=num_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.689ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 54, 75355)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21042471042471042, 'recall': 0.8320610687022901, 'f1-score': 0.33590138674884434, 'support': 131.0, 'confusion_matrix': [[817, 409], [22, 109]], 'auc': 0.7565315118986838, 'n': 1357, 'tn': 817, 'fp': 409, 'fn': 22, 'tp': 109, 'dor': 9.896977106023561}, 'calibration': {'slope': 5.428792705015302, 'intercept': -0.14235213290862525}, 'clinical_usefulness': {'treated': -0.6229427659051829, 'treated_all': -2.011545074920167, 'untreated': 0.595115275292136, 'overall': -0.0278274906130469, 'prevalence': 0.09653647752394989, 'adapt': 0.2296978629329403, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.022654999998849235, 'explain': 2.0000001313746907e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=536\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/over_sampling/_random_over_sampler.py\", line 111, in _fit_resample\n",
      "    low=0, high=target_stats[class_sample], size=num_samples)\n",
      "  File \"mtrand.pyx\", line 994, in mtrand.RandomState.randint\n",
      "  File \"mtrand.pyx\", line 995, in mtrand.RandomState.randint\n",
      "  File \"randint_helpers.pxi\", line 253, in mtrand._rand_int64\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 22.839ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 54, 510204)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2053742802303263, 'recall': 0.816793893129771, 'f1-score': 0.3282208588957055, 'support': 131.0, 'confusion_matrix': [[812, 414], [24, 107]], 'auc': 0.747191885732787, 'n': 1357, 'tn': 812, 'fp': 414, 'fn': 24, 'tp': 107, 'dor': 8.744363929146537}, 'calibration': {'slope': 5.660358432806892, 'intercept': -0.1624983220725883}, 'clinical_usefulness': {'treated': -0.6330140014738393, 'treated_all': -2.011545074920167, 'untreated': 0.5907990314769976, 'overall': -0.04221496999684171, 'prevalence': 0.09653647752394989, 'adapt': 0.2236551215917465, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.024932000000262633, 'explain': 4.3000000005122274e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4906\n",
      "Class:1.0/N=519\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4906\n",
      "Class:1.0/N=1226\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 24.948ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 54, 956315)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.29878048780487804, 'recall': 0.6621621621621622, 'f1-score': 0.4117647058823529, 'support': 148.0, 'confusion_matrix': [[979, 230], [50, 98]], 'auc': 0.7358214293698164, 'n': 1357, 'tn': 979, 'fp': 230, 'fn': 50, 'tp': 98, 'dor': 8.342782608695652}, 'calibration': {'slope': 3.9969683332938586, 'intercept': -0.19421614836218948}, 'clinical_usefulness': {'treated': -0.3232620977646769, 'treated_all': -1.9697862932940307, 'untreated': 0.7056532266554375, 'overall': 0.3823911288907606, 'prevalence': 0.10906411201179071, 'adapt': 0.39697862932940314, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.0305819999994128, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4904\n",
      "Class:1.0/N=521\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4904\n",
      "Class:1.0/N=1226\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 25.372ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 55, 403301)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21042471042471042, 'recall': 0.7465753424657534, 'f1-score': 0.32831325301204817, 'support': 146.0, 'confusion_matrix': [[802, 409], [37, 109]], 'auc': 0.7080500661742247, 'n': 1357, 'tn': 802, 'fp': 409, 'fn': 37, 'tp': 109, 'dor': 5.776647062710633}, 'calibration': {'slope': 6.0123400428858, 'intercept': -0.2651449124991354}, 'clinical_usefulness': {'treated': -0.6229427659051829, 'treated_all': -1.9746990911323994, 'untreated': 0.579324139383093, 'overall': -0.04361862652208992, 'prevalence': 0.10759027266028003, 'adapt': 0.21864406779661016, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.031520000000455184, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4890\n",
      "Class:1.0/N=535\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4890\n",
      "Class:1.0/N=1222\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 27.874ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 55, 863106)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20593692022263452, 'recall': 0.8409090909090909, 'f1-score': 0.33084947839046197, 'support': 132.0, 'confusion_matrix': [[797, 428], [21, 111]], 'auc': 0.7540321583178726, 'n': 1357, 'tn': 797, 'fp': 428, 'fn': 21, 'tp': 111, 'dor': 9.84279038718291}, 'calibration': {'slope': 5.547345649757937, 'intercept': -0.1424131889032324}, 'clinical_usefulness': {'treated': -0.6541390321788259, 'treated_all': -2.009088676000982, 'untreated': 0.58069270449521, 'overall': -0.07344632768361581, 'prevalence': 0.09727339719970524, 'adapt': 0.2102431834929992, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.034046000000671484, 'explain': 2.700000004551839e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=536\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=1222\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 25.32ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 56, 311376)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18653846153846154, 'recall': 0.7404580152671756, 'f1-score': 0.2980030721966206, 'support': 131.0, 'confusion_matrix': [[803, 423], [34, 97]], 'auc': 0.696586677957237, 'n': 1357, 'tn': 803, 'fp': 423, 'fn': 34, 'tp': 97, 'dor': 5.415867056042274}, 'calibration': {'slope': 6.8532019083909255, 'intercept': -0.27838574060369337}, 'clinical_usefulness': {'treated': -0.6558585114222549, 'treated_all': -2.011545074920167, 'untreated': 0.5810085272133908, 'overall': -0.07484998420886413, 'prevalence': 0.09653647752394989, 'adapt': 0.20994841562269706, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03118499999982305, 'explain': 3.400000059627928e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4899\n",
      "Class:1.0/N=526\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4899\n",
      "Class:1.0/N=1224\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 25.308ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 56, 776980)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19553072625698323, 'recall': 0.7446808510638298, 'f1-score': 0.3097345132743363, 'support': 141.0, 'confusion_matrix': [[784, 432], [36, 105]], 'auc': 0.6990248226950354, 'n': 1357, 'tn': 784, 'fp': 432, 'fn': 36, 'tp': 105, 'dor': 5.29320987654321}, 'calibration': {'slope': 6.594997103830769, 'intercept': -0.28953645821696056}, 'clinical_usefulness': {'treated': -0.6654384672070742, 'treated_all': -1.9869810857283219, 'untreated': 0.5663754079376777, 'overall': -0.09906305926939651, 'prevalence': 0.10390567428150331, 'adapt': 0.1968312453942521, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03142499999921711, 'explain': 2.3999999029911123e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4909\n",
      "Class:1.0/N=516\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4909\n",
      "Class:1.0/N=2454\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 30.474ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 57, 255142)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.8620689655172413, 'recall': 0.16556291390728478, 'f1-score': 0.27777777777777785, 'support': 151.0, 'confusion_matrix': [[1202, 4], [126, 25]], 'auc': 0.580777129803521, 'n': 1357, 'tn': 1202, 'fp': 4, 'fn': 126, 'tp': 25, 'dor': 59.62301587301587}, 'calibration': {'slope': 1.3034590130643742, 'intercept': -0.12367156298652937}, 'clinical_usefulness': {'treated': 0.011545074920167037, 'treated_all': -1.9624170965364773, 'untreated': 0.8459837877671333, 'overall': 0.8575288626873003, 'prevalence': 0.11127487103905674, 'adapt': 0.5956521739130434, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03790099999969243, 'explain': 2.2000000171829015e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4887\n",
      "Class:1.0/N=538\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4887\n",
      "Class:1.0/N=2443\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 31.883ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 57, 713472)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19157088122605365, 'recall': 0.7751937984496124, 'f1-score': 0.3072196620583717, 'support': 129.0, 'confusion_matrix': [[806, 422], [29, 100]], 'auc': 0.7227198697068404, 'n': 1357, 'tn': 806, 'fp': 422, 'fn': 29, 'tp': 100, 'dor': 6.586043471155418}, 'calibration': {'slope': 6.375910547318408, 'intercept': -0.22143880216827738}, 'clinical_usefulness': {'treated': -0.6519282731515598, 'treated_all': -2.016457872758535, 'untreated': 0.5847983998315612, 'overall': -0.06712987331999853, 'prevalence': 0.0950626381724392, 'adapt': 0.2137803979366249, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.0387380000011035, 'explain': 2.4000000848900527e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4877\n",
      "Class:1.0/N=548\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4877\n",
      "Class:1.0/N=2438\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 30.262ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 58, 182787)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.16129032258064516, 'recall': 0.7563025210084033, 'f1-score': 0.2658788774002954, 'support': 119.0, 'confusion_matrix': [[770, 468], [29, 90]], 'auc': 0.6900802324160682, 'n': 1357, 'tn': 770, 'fp': 468, 'fn': 29, 'tp': 90, 'dor': 5.106100795755968}, 'calibration': {'slope': 2.63821749705681, 'intercept': 0.45047264414871535}, 'clinical_usefulness': {'treated': -0.7383935151068531, 'treated_all': -2.0410218619503806, 'untreated': 0.5582692915043689, 'overall': -0.18012422360248426, 'prevalence': 0.08769344141488578, 'adapt': 0.16927044952100223, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03684699999939767, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4890\n",
      "Class:1.0/N=535\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4890\n",
      "Class:1.0/N=2445\n",
      "*** Training of model 'SGDClassifier' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 30.527ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 58, 683949)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1958955223880597, 'recall': 0.7954545454545454, 'f1-score': 0.3143712574850299, 'support': 132.0, 'confusion_matrix': [[794, 431], [27, 105]], 'auc': 0.7222047000618429, 'n': 1357, 'tn': 794, 'fp': 431, 'fn': 27, 'tp': 105, 'dor': 7.164217581850992}, 'calibration': {'slope': 6.134555475462459, 'intercept': -0.20174542827015007}, 'clinical_usefulness': {'treated': -0.6637189879636453, 'treated_all': -2.009088676000982, 'untreated': 0.5765870091588589, 'overall': -0.0871319788047864, 'prevalence': 0.09727339719970524, 'adapt': 0.20449521002210758, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03843400000005204, 'explain': 2.4000000848900527e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4890\n",
      "Class:1.0/N=535\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4890\n",
      "Class:1.0/N=2445\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 30.954ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 59, 142486)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21626617375231053, 'recall': 0.8863636363636364, 'f1-score': 0.3476968796433878, 'support': 132.0, 'confusion_matrix': [[801, 424], [15, 117]], 'auc': 0.7697217068645639, 'n': 1357, 'tn': 801, 'fp': 424, 'fn': 15, 'tp': 117, 'dor': 14.735377358490567}, 'calibration': {'slope': 5.053467828772279, 'intercept': -0.0928946292053679}, 'clinical_usefulness': {'treated': -0.6428395971505773, 'treated_all': -2.009088676000982, 'untreated': 0.5855353195073165, 'overall': -0.05730427764326074, 'prevalence': 0.09727339719970524, 'adapt': 0.21702284450994835, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.036908000000039465, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=535\n",
      "Class:0.0/N=4890\n",
      "Label distribution after sampling: \n",
      "Class:1.0/N=3667\n",
      "Class:0.0/N=4890\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 37.836ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 22, 59, 602948)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.10496794871794872, 'recall': 0.9924242424242424, 'f1-score': 0.18985507246376812, 'support': 132.0, 'confusion_matrix': [[108, 1117], [1, 131]], 'auc': 0.5402875695732838, 'n': 1357, 'tn': 108, 'fp': 1117, 'fn': 1, 'tp': 131, 'dor': 12.666069829901522}, 'calibration': {'slope': 10.43910674545315, 'intercept': -0.09577162151791885}, 'clinical_usefulness': {'treated': -1.8241218373863912, 'treated_all': -2.009088676000982, 'untreated': 0.07927150226339615, 'overall': -1.7448503351229951, 'prevalence': 0.09727339719970524, 'adapt': -0.4917464996315401, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04497600000104285, 'explain': 2.3999999029911123e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=537\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=3666\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 34.8ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 0, 75804)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20075046904315197, 'recall': 0.823076923076923, 'f1-score': 0.32277526395173456, 'support': 130.0, 'confusion_matrix': [[801, 426], [23, 107]], 'auc': 0.7436869161808036, 'n': 1357, 'tn': 801, 'fp': 426, 'fn': 23, 'tp': 107, 'dor': 8.74739742804654}, 'calibration': {'slope': 5.785769750458672, 'intercept': -0.16149600030109557}, 'clinical_usefulness': {'treated': -0.653647752394989, 'treated_all': -2.014001473839351, 'untreated': 0.5830087377618697, 'overall': -0.07063901463311928, 'prevalence': 0.09579955784819455, 'adapt': 0.21201179071481202, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.043288000000757165, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4890\n",
      "Class:1.0/N=535\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4890\n",
      "Class:1.0/N=3667\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 33.994ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 0, 534639)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2037037037037037, 'recall': 0.8333333333333334, 'f1-score': 0.3273809523809524, 'support': 132.0, 'confusion_matrix': [[795, 430], [22, 110]], 'auc': 0.7394557823129252, 'n': 1357, 'tn': 795, 'fp': 430, 'fn': 22, 'tp': 110, 'dor': 9.244186046511627}, 'calibration': {'slope': 5.656877818950692, 'intercept': -0.15232696791594202}, 'clinical_usefulness': {'treated': -0.6583149103414394, 'treated_all': -2.009088676000982, 'untreated': 0.5789030424255185, 'overall': -0.07941186791592092, 'prevalence': 0.09727339719970524, 'adapt': 0.20773765659543109, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.03976700000021083, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=529\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4896\n",
      "Class:1.0/N=3672\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 36.161ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 1, 1073)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21875, 'recall': 0.8623188405797102, 'f1-score': 0.3489736070381232, 'support': 138.0, 'confusion_matrix': [[794, 425], [19, 119]], 'auc': 0.758310446909441, 'n': 1357, 'tn': 794, 'fp': 425, 'fn': 19, 'tp': 119, 'dor': 11.701052631578948}, 'calibration': {'slope': 5.118213148739115, 'intercept': -0.11960913837693599}, 'clinical_usefulness': {'treated': -0.6430852370424956, 'treated_all': -1.9943502824858752, 'untreated': 0.5791135909043057, 'overall': -0.06397164613818995, 'prevalence': 0.1016949152542373, 'adapt': 0.21245394252026523, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04317300000002433, 'explain': 2.5000001187436283e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=530\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=3671\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 36.868ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 1, 467582)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.20708955223880596, 'recall': 0.8102189781021898, 'f1-score': 0.3298662704309064, 'support': 137.0, 'confusion_matrix': [[795, 425], [26, 111]], 'auc': 0.7390331458657413, 'n': 1357, 'tn': 795, 'fp': 425, 'fn': 26, 'tp': 111, 'dor': 7.985972850678733}, 'calibration': {'slope': 5.700576404950338, 'intercept': -0.1805298252481226}, 'clinical_usefulness': {'treated': -0.6489805944485384, 'treated_all': -1.9968066814050593, 'untreated': 0.577639751552795, 'overall': -0.07134084289574338, 'prevalence': 0.10095799557848195, 'adapt': 0.20965364775239492, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.043061000000307104, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4906\n",
      "Class:1.0/N=519\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4906\n",
      "Class:1.0/N=4906\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 42.458ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 1, 945940)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.6538461538461539, 'recall': 0.34459459459459457, 'f1-score': 0.45132743362831856, 'support': 148.0, 'confusion_matrix': [[1182, 27], [97, 51]], 'auc': 0.6611310441955602, 'n': 1357, 'tn': 1182, 'fp': 27, 'fn': 97, 'tp': 51, 'dor': 23.01718213058419}, 'calibration': {'slope': 1.7300868841371415, 'intercept': -0.13121065501274642}, 'clinical_usefulness': {'treated': -0.008843036109064097, 'treated_all': -1.9697862932940307, 'untreated': 0.8404042530792715, 'overall': 0.8315612169702074, 'prevalence': 0.10906411201179071, 'adapt': 0.5856300663227707, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.05291399999987334, 'explain': 2.300000051036477e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4869\n",
      "Class:1.0/N=556\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4869\n",
      "Class:1.0/N=4869\n",
      "*** Training of model 'SGDClassifier' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 41.408ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 2, 466362)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.15097690941385436, 'recall': 0.7657657657657657, 'f1-score': 0.2522255192878338, 'support': 111.0, 'confusion_matrix': [[768, 478], [26, 85]], 'auc': 0.6929272771969401, 'n': 1357, 'tn': 768, 'fp': 478, 'fn': 26, 'tp': 85, 'dor': 5.252655294496299}, 'calibration': {'slope': 6.113169325337462, 'intercept': 0.02752418156303743}, 'clinical_usefulness': {'treated': -0.7592729059199212, 'treated_all': -2.0606730533038564, 'untreated': 0.5577429203074008, 'overall': -0.20152998561252045, 'prevalence': 0.08179808400884303, 'adapt': 0.16263817243920414, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04977400000097987, 'explain': 2.1000001652282663e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4897\n",
      "Class:1.0/N=528\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4897\n",
      "Class:1.0/N=4897\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 38.279ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 2, 932411)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2169811320754717, 'recall': 0.8273381294964028, 'f1-score': 0.343796711509716, 'support': 139.0, 'confusion_matrix': [[803, 415], [24, 115]], 'auc': 0.7489958771898737, 'n': 1357, 'tn': 803, 'fp': 415, 'fn': 24, 'tp': 115, 'dor': 9.271586345381525}, 'calibration': {'slope': 3.274691055568832, 'intercept': 0.24298531535593149}, 'clinical_usefulness': {'treated': -0.6288381233112257, 'treated_all': -1.9918938835666908, 'untreated': 0.5841667543951995, 'overall': -0.04467136891602619, 'prevalence': 0.10243183492999262, 'adapt': 0.22026529108327192, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.045675999999730266, 'explain': 2.2000000171829015e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=537\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4888\n",
      "Class:1.0/N=4888\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 38.243ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 3, 406207)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.17216117216117216, 'recall': 0.7230769230769231, 'f1-score': 0.2781065088757397, 'support': 130.0, 'confusion_matrix': [[775, 452], [36, 94]], 'auc': 0.6823992226192716, 'n': 1357, 'tn': 775, 'fp': 452, 'fn': 36, 'tp': 94, 'dor': 4.477015732546706}, 'calibration': {'slope': 5.795072808219721, 'intercept': -0.05107474361079922}, 'clinical_usefulness': {'treated': -0.7079341685089656, 'treated_all': -2.014001473839351, 'untreated': 0.5597431308558796, 'overall': -0.14819103765308606, 'prevalence': 0.09579955784819455, 'adapt': 0.17943994104642597, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04415499999959138, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomOverSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=536\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=4889\n",
      "*** Training of model 'SGDClassifier' started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training of classifier ready. Time elapsed: 37.757ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomOverSampler', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 3, 919444)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.1963302752293578, 'recall': 0.816793893129771, 'f1-score': 0.31656804733727817, 'support': 131.0, 'confusion_matrix': [[788, 438], [24, 107]], 'auc': 0.7326936727145934, 'n': 1357, 'tn': 788, 'fp': 438, 'fn': 24, 'tp': 107, 'dor': 8.020928462709284}, 'calibration': {'slope': 5.996151970082922, 'intercept': -0.17722616660343604}, 'clinical_usefulness': {'treated': -0.6742815033161383, 'treated_all': -2.011545074920167, 'untreated': 0.5731129592588694, 'overall': -0.10116854405726894, 'prevalence': 0.09653647752394989, 'adapt': 0.19889462048636705, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.04543600000033621, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4899\n",
      "Class:1.0/N=526\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_selection/_random_under_sampler.py\", line 123, in _fit_resample\n",
      "    replace=self.replacement)\n",
      "  File \"mtrand.pyx\", line 1168, in mtrand.RandomState.choice\n",
      "ValueError: Cannot take a larger sample than population when 'replace=False'\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.992ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 4, 335193)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.7428571428571429, 'recall': 0.18439716312056736, 'f1-score': 0.2954545454545454, 'support': 141.0, 'confusion_matrix': [[1207, 9], [115, 26]], 'auc': 0.5884979236655469, 'n': 1357, 'tn': 1207, 'fp': 9, 'fn': 115, 'tp': 26, 'dor': 30.320772946859904}, 'calibration': {'slope': 1.5246976636899858, 'intercept': -0.13263255016970377}, 'clinical_usefulness': {'treated': 0.0036845983787767173, 'treated_all': -1.9869810857283219, 'untreated': 0.8531424360458996, 'overall': 0.8568270344246763, 'prevalence': 0.10390567428150331, 'adapt': 0.5983050847457626, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.022863000000143074, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=518\n",
      "Class:0.0/N=4907\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_selection/_random_under_sampler.py\", line 123, in _fit_resample\n",
      "    replace=self.replacement)\n",
      "  File \"mtrand.pyx\", line 1168, in mtrand.RandomState.choice\n",
      "ValueError: Cannot take a larger sample than population when 'replace=False'\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 21.146ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 4, 773777)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2106299212598425, 'recall': 0.7181208053691275, 'f1-score': 0.32572298325722987, 'support': 149.0, 'confusion_matrix': [[807, 401], [42, 107]], 'auc': 0.6954947997688786, 'n': 1357, 'tn': 807, 'fp': 401, 'fn': 42, 'tp': 107, 'dor': 5.127003918774492}, 'calibration': {'slope': 6.205011470882469, 'intercept': -0.30696168641655086}, 'clinical_usefulness': {'treated': -0.6106607713092606, 'treated_all': -1.967329894374846, 'untreated': 0.5814296241709653, 'overall': -0.02923114713829522, 'prevalence': 0.10980103168754606, 'adapt': 0.2238025055268975, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.02292699999998149, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4901\n",
      "Class:1.0/N=524\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_selection/_random_under_sampler.py\", line 123, in _fit_resample\n",
      "    replace=self.replacement)\n",
      "  File \"mtrand.pyx\", line 1168, in mtrand.RandomState.choice\n",
      "ValueError: Cannot take a larger sample than population when 'replace=False'\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.878ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 5, 209911)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.22612085769980506, 'recall': 0.8111888111888111, 'f1-score': 0.3536585365853659, 'support': 143.0, 'confusion_matrix': [[817, 397], [27, 116]], 'auc': 0.7405905461918642, 'n': 1357, 'tn': 817, 'fp': 397, 'fn': 27, 'tp': 116, 'dor': 8.841496408247037}, 'calibration': {'slope': 5.150887436072922, 'intercept': -0.1647230849599588}, 'clinical_usefulness': {'treated': -0.597150577253746, 'treated_all': -1.9820682878899532, 'untreated': 0.5935361617012317, 'overall': -0.003614415552514294, 'prevalence': 0.105379513633014, 'adapt': 0.23633014001473834, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.022688999999445514, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4880\n",
      "Class:1.0/N=545\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_selection/_random_under_sampler.py\", line 123, in _fit_resample\n",
      "    replace=self.replacement)\n",
      "  File \"mtrand.pyx\", line 1168, in mtrand.RandomState.choice\n",
      "ValueError: Cannot take a larger sample than population when 'replace=False'\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.844ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 5, 687670)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19736842105263158, 'recall': 0.860655737704918, 'f1-score': 0.3211009174311927, 'support': 122.0, 'confusion_matrix': [[808, 427], [17, 105]], 'auc': 0.7578150925864472, 'n': 1357, 'tn': 808, 'fp': 427, 'fn': 17, 'tp': 105, 'dor': 11.687560270009643}, 'calibration': {'slope': 3.675524018370235, 'intercept': 0.2402338734470651}, 'clinical_usefulness': {'treated': -0.6568410709899287, 'treated_all': -2.0336526651928266, 'untreated': 0.5900621118012422, 'overall': -0.06677895918868648, 'prevalence': 0.0899042004421518, 'adapt': 0.21599115696389093, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.02351000000089698, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4902\n",
      "Class:1.0/N=523\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_selection/_random_under_sampler.py\", line 123, in _fit_resample\n",
      "    replace=self.replacement)\n",
      "  File \"mtrand.pyx\", line 1168, in mtrand.RandomState.choice\n",
      "ValueError: Cannot take a larger sample than population when 'replace=False'\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.826ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 6, 114056)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.22840690978886757, 'recall': 0.8263888888888888, 'f1-score': 0.35789473684210527, 'support': 144.0, 'confusion_matrix': [[811, 402], [25, 119]], 'auc': 0.7469228038838509, 'n': 1357, 'tn': 811, 'fp': 402, 'fn': 25, 'tp': 119, 'dor': 9.602885572139304}, 'calibration': {'slope': 5.037715052966327, 'intercept': -0.1506491321293426}, 'clinical_usefulness': {'treated': -0.6035372144436256, 'treated_all': -1.9796118889707683, 'untreated': 0.5897462890830614, 'overall': -0.013790925360564255, 'prevalence': 0.10611643330876934, 'adapt': 0.23176123802505522, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.022598999999900116, 'explain': 2.0000001313746907e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4891\n",
      "Class:1.0/N=534\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2136\n",
      "Class:1.0/N=534\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 11.708ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 6, 529243)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.6363636363636364, 'recall': 0.05263157894736842, 'f1-score': 0.0972222222222222, 'support': 133.0, 'confusion_matrix': [[1220, 4], [126, 7]], 'auc': 0.5246818025455796, 'n': 1357, 'tn': 1220, 'fp': 4, 'fn': 126, 'tp': 7, 'dor': 16.944444444444443}, 'calibration': {'slope': 1.8424589347934295, 'intercept': -0.17247386759581873}, 'clinical_usefulness': {'treated': -0.0017194792434291322, 'treated_all': -2.0066322770817977, 'untreated': 0.8592483419307295, 'overall': 0.8575288626873004, 'prevalence': 0.09801031687546058, 'adapt': 0.600957995578482, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.014624000001276727, 'explain': 2.2000000171829015e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=540\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2160\n",
      "Class:1.0/N=540\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 11.281ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 6, 983830)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19186046511627908, 'recall': 0.7795275590551181, 'f1-score': 0.30793157076205285, 'support': 127.0, 'confusion_matrix': [[813, 417], [28, 99]], 'auc': 0.7238557070610075, 'n': 1357, 'tn': 813, 'fp': 417, 'fn': 28, 'tp': 99, 'dor': 6.893371017471737}, 'calibration': {'slope': 6.306488991118905, 'intercept': -0.20996591108676665}, 'clinical_usefulness': {'treated': -0.6440677966101694, 'treated_all': -2.021370670596905, 'untreated': 0.5902726602800294, 'overall': -0.05379513633013999, 'prevalence': 0.09358879882092852, 'adapt': 0.21997052321296973, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.014938999998776126, 'explain': 3.199999991920777e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4892\n",
      "Class:1.0/N=533\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2132\n",
      "Class:1.0/N=533\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 11.721ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 7, 404743)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21264367816091953, 'recall': 0.8283582089552238, 'f1-score': 0.3384146341463415, 'support': 134.0, 'confusion_matrix': [[812, 411], [23, 111]], 'auc': 0.7480595794535092, 'n': 1357, 'tn': 812, 'fp': 411, 'fn': 23, 'tp': 111, 'dor': 9.534750872738813}, 'calibration': {'slope': 5.40252110214554, 'intercept': -0.14881195850221252}, 'clinical_usefulness': {'treated': -0.6249078850405305, 'treated_all': -2.0041758781626133, 'untreated': 0.5911148541951785, 'overall': -0.03379303084535201, 'prevalence': 0.09874723655121592, 'adapt': 0.22630803242446573, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.015239000000292435, 'explain': 1.799999881768599e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4903\n",
      "Class:1.0/N=522\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2088\n",
      "Class:1.0/N=522\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 11.515ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 7, 824734)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2189922480620155, 'recall': 0.7793103448275862, 'f1-score': 0.34190620272314676, 'support': 145.0, 'confusion_matrix': [[809, 403], [32, 113]], 'auc': 0.7328695800614544, 'n': 1357, 'tn': 809, 'fp': 403, 'fn': 32, 'tp': 113, 'dor': 7.088787220843672}, 'calibration': {'slope': 5.526622349362834, 'intercept': -0.21028745247675018}, 'clinical_usefulness': {'treated': -0.6096782117415868, 'treated_all': -1.9771554900515838, 'untreated': 0.5860616907042846, 'overall': -0.023616521037302163, 'prevalence': 0.10685335298452468, 'adapt': 0.22733971997052316, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.014488999999230145, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4884\n",
      "Class:1.0/N=541\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2164\n",
      "Class:1.0/N=541\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 11.719ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 8, 244914)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19391634980988592, 'recall': 0.8095238095238095, 'f1-score': 0.3128834355828221, 'support': 126.0, 'confusion_matrix': [[807, 424], [24, 102]], 'auc': 0.73175118950911, 'n': 1357, 'tn': 807, 'fp': 424, 'fn': 24, 'tp': 102, 'dor': 8.089033018867925}, 'calibration': {'slope': 5.077873765627581, 'intercept': -0.005723900994441866}, 'clinical_usefulness': {'treated': -0.6538933922869073, 'treated_all': -2.023827069516089, 'untreated': 0.5871144330982209, 'overall': -0.06677895918868648, 'prevalence': 0.09285187914517318, 'adapt': 0.21481208548268238, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.015037999999549356, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4884\n",
      "Class:1.0/N=541\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=1082\n",
      "Class:1.0/N=541\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 7.831ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 8, 653626)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.6923076923076923, 'recall': 0.07142857142857142, 'f1-score': 0.12949640287769784, 'support': 126.0, 'confusion_matrix': [[1227, 4], [117, 9]], 'auc': 0.5340895903446675, 'n': 1357, 'tn': 1227, 'fp': 4, 'fn': 117, 'tp': 9, 'dor': 23.596153846153847}, 'calibration': {'slope': 1.6521985815602835, 'intercept': -0.1438297872340425}, 'clinical_usefulness': {'treated': -0.00024563989191844684, 'treated_all': -2.023827069516089, 'untreated': 0.8672491841246448, 'overall': 0.8670035442327264, 'prevalence': 0.09285187914517318, 'adapt': 0.6070007369196757, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.010575999998764019, 'explain': 3.099999958067201e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4879\n",
      "Class:1.0/N=546\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=1092\n",
      "Class:1.0/N=546\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 8.07ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 9, 69844)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18003913894324852, 'recall': 0.7603305785123967, 'f1-score': 0.29113924050632906, 'support': 121.0, 'confusion_matrix': [[817, 419], [29, 92]], 'auc': 0.7127296798523629, 'n': 1357, 'tn': 817, 'fp': 419, 'fn': 29, 'tp': 92, 'dor': 6.185828326886676}, 'calibration': {'slope': 6.860584323869678, 'intercept': -0.2351736943170457}, 'clinical_usefulness': {'treated': -0.652665192827315, 'treated_all': -2.036109064112011, 'untreated': 0.59290451626487, 'overall': -0.0597606765624451, 'prevalence': 0.08916728076639646, 'adapt': 0.2192336035372144, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.01083699999981036, 'explain': 2.0000001313746907e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=540\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=1080\n",
      "Class:1.0/N=540\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 7.914ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 9, 494447)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19397363465160075, 'recall': 0.8110236220472441, 'f1-score': 0.3130699088145897, 'support': 127.0, 'confusion_matrix': [[802, 428], [24, 103]], 'auc': 0.7300684975353691, 'n': 1357, 'tn': 802, 'fp': 428, 'fn': 24, 'tp': 103, 'dor': 8.04186137071651}, 'calibration': {'slope': 6.06362153132886, 'intercept': -0.17618270758356436}, 'clinical_usefulness': {'treated': -0.6600343895848686, 'treated_all': -2.021370670596905, 'untreated': 0.5834298347194442, 'overall': -0.07660455486542439, 'prevalence': 0.09358879882092852, 'adapt': 0.21039056742815032, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.011145000000396976, 'explain': 1.799999881768599e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4884\n",
      "Class:1.0/N=541\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=1082\n",
      "Class:1.0/N=541\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 7.863ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 9, 911884)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.18809980806142035, 'recall': 0.7777777777777778, 'f1-score': 0.3029366306027821, 'support': 126.0, 'confusion_matrix': [[808, 423], [28, 98]], 'auc': 0.7192178252291981, 'n': 1357, 'tn': 808, 'fp': 423, 'fn': 28, 'tp': 98, 'dor': 6.6855791962174935}, 'calibration': {'slope': 6.467982767843442, 'intercept': -0.21662631717593706}, 'clinical_usefulness': {'treated': -0.6551215917464995, 'treated_all': -2.023827069516089, 'untreated': 0.5865880619012528, 'overall': -0.06853352984524674, 'prevalence': 0.09285187914517318, 'adapt': 0.214075165806927, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.010942000000795815, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4909\n",
      "Class:1.0/N=516\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=1032\n",
      "Class:1.0/N=516\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 7.931ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.5, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 10, 327080)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.23517382413087934, 'recall': 0.7615894039735099, 'f1-score': 0.359375, 'support': 151.0, 'confusion_matrix': [[832, 374], [36, 115]], 'auc': 0.7265246614609073, 'n': 1357, 'tn': 832, 'fp': 374, 'fn': 36, 'tp': 115, 'dor': 7.106357694592989}, 'calibration': {'slope': 5.162644740682825, 'intercept': -0.21411890629555175}, 'clinical_usefulness': {'treated': -0.5583394743306312, 'treated_all': -1.9624170965364773, 'untreated': 0.6017475523739342, 'overall': 0.04340807804330293, 'prevalence': 0.11127487103905674, 'adapt': 0.2537214443625645, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.010792000000947155, 'explain': 2.0000001313746907e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4886\n",
      "Class:1.0/N=539\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=718\n",
      "Class:1.0/N=539\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 6.845ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 10, 732509)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.6086956521739131, 'recall': 0.21875, 'f1-score': 0.3218390804597701, 'support': 128.0, 'confusion_matrix': [[1211, 18], [100, 28]], 'auc': 0.6020519731489015, 'n': 1357, 'tn': 1211, 'fp': 18, 'fn': 100, 'tp': 28, 'dor': 18.837777777777777}, 'calibration': {'slope': 1.8782234957020056, 'intercept': -0.14326647564469908}, 'clinical_usefulness': {'treated': -0.010316875460574793, 'treated_all': -2.01891427167772, 'untreated': 0.8608274555216339, 'overall': 0.8505105800610591, 'prevalence': 0.09432571849668386, 'adapt': 0.5994841562269713, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.009775999998964835, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4894\n",
      "Class:1.0/N=531\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=708\n",
      "Class:1.0/N=531\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 7.092ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 11, 161033)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2230769230769231, 'recall': 0.8529411764705882, 'f1-score': 0.35365853658536583, 'support': 136.0, 'confusion_matrix': [[817, 404], [20, 116]], 'auc': 0.7608999373705256, 'n': 1357, 'tn': 817, 'fp': 404, 'fn': 20, 'tp': 116, 'dor': 11.729207920792078}, 'calibration': {'slope': 5.020463976949958, 'intercept': -0.11996329694026181}, 'clinical_usefulness': {'treated': -0.6091869319577499, 'treated_all': -1.9992630803242442, 'untreated': 0.5957469207284977, 'overall': -0.013440011229252202, 'prevalence': 0.10022107590272661, 'adapt': 0.23426676492262338, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.010501999999178224, 'explain': 2.0000001313746907e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4887\n",
      "Class:1.0/N=538\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=717\n",
      "Class:1.0/N=538\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 6.937ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 11, 836825)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21370967741935484, 'recall': 0.8217054263565892, 'f1-score': 0.3392, 'support': 129.0, 'confusion_matrix': [[838, 390], [23, 106]], 'auc': 0.7514487538822816, 'n': 1357, 'tn': 838, 'fp': 390, 'fn': 23, 'tp': 106, 'dor': 9.902787068004459}, 'calibration': {'slope': 5.347692147415029, 'intercept': -0.1428535637620828}, 'clinical_usefulness': {'treated': -0.5924834193072954, 'treated_all': -2.016457872758535, 'untreated': 0.6102747657648174, 'overall': 0.017791346457522006, 'prevalence': 0.0950626381724392, 'adapt': 0.2494473102431835, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.009820999999647029, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4889\n",
      "Class:1.0/N=536\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=714\n",
      "Class:1.0/N=536\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 6.9ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 12, 259698)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21705426356589147, 'recall': 0.8549618320610687, 'f1-score': 0.3462132921174652, 'support': 131.0, 'confusion_matrix': [[822, 404], [19, 112]], 'auc': 0.7625337783146333, 'n': 1357, 'tn': 822, 'fp': 404, 'fn': 19, 'tp': 112, 'dor': 11.993746743095363}, 'calibration': {'slope': 5.142389913257808, 'intercept': -0.11617765559084225}, 'clinical_usefulness': {'treated': -0.6121346106607712, 'treated_all': -2.011545074920167, 'untreated': 0.5997473418254553, 'overall': -0.012387268835315934, 'prevalence': 0.09653647752394989, 'adapt': 0.23618275607958727, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.009742000000187545, 'explain': 1.700000029813964e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4885\n",
      "Class:1.0/N=540\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=720\n",
      "Class:1.0/N=540\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 6.36ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 0.75, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 12, 708199)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.202, 'recall': 0.7952755905511811, 'f1-score': 0.32216905901116427, 'support': 127.0, 'confusion_matrix': [[831, 399], [26, 101]], 'auc': 0.737299148582037, 'n': 1357, 'tn': 831, 'fp': 399, 'fn': 26, 'tp': 101, 'dor': 8.090514748409484}, 'calibration': {'slope': 5.825336694102105, 'intercept': -0.17671801220896854}, 'clinical_usefulness': {'treated': -0.6116433308769343, 'treated_all': -2.021370670596905, 'untreated': 0.6041688598799874, 'overall': -0.00747447099694698, 'prevalence': 0.09358879882092852, 'adapt': 0.23942520265291078, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.008998999999676016, 'explain': 2.2000000171829015e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4894\n",
      "Class:1.0/N=531\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=531\n",
      "Class:1.0/N=531\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 6.325ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 13, 139286)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19262981574539365, 'recall': 0.8455882352941176, 'f1-score': 0.31377899045020463, 'support': 136.0, 'confusion_matrix': [[739, 482], [21, 115]], 'auc': 0.7254149202678615, 'n': 1357, 'tn': 739, 'fp': 482, 'fn': 21, 'tp': 115, 'dor': 8.396067970756768}, 'calibration': {'slope': 6.06067082537435, 'intercept': -0.16746590438534392}, 'clinical_usefulness': {'treated': -0.7440432326209775, 'treated_all': -1.9992630803242442, 'untreated': 0.5379513633014003, 'overall': -0.20609186931957724, 'prevalence': 0.10022107590272661, 'adapt': 0.15335298452468688, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.008981999999377877, 'explain': 1.8000000636675395e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4880\n",
      "Class:1.0/N=545\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=545\n",
      "Class:1.0/N=545\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 6.175ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 13, 544937)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.19611650485436893, 'recall': 0.8278688524590164, 'f1-score': 0.31711145996860285, 'support': 122.0, 'confusion_matrix': [[821, 414], [21, 101]], 'auc': 0.7538627463994161, 'n': 1357, 'tn': 821, 'fp': 414, 'fn': 21, 'tp': 101, 'dor': 9.53772716816195}, 'calibration': {'slope': 5.841944305525223, 'intercept': -0.14570169883138923}, 'clinical_usefulness': {'treated': -0.6374355195283714, 'treated_all': -2.0336526651928266, 'untreated': 0.5983787767133383, 'overall': -0.03905674281503313, 'prevalence': 0.0899042004421518, 'adapt': 0.2276344878408253, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.008595999999670312, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4891\n",
      "Class:1.0/N=534\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=534\n",
      "Class:1.0/N=534\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 6.106ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 13, 955624)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21330724070450097, 'recall': 0.8195488721804511, 'f1-score': 0.3385093167701863, 'support': 133.0, 'confusion_matrix': [[822, 402], [24, 109]], 'auc': 0.7446741854636592, 'n': 1357, 'tn': 822, 'fp': 402, 'fn': 24, 'tp': 109, 'dor': 9.286691542288557}, 'calibration': {'slope': 5.40720450281426, 'intercept': -0.15339587242026265}, 'clinical_usefulness': {'treated': -0.6109064112011791, 'treated_all': -2.0066322770817977, 'untreated': 0.5981682282345511, 'overall': -0.012738182966627987, 'prevalence': 0.09801031687546058, 'adapt': 0.235445836403832, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.008611999999629916, 'explain': 1.900000097521115e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4898\n",
      "Class:1.0/N=527\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=527\n",
      "Class:1.0/N=527\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 6.016ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 14, 365768)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2204724409448819, 'recall': 0.8, 'f1-score': 0.345679012345679, 'support': 140.0, 'confusion_matrix': [[821, 396], [28, 112]], 'auc': 0.743626012442775, 'n': 1357, 'tn': 821, 'fp': 396, 'fn': 28, 'tp': 112, 'dor': 8.292929292929292}, 'calibration': {'slope': 5.333526591734548, 'intercept': -0.17589958135284728}, 'clinical_usefulness': {'treated': -0.5983787767133382, 'treated_all': -1.9894374846475065, 'untreated': 0.5961680176860722, 'overall': -0.002210759027265974, 'prevalence': 0.10316875460574797, 'adapt': 0.23780397936624903, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.008526999999958207, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with RandomUnderSampler...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=530\n",
      "Class:0.0/N=4895\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=530\n",
      "Class:1.0/N=530\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 6.623ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'RandomUnderSampler', 'sampling_strategy': 1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 14, 780029)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.22515212981744423, 'recall': 0.8102189781021898, 'f1-score': 0.35238095238095246, 'support': 137.0, 'confusion_matrix': [[838, 382], [26, 111]], 'auc': 0.7497367476367117, 'n': 1357, 'tn': 838, 'fp': 382, 'fn': 26, 'tp': 111, 'dor': 9.365485300040275}, 'calibration': {'slope': 5.126639861530147, 'intercept': -0.15427388363051997}, 'clinical_usefulness': {'treated': -0.5750429869810857, 'treated_all': -1.9968066814050593, 'untreated': 0.6093272976102748, 'overall': 0.03428431062918913, 'prevalence': 0.10095799557848195, 'adapt': 0.25401621223286663, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.00909499999943364, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4893\n",
      "Class:1.0/N=532\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_generation/_cluster_centroids.py\", line 156, in _fit_resample\n",
      "    self.estimator_.fit(X[y == target_class])\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 971, in fit\n",
      "    return_n_iter=True)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 315, in k_means\n",
      "    _num_samples(X), n_clusters))\n",
      "ValueError: n_samples=4893 should be >= n_clusters=5320\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 23.382ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 15, 203497)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.7857142857142857, 'recall': 0.08148148148148149, 'f1-score': 0.1476510067114094, 'support': 135.0, 'confusion_matrix': [[1219, 3], [124, 11]], 'auc': 0.5395132448323938, 'n': 1357, 'tn': 1219, 'fp': 3, 'fn': 124, 'tp': 11, 'dor': 36.045698924731184}, 'calibration': {'slope': 1.442202960803866, 'intercept': -0.13315946920303756}, 'clinical_usefulness': {'treated': 0.0029476787030213707, 'treated_all': -2.001719479243429, 'untreated': 0.859143067691336, 'overall': 0.8620907463943573, 'prevalence': 0.09948415622697127, 'adapt': 0.6022844509948415, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.025445000001127482, 'explain': 2.099999983329326e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4876\n",
      "Class:1.0/N=549\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_generation/_cluster_centroids.py\", line 156, in _fit_resample\n",
      "    self.estimator_.fit(X[y == target_class])\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 971, in fit\n",
      "    return_n_iter=True)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 315, in k_means\n",
      "    _num_samples(X), n_clusters))\n",
      "ValueError: n_samples=4876 should be >= n_clusters=5490\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 23.581ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 15, 635727)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.183206106870229, 'recall': 0.8135593220338984, 'f1-score': 0.2990654205607477, 'support': 118.0, 'confusion_matrix': [[811, 428], [22, 96]], 'auc': 0.7482318983324442, 'n': 1357, 'tn': 811, 'fp': 428, 'fn': 22, 'tp': 96, 'dor': 8.268479184367035}, 'calibration': {'slope': 6.377732171089158, 'intercept': -0.16843950511880135}, 'clinical_usefulness': {'treated': -0.6651928273151559, 'treated_all': -2.043478260869565, 'untreated': 0.590693757237604, 'overall': -0.07449907007755197, 'prevalence': 0.08695652173913043, 'adapt': 0.21392778187177597, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.02557899999919755, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:1.0/N=527\n",
      "Class:0.0/N=4898\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_generation/_cluster_centroids.py\", line 156, in _fit_resample\n",
      "    self.estimator_.fit(X[y == target_class])\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 971, in fit\n",
      "    return_n_iter=True)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 315, in k_means\n",
      "    _num_samples(X), n_clusters))\n",
      "ValueError: n_samples=4898 should be >= n_clusters=5270\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.244ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 16, 64048)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21172022684310018, 'recall': 0.8, 'f1-score': 0.33482810164424515, 'support': 140.0, 'confusion_matrix': [[800, 417], [28, 112]], 'auc': 0.7344142504988849, 'n': 1357, 'tn': 800, 'fp': 417, 'fn': 28, 'tp': 112, 'dor': 7.673860911270983}, 'calibration': {'slope': 5.620389531774676, 'intercept': -0.18995106733125733}, 'clinical_usefulness': {'treated': -0.63448784082535, 'treated_all': -1.9894374846475065, 'untreated': 0.58069270449521, 'overall': -0.05379513633013999, 'prevalence': 0.10316875460574797, 'adapt': 0.21613854089904194, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.02203699999881792, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4895\n",
      "Class:1.0/N=530\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_generation/_cluster_centroids.py\", line 156, in _fit_resample\n",
      "    self.estimator_.fit(X[y == target_class])\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 971, in fit\n",
      "    return_n_iter=True)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 315, in k_means\n",
      "    _num_samples(X), n_clusters))\n",
      "ValueError: n_samples=4895 should be >= n_clusters=5300\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.523ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 16, 488826)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.21052631578947367, 'recall': 0.8175182481751825, 'f1-score': 0.3348281016442451, 'support': 137.0, 'confusion_matrix': [[800, 420], [25, 112]], 'auc': 0.7339715208806988, 'n': 1357, 'tn': 800, 'fp': 420, 'fn': 25, 'tp': 112, 'dor': 8.533333333333333}, 'calibration': {'slope': 5.548672566198066, 'intercept': -0.16814159291509284}, 'clinical_usefulness': {'treated': -0.6396462785556374, 'treated_all': -1.9968066814050593, 'untreated': 0.5816401726497527, 'overall': -0.05800610590588473, 'prevalence': 0.10095799557848195, 'adapt': 0.21525423728813559, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.022326000000248314, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4890\n",
      "Class:1.0/N=535\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freith01/morpher-toolkit/morpher/jobs/Sample.py\", line 44, in execute\n",
      "    X, y = sampler.fit_resample(features, labels)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/base.py\", line 85, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_generation/_cluster_centroids.py\", line 156, in _fit_resample\n",
      "    self.estimator_.fit(X[y == target_class])\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 971, in fit\n",
      "    return_n_iter=True)\n",
      "  File \"/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\", line 315, in k_means\n",
      "    _num_samples(X), n_clusters))\n",
      "ValueError: n_samples=4890 should be >= n_clusters=5350\n",
      "\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 20.862ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.1, 'scale_method': 'QuantileTransformer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 23, 16, 924245)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2053742802303263, 'recall': 0.8106060606060606, 'f1-score': 0.32771822358346103, 'support': 132.0, 'confusion_matrix': [[811, 414], [25, 107]], 'auc': 0.7387353123067408, 'n': 1357, 'tn': 811, 'fp': 414, 'fn': 25, 'tp': 107, 'dor': 8.384251207729468}, 'calibration': {'slope': 4.7316037044652655, 'intercept': 0.006483964638946016}, 'clinical_usefulness': {'treated': -0.6330140014738393, 'treated_all': -2.009088676000982, 'untreated': 0.5897462890830614, 'overall': -0.04326771239077798, 'prevalence': 0.09727339719970524, 'adapt': 0.2229182019159911, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.02295599999888509, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4882\n",
      "Class:1.0/N=543\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2172\n",
      "Class:1.0/N=543\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 11.662ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': None, 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 41, 15, 838156)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.6666666666666666, 'recall': 0.11290322580645161, 'f1-score': 0.19310344827586204, 'support': 124.0, 'confusion_matrix': [[1226, 7], [110, 14]], 'auc': 0.5536130078748397, 'n': 1357, 'tn': 1226, 'fp': 7, 'fn': 110, 'tp': 14, 'dor': 22.29090909090909}, 'calibration': {'slope': 1.71135781383433, 'intercept': -0.14090520922288652}, 'clinical_usefulness': {'treated': -0.0017194792434291305, 'treated_all': -2.028739867354458, 'untreated': 0.8687230234761554, 'overall': 0.8670035442327263, 'prevalence': 0.09137803979366249, 'adapt': 0.60759027266028, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.015476000000489876, 'explain': 1.8999999156221747e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4906\n",
      "Class:1.0/N=519\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2076\n",
      "Class:1.0/N=519\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 11.433ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': 'StandardScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 19, 59, 22, 293154)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.2188679245283019, 'recall': 0.7837837837837838, 'f1-score': 0.3421828908554573, 'support': 148.0, 'confusion_matrix': [[795, 414], [32, 116]], 'auc': 0.7258651331231976, 'n': 1357, 'tn': 795, 'fp': 414, 'fn': 32, 'tp': 116, 'dor': 6.9610507246376825}, 'calibration': {'slope': 5.55019500421658, 'intercept': -0.2147596615900006}, 'clinical_usefulness': {'treated': -0.6263817243920413, 'treated_all': -1.9697862932940307, 'untreated': 0.5757448152437098, 'overall': -0.05063690914833152, 'prevalence': 0.10906411201179071, 'adapt': 0.21510685335298443, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.014538999999786029, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4894\n",
      "Class:1.0/N=531\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2124\n",
      "Class:1.0/N=531\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 12.462ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': 'RobustScaler', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 20, 18, 10, 277366)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.22879684418145957, 'recall': 0.8529411764705882, 'f1-score': 0.36080870917573876, 'support': 136.0, 'confusion_matrix': [[830, 391], [20, 116]], 'auc': 0.7682077130606543, 'n': 1357, 'tn': 830, 'fp': 391, 'fn': 20, 'tp': 116, 'dor': 12.312020460358056}, 'calibration': {'slope': 2.251254919358045, 'intercept': 0.4330222631615763}, 'clinical_usefulness': {'treated': -0.5868337017931711, 'treated_all': -1.9992630803242442, 'untreated': 0.6053268765133172, 'overall': 0.01849317472014611, 'prevalence': 0.10022107590272661, 'adapt': 0.24767870302137066, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.015883000000030734, 'explain': 1.9999999494757503e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4874\n",
      "Class:1.0/N=551\n",
      "Label distribution after sampling: \n",
      "Class:0.0/N=2204\n",
      "Class:1.0/N=551\n",
      "*** Training of model 'SGDClassifier' started.\n",
      "*** Training of classifier ready. Time elapsed: 12.243ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/freith01/anaconda3/envs/fiber/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': 'Normalizer', 'optimize_mode': False, 'features_to_select': 'all', 'datetime': datetime.datetime(2019, 12, 13, 20, 37, 17, 789545)}, 'pipeline': None, 'performance': {'crossval_metrics': None, 'discrimination': {'precision': 0.16666666666666666, 'recall': 0.75, 'f1-score': 0.27272727272727276, 'support': 116.0, 'confusion_matrix': [[806, 435], [29, 87]], 'auc': 0.6990434577231932, 'n': 1357, 'tn': 806, 'fp': 435, 'fn': 29, 'tp': 87, 'dor': 5.558620689655172}, 'calibration': {'slope': 7.579425113464448, 'intercept': -0.2632375189107413}, 'clinical_usefulness': {'treated': -0.6838614591009579, 'treated_all': -2.0483910587079337, 'untreated': 0.5847983998315612, 'overall': -0.09906305926939662, 'prevalence': 0.08548268238761975, 'adapt': 0.20420044215180547, 'n': 1357}}, 'explanations': {}, 'weighted_explanations': {}, 'feature_importances': None, 'runtime': {'train': 0.015720999999757623, 'explain': 2.300000051036477e-05}}\n",
      "Running experiment with following parameters: {'target': 'AKI', 'cohort': 'MIMIC', 'test_size': 0.2, 'imputation_method': 'SimpleImputer', 'algorithm': 'ElasticNetLR', 'sampling_method': 'ClusterCentroids', 'sampling_strategy': 0.25, 'scale_method': 'QuantileTransformer', 'optimize_mode': False}\n",
      "Performing sampling with ClusterCentroids...\n",
      "Prior label distribution: \n",
      "Class:0.0/N=4903\n",
      "Class:1.0/N=522\n"
     ]
    }
   ],
   "source": [
    "''' define options to run experiments on '''\n",
    "options = {\n",
    "    'target': [\"AKI\"],\n",
    "    'cohort': ['MIMIC'],\n",
    "    'test_size': [0.2],\n",
    "    'imputation_method': [imputer for imputer in imputers],    \n",
    "    'algorithm': [algorithms.LR, algorithms.ENLR, algorithms.DT, algorithms.GNBAYES, algorithms.ADABOOST, algorithms.GBDT, algorithms.RF],\n",
    "    'sampling_method': [None] + [sampler for sampler in samplers],\n",
    "    'sampling_strategy': [0.1, 0.25, 0.50, 0.75, 1],\n",
    "    'scale_method': [None] + [scaler for scaler in scalers],\n",
    "    'optimize_mode': [False],\n",
    "    \n",
    "    #'explainers' : [['MimicExplainer', 'ShapExplainer', 'FeatContribExplainer', 'LimeExplainer']]\n",
    "}\n",
    "\n",
    "experiments = unpickle('experiments.json') or {}\n",
    "n_experiments = 0\n",
    "\n",
    "with Timer() as t:\n",
    "    \n",
    "    ''' iterate over different options '''\n",
    "    for combination in product(*options.values()):\n",
    "        try:\n",
    "            params = dict(zip(options.keys(), combination))\n",
    "            print(f\"Running experiment with following parameters: {params}\")\n",
    "            experiment = run_experiment(params)\n",
    "            print(experiment)\n",
    "            exp_id = str(uuid.uuid1())\n",
    "            experiments[exp_id] = experiment            \n",
    "            n_experiments += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Could not run experiment with params {str(params)}. Error: {str(e)}\")\n",
    "\n",
    "print(f'Running {n_experiments} experiments took {t.interval:.03f} sec.')\n",
    "\n",
    "''' store everything '''\n",
    "if pickle(experiments, 'experiments.json'):\n",
    "    print('Successfully saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
